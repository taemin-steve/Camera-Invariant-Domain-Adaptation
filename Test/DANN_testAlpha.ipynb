{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EHmin\\anaconda3\\envs\\EHmin\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import glob\n",
    "import cv2 as cv\n",
    "import random\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import PIL.ImageOps    \n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.utils\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import timm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = 'a'\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "CFG = {\n",
    "    'IMG_SIZE':224,\n",
    "    'EPOCHS':30,\n",
    "    'LEARNING_RATE':3e-4,\n",
    "    # 'LEARNING_RATE':10,\n",
    "    'BATCH_SIZE':8,\n",
    "    'SEED':41\n",
    "}\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#폴더 이동시 경로 수정이 필요할 수 있음 \n",
    "train_source = glob.glob(\"../Data/train_source_image/*\")\n",
    "val_source = glob.glob(\"../Data/val_source_image/*\")\n",
    "train_gt = glob.glob(\"../Data/train_source_gt/*\")\n",
    "val_gt = glob.glob(\"../Data/val_source_gt/*\")\n",
    "\n",
    "train_source += val_source\n",
    "train_gt += val_gt\n",
    "\n",
    "# glob 이후에 정렬이 안되어 있기 때문에, source - gt matching을 위해 정렬\n",
    "train_source.sort()\n",
    "train_gt.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF 생성 \n",
    "df_seg = pd.DataFrame(columns=['source','gt'])\n",
    "df_seg['source'] = train_source\n",
    "df_seg['gt'] = train_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#폴더 이동시 경로 수정이 필요할 수 있음 \n",
    "train_source_l = glob.glob(\"../Data/train_source_image/*\")\n",
    "val_source_l = glob.glob(\"../Data/val_source_image/*\")\n",
    "train_target_l = glob.glob(\"../Data/train_target_image/*\")\n",
    "\n",
    "length_s = len(train_source_l) + len(val_source_l)\n",
    "length_t = len(train_target_l)\n",
    "label = [0 for _ in range(length_s)] + [1 for _ in range(length_t)]\n",
    "\n",
    "train_source_l = train_source_l + val_source_l + train_target_l\n",
    "\n",
    "# glob 이후에 정렬이 안되어 있기 때문에, source - gt matching을 위해 정렬\n",
    "train_source_l.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF 생성 \n",
    "df_domain_adpt = pd.DataFrame(columns=['source','label'])\n",
    "df_domain_adpt['source'] = train_source_l\n",
    "df_domain_adpt['label'] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset_seg(Dataset):\n",
    "    def __init__(self, source, gt, transform=None, infer=False):\n",
    "        self.source = source\n",
    "        self.gt = gt\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.source[idx]\n",
    "        image = cv.imread(img_path)\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "        \n",
    "        mask_path = self.gt[idx]\n",
    "        mask = cv.imread(mask_path, cv.IMREAD_GRAYSCALE)\n",
    "        mask[mask == 255] = 12 #/ 배경을 픽셀값 12로 간주 이거 원래 없던 값!\n",
    "\n",
    "        if self.transform: # 알부네이션 먹이이는 형식으로 진행 \n",
    "            augmented = self.transform(image=image, mask=mask) \n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "            \n",
    "        return image, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset_domain_adpt(Dataset): # 도메인 adaptive 한 형식으로 진행하기 위해서!\n",
    "    def __init__(self, source, label, transform=None, infer=False):\n",
    "        self.source = source\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.source[idx]\n",
    "        image = cv.imread(img_path)\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        \n",
    "        # if self.infer: #/해당 Data Loader는 사실상 학습에만 쓰여서 애당 코드 필요 없음!\n",
    "        #     if self.transform:\n",
    "        #         image = self.transform(image=image)['image']\n",
    "        #     return image\n",
    "        \n",
    "        label = self.label[idx]\n",
    "        \n",
    "\n",
    "        if self.transform: # 알부네이션 먹이이는 형식으로 진행 \n",
    "            augmented = self.transform(image=image) \n",
    "            image = augmented['image']\n",
    "            \n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfrom - Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose(\n",
    "    [   \n",
    "        A.Resize(224, 224),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2660, 0]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_seg, val_seg, _, _ \u001b[39m=\u001b[39m train_test_split(df_seg, _, test_size\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, random_state\u001b[39m=\u001b[39;49mCFG[\u001b[39m'\u001b[39;49m\u001b[39mSEED\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      2\u001b[0m train_domain_adpt, val_domain_adpt, _, _ \u001b[39m=\u001b[39m train_test_split(df_domain_adpt, df_domain_adpt[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m], test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39mCFG[\u001b[39m'\u001b[39m\u001b[39mSEED\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\EHmin\\anaconda3\\envs\\EHmin\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2559\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2556\u001b[0m \u001b[39mif\u001b[39;00m n_arrays \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2557\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAt least one array required as input\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 2559\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39;49marrays)\n\u001b[0;32m   2561\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[0;32m   2562\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m\n\u001b[0;32m   2564\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\EHmin\\anaconda3\\envs\\EHmin\\lib\\site-packages\\sklearn\\utils\\validation.py:443\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \n\u001b[0;32m    426\u001b[0m \u001b[39mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    442\u001b[0m result \u001b[39m=\u001b[39m [_make_indexable(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m iterables]\n\u001b[1;32m--> 443\u001b[0m check_consistent_length(\u001b[39m*\u001b[39;49mresult)\n\u001b[0;32m    444\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\EHmin\\anaconda3\\envs\\EHmin\\lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2660, 0]"
     ]
    }
   ],
   "source": [
    "train_seg, val_seg, _, _ = train_test_split(df_seg, _, test_size=0.2, random_state=CFG['SEED'])\n",
    "train_domain_adpt, val_domain_adpt, _, _ = train_test_split(df_domain_adpt, df_domain_adpt['label'], test_size=0.2, random_state=CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_seg = CustomDataset_seg(source = train_seg['source'].values, gt = train_seg['gt'].values, transform=transform, infer=False)\n",
    "train_loader_seg = DataLoader(train_dataset_seg, batch_size=16, shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset_seg = CustomDataset_seg(source = val_seg['source'].values, gt = val_seg['gt'].values, transform=transform, infer=False)\n",
    "val_loader_seg = DataLoader(val_dataset_seg, batch_size=16, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_domain_adpt = CustomDataset_domain_adpt(source = train_domain_adpt['source'].values, label = train_domain_adpt['label'].values, transform=transform, infer=False)\n",
    "train_loader_domain_adpt = DataLoader(train_dataset_domain_adpt, batch_size=16, shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset_domain_adpt = CustomDataset_domain_adpt(source = val_domain_adpt['source'].values, label = val_domain_adpt['label'].values, transform=transform, infer=False)\n",
    "val_loader_domain_adpt = DataLoader(val_dataset_domain_adpt, batch_size=16, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "### SMP API\n",
    "\n",
    "- model.encoder - pretrained backbone to extract features of different spatial resolution\n",
    "- model.decoder - depends on models architecture (Unet/Linknet/PSPNet/FPN)\n",
    "- model.segmentation_head - last block to produce required number of mask channels (include also optional upsampling and activation)\n",
    "- model.classification_head - optional block which create classification head on top of encoder\n",
    "- model.forward(x) - sequentially pass x through model`s encoder, decoder and segmentation head (and classification head if specified)\n",
    "\n",
    "### Model Param\n",
    " - Docs - https://www.kaggle.com/code/ligtfeather/semantic-segmentation-is-easy-with-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_params=dict(\n",
    "    pooling='avg',             # one of 'avg', 'max'\n",
    "    dropout=0.5,               # dropout ratio, default is None\n",
    "    activation='sigmoid',      # activation function, default is None\n",
    "    classes=13,                 # define number of output labels\n",
    ")\n",
    "\n",
    "# model = smp.Unet('mobilenet_v2', encoder_weights='imagenet', classes=13, activation=None, encoder_depth=5, decoder_channels=[256, 128, 64, 32, 16] , aux_params=aux_params)\n",
    "# model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_params=dict(\n",
    "    pooling='max',             # one of 'avg', 'max'\n",
    "    dropout=0.5,               # dropout ratio, default is None\n",
    "    activation='sigmoid',      # activation function, default is None\n",
    "    classes=13,                 # define number of output labels\n",
    ")\n",
    "\n",
    "# from torch.autograd import Function\n",
    "\n",
    "# class ReverseLayerF(Function):\n",
    "#     @staticmethod\n",
    "#     def forward(ctx, x, alpha):\n",
    "#         ctx.alpha = alpha\n",
    "\n",
    "#         return x.view_as(x)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def backward(ctx, grad_output):\n",
    "#         output = grad_output.neg() * ctx.alpha\n",
    "\n",
    "#         return output, None\n",
    "from torch.autograd import Function\n",
    "\n",
    "class ReverseLayerF(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return [-x * ctx.alpha for x in grad_output]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "class DANN(pl.LightningModule):\n",
    "    \n",
    "    def __init__( self, arch, encoder_name, in_channels, out_classes, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.model = smp.create_model(\n",
    "            arch, encoder_name=encoder_name, in_channels=in_channels, classes=out_classes, **kwargs\n",
    "        )\n",
    "        \n",
    "        self.AdaptiveAvgPool2d = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.Flatten = nn.Flatten(start_dim=1, end_dim=-1)\n",
    "        self.Dropout = nn.Dropout(p=0.5, inplace=True)\n",
    "        self.Classifier = nn.Linear(in_features=1280, out_features=2, bias=True)\n",
    "        self.Activation = nn.Identity()\n",
    "        \n",
    "    \n",
    "    def forward(self, x, flag, alpha):\n",
    "        if flag:\n",
    "            x = self.model.encoder(x)\n",
    "            x = self.model.decoder(*x)\n",
    "            x = self.model.segmentation_head(x)\n",
    "            return x\n",
    "        \n",
    "        else:\n",
    "            x = self.model.encoder(x)\n",
    "            x = ReverseLayerF.apply(x, alpha)\n",
    "            x = self.AdaptiveAvgPool2d(x[-1])\n",
    "            x = self.Flatten(x)\n",
    "            x = self.Dropout(x)\n",
    "            x = self.Classifier(x)\n",
    "            x = self.Activation(x)\n",
    "            return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DANN(\"Unet\", \"mobilenet_v2\", in_channels=3, out_classes=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mIoU for Score >> 가져온 함수여서... batch 사이즈에 대한 고려가 안되어 있을 수 있음\n",
    "def mIoU(pred_mask, mask, smooth=1e-10, n_classes=13):\n",
    "    with torch.no_grad():\n",
    "        pred_mask = F.softmax(pred_mask, dim=1)\n",
    "        pred_mask = torch.argmax(pred_mask, dim=1)\n",
    "        pred_mask = pred_mask.contiguous().view(-1)\n",
    "        mask = mask.contiguous().view(-1)\n",
    "\n",
    "        iou_per_class = []\n",
    "        for clas in range(0, n_classes): #loop per pixel class\n",
    "            true_class = pred_mask == clas\n",
    "            true_label = mask == clas\n",
    "\n",
    "            if true_label.long().sum().item() == 0: #no exist label in this loop\n",
    "                iou_per_class.append(np.nan)\n",
    "            else:\n",
    "                intersect = torch.logical_and(true_class, true_label).sum().float().item()\n",
    "                union = torch.logical_or(true_class, true_label).sum().float().item()\n",
    "\n",
    "                iou = (intersect + smooth) / (union +smooth)\n",
    "                iou_per_class.append(iou)\n",
    "                \n",
    "    return np.nanmean(iou_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, loss_segmentation, loss_classification, val_loader_seg,val_loader_domain_adpt, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_score = 0\n",
    "    preds, true_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for  (source , gt), (source_domain, label) in tqdm(zip(val_loader_seg, val_loader_domain_adpt)):\n",
    "            source = source.float().to(device)\n",
    "            gt = gt.long().to(device)\n",
    "            \n",
    "            source_domain = source_domain.float().to(device)\n",
    "            labels = label.type(torch.LongTensor).to(device)\n",
    "            \n",
    "            outputs= model(source, True, 0)\n",
    "            output_c = model(source_domain, False, 0)\n",
    "            \n",
    "            outputs.requires_grad_(True)\n",
    "            output_c.requires_grad_(True)\n",
    "            loss_s = loss_segmentation(outputs, gt.squeeze(1))\n",
    "            loss_d = loss_classification(output_c, labels)\n",
    "            loss = loss_s + loss_d\n",
    "            \n",
    "            preds += output_c.detach().argmax(1).cpu().numpy().tolist()\n",
    "            true_labels += labels.detach().cpu().numpy().tolist()\n",
    "            \n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_score += mIoU(outputs, gt)\n",
    "        \n",
    "        val_score_acc = accuracy_score(true_labels, preds)\n",
    "    \n",
    "    return val_loss/len(val_loader_seg) , val_score/len(val_loader_seg), val_score_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader_seg, val_loader_seg, train_loader_domain_adpt, val_loader_domain_adpt, scheduler, device):\n",
    "    # Model load \n",
    "    model = model.to(device) # 그냥 model.to(device)만 하면 저장 안됨\n",
    "\n",
    "    # loss function과 optimizer 정의\n",
    "    loss_segmentation = torch.nn.CrossEntropyLoss()\n",
    "    loss_classification = torch.nn.CrossEntropyLoss()\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "    # 이거 밖에서 선언할거임 \n",
    "    \n",
    "    best_score = 0\n",
    "    acc_best_score = -2\n",
    "    best_model = None\n",
    "    best_acc_model = None\n",
    "    \n",
    "    i = 1\n",
    "    \n",
    "    for epoch in range(0, CFG['EPOCHS']):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        i = 0\n",
    "        for (source , gt), (source_domain, label) in tqdm(zip(train_loader_seg, train_loader_domain_adpt)):\n",
    "            p = float(i + 1 * len(val_loader_seg)) / CFG['EPOCHS']/len(val_loader_seg)\n",
    "            alpha = 2. / (1 + np.exp(-10* p)) - 1\n",
    "            i += 1\n",
    "            source = source.float().to(device)\n",
    "            gt = gt.long().to(device)\n",
    "            \n",
    "            source_domain = source_domain.float().to(device)\n",
    "            labels = label.type(torch.LongTensor).to(device)\n",
    "            \n",
    "            optimizer.zero_grad() #! 이건 뭐해주는거지?? 추후에 확인 필\n",
    "            outputs  = model(source, True, alpha )\n",
    "            output_c = model(source_domain, False, alpha )\n",
    "            \n",
    "            outputs.requires_grad_(True)\n",
    "            output_c.requires_grad_(True)\n",
    "                \n",
    "            \n",
    "            loss_s = loss_segmentation(outputs, gt.squeeze(1))\n",
    "            loss_d = loss_classification(output_c, labels)\n",
    "            \n",
    "            # if i < 0:\n",
    "            #     loss = (loss_s)\n",
    "            #     loss.backward()\n",
    "            #     optimizer.step()\n",
    "            #     train_loss += loss.item()\n",
    "            # ###\n",
    "            # else:\n",
    "            #     loss = (loss_s + loss_d)/2\n",
    "            #     loss.backward()\n",
    "            #     optimizer.step()\n",
    "            #     train_loss += loss_s.item()\n",
    "            \n",
    "            loss = (loss_s + loss_d)/2\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss_s.item()\n",
    "            \n",
    "            \n",
    "            \n",
    "        _train_loss = train_loss/len(train_loader_seg)\n",
    "        _val_loss, _val_score, val_score_acc = validation(model, loss_segmentation, loss_classification, val_loader_seg,val_loader_domain_adpt, device)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val IOU score(segmentation) : [{_val_score:.5f}] Val accuracy score(Domain Classifier) : [{val_score_acc:.5f}]')\n",
    "         \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(_val_score)\n",
    "        \n",
    "        if best_score < _val_score:\n",
    "            best_score = _val_score\n",
    "            best_model = model\n",
    "            torch.save(best_model.state_dict(), \"./models/DANN_mobile.pt\")\n",
    "        \n",
    "        if acc_best_score < _val_score - abs(0.5 - val_score_acc):\n",
    "            acc_best_score = _val_score - val_score_acc\n",
    "            acc_best_model = model\n",
    "            torch.save(acc_best_model.state_dict(), \"./models/DANN_mobile_Consider_domain.pt\")\n",
    "    \n",
    "    return acc_best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model()\n",
    "# model.load_state_dict(torch.load('path'))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "\n",
    "infer_model = train(model, optimizer, train_loader_seg, val_loader_seg,train_loader_domain_adpt, val_loader_domain_adpt, scheduler, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#폴더 이동시 경로 수정이 필요할 수 있음 \n",
    "test_dataset = glob.glob(\"../Data/test_image/*\")\n",
    "\n",
    "# glob 이후에 정렬이 안되어 있기 때문에, source - gt matching을 위해 정렬\n",
    "test_dataset.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(columns=['test'])\n",
    "df_test['test'] = test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset_seg(source = df_test['test'].values ,gt = _ , transform=transform, infer=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model =  smp.Unet('mobilenet_v2', encoder_weights='imagenet', classes=13, activation=None, encoder_depth=5, decoder_channels=[256, 128, 64, 32, 16] , aux_params=aux_params)\n",
    "# model.load_state_dict(torch.load('./models/smp_base.pt'))\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    infer_model.eval()\n",
    "    result = []\n",
    "    for images in tqdm(test_loader):\n",
    "        images = images.float().to(device)\n",
    "        outputs = infer_model(images, True, 0)\n",
    "        outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "        outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "        # batch에 존재하는 각 이미지에 대해서 반복\n",
    "        for pred in outputs:\n",
    "            pred = pred.astype(np.uint8)\n",
    "            pred = Image.fromarray(pred) # 이미지로 변환\n",
    "            pred = pred.resize((960, 540), Image.NEAREST) # 960 x 540 사이즈로 변환\n",
    "            pred = np.array(pred) # 다시 수치로 변환\n",
    "            # class 0 ~ 11에 해당하는 경우에 마스크 형성 / 12(배경)는 제외하고 진행\n",
    "            for class_id in range(12):\n",
    "                class_mask = (pred == class_id).astype(np.uint8)\n",
    "                if np.sum(class_mask) > 0: # 마스크가 존재하는 경우 encode\n",
    "                    mask_rle = rle_encode(class_mask)\n",
    "                    result.append(mask_rle)\n",
    "                else: # 마스크가 존재하지 않는 경우 -1\n",
    "                    result.append(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submisssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../Data/sample_submission.csv')\n",
    "submit['mask_rle'] = result\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./DANN_mobile.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EHmin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
