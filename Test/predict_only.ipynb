{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import glob\n",
    "import cv2 as cv\n",
    "import random\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import PIL.ImageOps    \n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.utils\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import timm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = 'a'\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "CFG = {\n",
    "    'IMG_SIZE':224,\n",
    "    'EPOCHS':30,\n",
    "    'LEARNING_RATE':3e-4,\n",
    "    # 'LEARNING_RATE':10,\n",
    "    'BATCH_SIZE':8,\n",
    "    'SEED':41\n",
    "}\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, source, gt, transform=None, infer=False):\n",
    "        self.source = source\n",
    "        self.gt = gt\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.source[idx]\n",
    "        image = cv.imread(img_path)\n",
    "        # image = img_path\n",
    "        \n",
    "        label = self.gt[idx]\n",
    "        # image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image, label\n",
    "        \n",
    "        mask_path = self.gt[idx]\n",
    "        mask = cv.imread(mask_path, cv.IMREAD_GRAYSCALE)\n",
    "        mask[mask == 255] = 12 #/ 배경을 픽셀값 12로 간주 이거 원래 없던 값!\n",
    "\n",
    "        if self.transform: # 알부네이션 먹이이는 형식으로 진행 \n",
    "            augmented = self.transform(image=image, mask=mask) \n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "            \n",
    "        return image, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.source)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose(\n",
    "    [   \n",
    "        # A.Resize(224, 224),\n",
    "        A.Normalize(),\n",
    "        # ToTensorV2()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #폴더 이동시 경로 수정이 필요할 수 있음 \n",
    "# test_dataset = glob.glob(\"../Data/test_image/*\")\n",
    "# test_label = glob.glob(\"../DataPreprocessing/test_image/*\")\n",
    "\n",
    "# # glob 이후에 정렬이 안되어 있기 때문에, source - gt matching을 위해 정렬\n",
    "# test_dataset.sort()\n",
    "\n",
    "# print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.DataFrame(columns=['test'])\n",
    "# df_test['test'] = test_dataset\n",
    "\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../DataPreprocessing/front_OR_back.csv')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(source = df_test['source'].values ,gt = df_test['label'].values , transform=None, infer=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add New pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation\n",
    "from PIL import Image\n",
    "import requests\n",
    "import cv2 as cv\n",
    "\n",
    "feature_extractor = SegformerFeatureExtractor.from_pretrained(\"nvidia/segformer-b0-finetuned-cityscapes-512-1024\", size = {\"height\": 540,\"width\": 960})\n",
    "# feature_extractor = SegformerFeatureExtractor.from_pretrained(\"nvidia/segformer-b0-finetuned-cityscapes-512-1024\")\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-cityscapes-512-1024\")\n",
    "\n",
    "# image = cv.imread(\"../Data/test_image/TEST_0005.png\")\n",
    "\n",
    "# inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "# outputs = model(**inputs)\n",
    "# logits = outputs.logits  # shape (batch_size, num_labels, height/4, width/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch import nn\n",
    "\n",
    "# upsampled_logits = nn.functional.interpolate(\n",
    "#     logits,\n",
    "#     size=image.shape[:2], # (height, width)\n",
    "#     mode='bilinear',\n",
    "#     align_corners=False\n",
    "# )\n",
    "\n",
    "# # Second, apply argmax on the class dimension\n",
    "# out = upsampled_logits.argmax(dim=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_to_12 = {\n",
    "    0: 0,\n",
    "    1: 1,\n",
    "    2: 2,\n",
    "    3: 3,\n",
    "    4: 3,\n",
    "    5: 4,\n",
    "    6: 5,\n",
    "    7: 6,\n",
    "    8: 7,\n",
    "    9: 7,\n",
    "    10: 8,\n",
    "    11: 9,\n",
    "    12 : 10,\n",
    "    13 : 11,\n",
    "    14 : 11,\n",
    "    15 : 11,\n",
    "    16 : 11,\n",
    "    17 : 11,\n",
    "    18 : 11,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_0 = np.load(\"../DataPreprocessing/mask0.npy\")\n",
    "mask_1 = np.load(\"../DataPreprocessing/mask1.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # infer_model.eval()\n",
    "    result = []\n",
    "    for images, label in tqdm(test_loader):\n",
    "        # images = images.float().to(device)\n",
    "        # images = images.to(device)\n",
    "        # print(images)\n",
    "        # images = cv.imread(images)\n",
    "        \n",
    "        inputs = feature_extractor(images=images, return_tensors=\"pt\")\n",
    "        op = model(**inputs)\n",
    "        outputs = op.logits\n",
    "        \n",
    "        outputs = nn.functional.interpolate(outputs,size=(540,960), mode='bilinear',align_corners=False)\n",
    "        outputs = outputs.argmax( dim=1).numpy()\n",
    "        \n",
    "        # new_outputs = []\n",
    "        # for row in outputs[0]:\n",
    "        #     a = []\n",
    "        #     for v in row:\n",
    "        #       a.append(city_to_12[v])\n",
    "        #     new_outputs.append(a)\n",
    "        \n",
    "        # new_outputs = np.array(new_outputs)\n",
    "        # new_outputs = new_outputs.astype(np.uint8)\n",
    "        \n",
    "        # batch에 존재하는 각 이미지에 대해서 반복\n",
    "        flag = True\n",
    "        for pred , l in zip(outputs,label):\n",
    "            new_pred = []\n",
    "            for row in pred:\n",
    "                a = []\n",
    "                for v in row:\n",
    "                    a.append(city_to_12[v])\n",
    "                new_pred.append(a)\n",
    "            new_pred = np.array(new_pred)\n",
    "            new_pred = new_pred.astype(np.uint8)\n",
    "            # print(new_pred.shape)\n",
    "            \n",
    "            if l == 0:\n",
    "                new_pred[~mask_0] = 12\n",
    "            else:\n",
    "                new_pred[~mask_1] = 12\n",
    "             \n",
    "            if flag:   \n",
    "                np.save('./test_img.npy', new_pred)\n",
    "                flag = False\n",
    "                \n",
    "            # pred = pred.astype(np.uint8)\n",
    "            # pred = Image.fromarray(pred) # 이미지로 변환\n",
    "            # pred = pred.resize((960, 540), Image.NEAREST) # 960 x 540 사이즈로 변환\n",
    "            # pred = np.array(pred) # 다시 수치로 변환\n",
    "            # class 0 ~ 11에 해당하는 경우에 마스크 형성 / 12(배경)는 제외하고 진행\n",
    "            for class_id in range(12):\n",
    "                class_mask = (new_pred == class_id).astype(np.uint8)\n",
    "                if np.sum(class_mask) > 0: # 마스크가 존재하는 경우 encode\n",
    "                    mask_rle = rle_encode(class_mask)\n",
    "                    result.append(mask_rle)\n",
    "                else: # 마스크가 존재하지 않는 경우 -1\n",
    "                    result.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../Data/sample_submission.csv')\n",
    "submit['mask_rle'] = result\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./OnlyPredict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = np.load(\"./test_img.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a custom colormap mapping values 0-11 to specific colors\n",
    "custom_colormap = [\n",
    "    (255, 0, 0),   # Red for 0\n",
    "    (0, 255, 0),   # Green for 1\n",
    "    (0, 0, 255),   # Blue for 2\n",
    "    (255, 255, 0), # Yellow for 3\n",
    "    (255, 0, 255), # Magenta for 4\n",
    "    (0, 255, 255), # Cyan for 5\n",
    "    (128, 0, 0),   # Maroon for 6\n",
    "    (0, 128, 0),   # Green for 7\n",
    "    (0, 0, 128),   # Navy for 8\n",
    "    (128, 128, 0), # Olive for 9\n",
    "    (128, 0, 128), # Purple for 10\n",
    "    (0, 128, 128),  # Teal for 11\n",
    "    (0,0,0) # 12영역\n",
    "]\n",
    "\n",
    "# Convert the image to a NumPy array\n",
    "image_array = np.array(new)\n",
    "iamge_array = image_array.astype(np.uint8)\n",
    "\n",
    "# Create an array for the colored image\n",
    "colored_image = np.zeros((image_array.shape[0], image_array.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "# Map the grayscale values to colors using the custom colormap\n",
    "for i in range(13):\n",
    "    colored_image[image_array == i] = custom_colormap[i]\n",
    "\n",
    "# Create a Pillow image from the NumPy array\n",
    "colored_image_pil = Image.fromarray(colored_image)\n",
    "# colored_image_pil = colored_image_pil.resize((833, 467), Image.NEAREST)\n",
    "\n",
    "# Display the image using matplotlib\n",
    "plt.imshow(colored_image_pil)\n",
    "# plt.axis('off')  # Turn off axis labels and ticks\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EHmin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
