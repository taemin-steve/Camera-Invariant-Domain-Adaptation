{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import glob\n",
    "import cv2 as cv\n",
    "import random\n",
    "import os\n",
    "from fisheye import ApplyFishEye\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import PIL.ImageOps    \n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.utils\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import timm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = 'a'\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "CFG = {\n",
    "    'IMG_SIZE':224,\n",
    "    'EPOCHS':20, # 추가 학습할때는 10 Epoch, 3e-5로 가자\n",
    "    'LEARNING_RATE':3e-4,\n",
    "    'BATCH_SIZE':8,\n",
    "    'SEED':41\n",
    "}\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#폴더 이동시 경로 수정이 필요할 수 있음 \n",
    "train_source = glob.glob(\"../Data/train_source_image/*\")\n",
    "val_source = glob.glob(\"../Data/val_source_image/*\")\n",
    "train_gt = glob.glob(\"../Data/train_source_gt/*\")\n",
    "val_gt = glob.glob(\"../Data/val_source_gt/*\")\n",
    "\n",
    "train_source += val_source\n",
    "train_gt += val_gt\n",
    "\n",
    "# glob 이후에 정렬이 안되어 있기 때문에, source - gt matching을 위해 정렬\n",
    "train_source.sort()\n",
    "train_gt.sort()\n",
    "\n",
    "print(train_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF 생성 \n",
    "df = pd.DataFrame(columns=['source','gt'])\n",
    "df['source'] = train_source\n",
    "df['gt'] = train_gt\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_back = np.load(\"../DataPreprocessing/mask0_1024_512.npy\")\n",
    "img_back = cv.imread('../DataPreprocessing/back.png')\n",
    "\n",
    "mask_front = np.load(\"../DataPreprocessing/mask1_1024_512.npy\")\n",
    "img_front = cv.imread('../DataPreprocessing/front.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "class CustomDataset(Dataset): \n",
    "    def __init__(self, source, gt, transform=None,t2= None, infer=False):\n",
    "        self.source = source\n",
    "        self.gt = gt\n",
    "        self.transform = transform\n",
    "        self.t2 = t2\n",
    "        self.infer = infer\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #추론의 경우 이때 self.gt[idx] 은 0,1 의 index\n",
    "        if self.infer:\n",
    "            image = cv.imread(img_path)\n",
    "            label = self.gt[idx]\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image, label\n",
    "        \n",
    "        # 학습할 때 \n",
    "        \n",
    "        img_path = self.source[idx]\n",
    "        mask_path = self.gt[idx]\n",
    "        image = cv.imread(img_path)\n",
    "        mask = cv.imread(mask_path)\n",
    "        \n",
    "        mask[mask == 255] = 12 #/ 배경을 픽셀값 12로 간주 이거 원래 없던 값!\n",
    "        mask[mask == 0] = 13 # 잠시 0값을 다른 값으로 변경 \n",
    "        \n",
    "        if self.transform: # 여기서 Data Aug를 진행해주고  \n",
    "            augmented = self.transform(image=image, mask = mask) \n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "        \n",
    "        # DOF aug\n",
    "        dit = 0.5 + np.random.uniform(-0.2, 0.2)\n",
    "        y_t = 0.2 + np.random.uniform(-0.05, 0.05)\n",
    "        x_t = np.random.uniform(-0.1, 0.1)\n",
    "        focal_length = 300 + np.random.uniform(-100, 100)\n",
    "        x_up = np.random.uniform(-200, 200)\n",
    "        y_up = 300 + np.random.uniform(-50, 50)\n",
    "        \n",
    "        if idx % 2 == 0:\n",
    "            image = ApplyFishEye(image,focal_length=focal_length, x_up = x_up, y_up=y_up, dit = dit, x_t = x_t,  y_t = y_t, mask_np = mask_back, mask_image=img_back, is_target= False)\n",
    "            mask = ApplyFishEye(mask,focal_length=focal_length, x_up = x_up, y_up=y_up, dit = dit, x_t = x_t,  y_t = y_t, mask_np = mask_back, mask_image=img_back, is_target= True)\n",
    "        else :\n",
    "            image = ApplyFishEye(image,focal_length=focal_length, x_up = x_up, y_up=y_up, dit = dit, x_t = x_t,  y_t = y_t, mask_np = mask_front, mask_image=img_front, is_target= False)\n",
    "            mask = ApplyFishEye(mask,focal_length=focal_length, x_up = x_up, y_up=y_up, dit = dit, x_t = x_t,  y_t = y_t, mask_np = mask_front, mask_image=img_front, is_target= True)\n",
    "        \n",
    "        mask[mask == 0] = 12\n",
    "        mask[mask == 13] = 0   \n",
    "\n",
    "        if self.t2: #현재 들어가는 구조가 다름 totensor 진행해줌\n",
    "            augmented = self.t2(image=image, mask = mask) \n",
    "            mask = augmented['mask']\n",
    "        \n",
    "        #제대로 나오는지 확인\n",
    "        \n",
    "        # fig, axs = plt.subplots(1, 2, figsize=(16, 8))\n",
    "        # axs[0].imshow(image)\n",
    "        # axs[0].set_title('Image 1')\n",
    "        # axs[1].imshow(mask)\n",
    "        # axs[1].set_title('Image 2')\n",
    "        # plt.show()\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.source)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfrom - Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose(\n",
    "    [   \n",
    "        A.Resize(512, 1024),\n",
    "        # A.Normalize(),\n",
    "        # ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_basic = A.Compose(\n",
    "    [   \n",
    "        A.RandomCrop(480*2,960*2),\n",
    "        # A.Normalize(),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "        A.Resize(512, 1024),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_basic_DOF = A.Compose(\n",
    "    [   \n",
    "        # A.RandomCrop(480*2,960*2),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "        A.Rotate(limit=15 ,p=1, border_mode=cv.BORDER_REPLICATE),\n",
    "        A.Resize(512, 1024),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "transform_gt = A.Compose(\n",
    "    [   \n",
    "        A.Resize(128, 256), # 반대일 수도 있음 \n",
    "        A.Normalize(),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, _, _ = train_test_split(df, _, test_size=0.05, random_state=CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset1= CustomDataset(source = train['source'].values, gt = train['gt'].values, transform=transform,t2 = transform_gt, infer=False)\n",
    "train_dataset2 = CustomDataset(source = train['source'].values, gt = train['gt'].values, transform=transform_basic,t2 = transform_gt, infer=False)\n",
    "train_dataset3 = CustomDataset(source = train['source'].values, gt = train['gt'].values, transform=transform_basic,t2 = transform_gt, infer=False)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset1 + train_dataset2 + train_dataset3, batch_size=4, shuffle=True, num_workers=0)\n",
    "# train_loader = DataLoader(train_dataset3, batch_size=4, shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "val_dataset = CustomDataset(source = val['source'].values, gt = val['gt'].values, transform=None,t2 = transform_gt, infer=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Segformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation, SegformerConfig\n",
    "\n",
    "\n",
    "\n",
    "# Segformer 모델을 불러오고 구성을 수정합니다.\n",
    "config = SegformerConfig.from_pretrained(\"nvidia/segformer-b0-finetuned-cityscapes-512-1024\")\n",
    "# config.num_labels = 13  # 분할 클래스 수에 맞게 수정\n",
    "config.num_labels = 19 \n",
    "\n",
    "\n",
    "feature_extractor = SegformerFeatureExtractor.from_pretrained(\"nvidia/segformer-b0-finetuned-cityscapes-512-1024\", size = {\"height\": 512,\"width\": 1024})\n",
    "segformer_model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-cityscapes-512-1024\", config=config, ignore_mismatched_sizes=True)\n",
    "\n",
    "# 분할 모델을 만듭니다.\n",
    "class SegmentationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SegmentationModel, self).__init__()\n",
    "        self.backbone1 =feature_extractor\n",
    "        self.backbone2 = segformer_model\n",
    "        self.last_conv1 = nn.Conv2d(in_channels=config.num_labels, out_channels=13, kernel_size=1, padding=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone1(images=x, return_tensors=\"pt\").to(device)\n",
    "        x = self.backbone2(**x).logits\n",
    "        x = self.last_conv1(x) # 위랑 연결 \n",
    "        \n",
    "        return x\n",
    "\n",
    "model = SegmentationModel() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추가적으로 distort된 것에 대한 증강을 하기 위해 사용한거임! 돌릴때 주의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('./models/Segformer_pretrained_decoder.pt'))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters(): # encoder는 잠그고 학습 \n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in model.backbone2.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.last_conv1.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mIoU for Score >> 가져온 함수여서... batch 사이즈에 대한 고려가 안되어 있을 수 있음\n",
    "def mIoU(pred_mask, mask, smooth=1e-10, n_classes=13):\n",
    "    with torch.no_grad():\n",
    "        pred_mask = F.softmax(pred_mask, dim=1)\n",
    "        pred_mask = torch.argmax(pred_mask, dim=1)\n",
    "        pred_mask = pred_mask.contiguous().view(-1)\n",
    "        mask = mask.contiguous().view(-1)\n",
    "\n",
    "        iou_per_class = []\n",
    "        for clas in range(0, n_classes): #loop per pixel class\n",
    "            true_class = pred_mask == clas\n",
    "            true_label = mask == clas\n",
    "\n",
    "            if true_label.long().sum().item() == 0: #no exist label in this loop\n",
    "                iou_per_class.append(np.nan)\n",
    "            else:\n",
    "                intersect = torch.logical_and(true_class, true_label).sum().float().item()\n",
    "                union = torch.logical_or(true_class, true_label).sum().float().item()\n",
    "\n",
    "                iou = (intersect + smooth) / (union +smooth)\n",
    "                iou_per_class.append(iou)\n",
    "                \n",
    "    return np.nanmean(iou_per_class) , iou_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_score = 0\n",
    "    Check_list = []\n",
    "    with torch.no_grad():\n",
    "        for source , gt in tqdm(iter(val_loader)):\n",
    "            # inputs = feature_extractor(images=source, return_tensors=\"pt\")\n",
    "            # inputs = inputs.to(device)\n",
    "            inputs = source\n",
    "            gt = gt.long().to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, gt.squeeze(1))\n",
    "            val_loss += loss.item()\n",
    "            a, b = mIoU(outputs, gt)\n",
    "            val_score += a\n",
    "            Check_list.append(b)\n",
    "    Check_list = np.array(Check_list)\n",
    "    print(np.nanmean(Check_list, axis=0))\n",
    "    return val_loss/len(val_loader) , val_score/len(val_loader)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    # Model load \n",
    "    model = model.to(device) # 그냥 model.to(device)만 하면 저장 안됨\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(0, CFG['EPOCHS']):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for source , gt in tqdm(train_loader):\n",
    "            # source = cv.cvtColor(source, cv.COLOR_RGB2BGR)\n",
    "            inputs = source\n",
    "            # inputs = feature_extractor(images=source, return_tensors=\"pt\")\n",
    "            # inputs = inputs.to(device)\n",
    "            gt = gt.long().to(device)\n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad() #! 이건 뭐해주는거지?? 추후에 확인 필\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, gt.squeeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        _train_loss = train_loss/len(train_loader)\n",
    "    \n",
    "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val accuracy score : [{_val_score:.5f}]')\n",
    "         \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(_val_score)\n",
    "        \n",
    "        if best_score < _val_score:\n",
    "            best_score = _val_score\n",
    "            best_model = model\n",
    "            torch.save(best_model.state_dict(), \"./models/Segformer_pretrained_with_noMask.pt\")\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../DataPreprocessing/front_OR_back.csv')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(source = df_test['source'].values ,gt = df_test['label'].values , transform=None,t2=None, infer=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_0 = np.load(\"../DataPreprocessing/mask0.npy\")\n",
    "mask_1 = np.load(\"../DataPreprocessing/mask1.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # infer_model.eval()\n",
    "    model = model.to(device)\n",
    "    result = []\n",
    "    for images, label in tqdm(test_loader):\n",
    "        inputs = images\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        outputs = nn.functional.interpolate(outputs,size=(540,960), mode='bilinear',align_corners=False)\n",
    "        outputs = outputs.argmax( dim=1).to(\"cpu\").numpy()\n",
    "        \n",
    "        flag = True\n",
    "        for pred , l in zip(outputs,label):\n",
    "            new_pred = np.array(pred)\n",
    "            new_pred = new_pred.astype(np.uint8)\n",
    "            # print(new_pred.shape)\n",
    "            \n",
    "            if l == 0:\n",
    "                new_pred[~mask_0] = 12\n",
    "            else:\n",
    "                new_pred[~mask_1] = 12\n",
    "             \n",
    "            if flag:   \n",
    "                np.save('./test_img.npy', new_pred)\n",
    "                flag = False\n",
    "                \n",
    "            for class_id in range(12):\n",
    "                class_mask = (new_pred == class_id).astype(np.uint8)\n",
    "                if np.sum(class_mask) > 0: # 마스크가 존재하는 경우 encode\n",
    "                    mask_rle = rle_encode(class_mask)\n",
    "                    result.append(mask_rle)\n",
    "                else: # 마스크가 존재하지 않는 경우 -1\n",
    "                    result.append(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submisssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../Data/sample_submission.csv')\n",
    "submit['mask_rle'] = result\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./Segformer_fintunning_with_noMask.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EHmin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
