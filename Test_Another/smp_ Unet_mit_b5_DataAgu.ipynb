{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EHmin\\anaconda3\\envs\\EHmin\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import glob\n",
    "import cv2 as cv\n",
    "import random\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import PIL.ImageOps    \n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.utils\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import timm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = 'a'\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "CFG = {\n",
    "    'IMG_SIZE':224,\n",
    "    'EPOCHS':30,\n",
    "    'LEARNING_RATE':3e-4,\n",
    "    # 'LEARNING_RATE':10,\n",
    "    'BATCH_SIZE':8,\n",
    "    'SEED':41\n",
    "}\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../Data/train_source_image\\\\TRAIN_SOURCE_0000.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0001.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0002.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0003.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0004.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0005.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0006.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0007.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0008.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0009.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0010.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0011.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0012.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0013.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0014.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0015.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0016.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0017.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0018.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0019.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0020.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0021.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0022.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0023.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0024.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0025.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0026.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0027.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0028.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0029.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0030.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0031.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0032.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0033.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0034.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0035.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0036.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0037.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0038.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0039.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0040.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0041.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0042.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0043.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0044.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0045.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0046.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0047.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0048.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0049.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0050.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0051.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0052.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0053.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0054.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0055.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0056.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0057.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0058.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0059.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0060.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0061.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0062.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0063.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0064.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0065.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0066.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0067.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0068.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0069.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0070.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0071.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0072.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0073.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0074.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0075.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0076.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0077.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0078.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0079.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0080.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0081.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0082.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0083.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0084.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0085.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0086.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0087.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0088.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0089.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0090.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0091.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0092.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0093.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0094.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0095.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0096.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0097.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0098.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0099.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0100.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0101.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0102.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0103.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0104.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0105.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0106.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0107.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0108.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0109.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0110.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0111.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0112.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0113.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0114.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0115.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0116.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0117.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0118.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0119.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0120.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0121.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0122.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0123.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0124.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0125.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0126.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0127.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0128.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0129.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0130.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0131.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0132.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0133.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0134.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0135.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0136.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0137.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0138.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0139.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0140.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0141.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0142.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0143.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0144.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0145.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0146.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0147.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0148.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0149.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0150.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0151.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0152.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0153.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0154.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0155.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0156.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0157.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0158.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0159.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0160.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0161.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0162.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0163.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0164.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0165.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0166.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0167.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0168.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0169.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0170.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0171.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0172.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0173.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0174.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0175.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0176.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0177.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0178.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0179.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0180.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0181.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0182.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0183.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0184.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0185.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0186.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0187.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0188.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0189.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0190.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0191.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0192.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0193.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0194.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0195.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0196.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0197.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0198.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0199.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0200.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0201.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0202.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0203.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0204.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0205.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0206.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0207.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0208.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0209.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0210.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0211.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0212.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0213.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0214.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0215.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0216.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0217.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0218.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0219.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0220.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0221.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0222.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0223.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0224.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0225.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0226.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0227.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0228.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0229.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0230.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0231.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0232.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0233.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0234.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0235.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0236.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0237.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0238.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0239.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0240.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0241.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0242.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0243.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0244.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0245.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0246.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0247.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0248.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0249.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0250.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0251.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0252.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0253.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0254.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0255.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0256.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0257.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0258.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0259.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0260.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0261.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0262.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0263.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0264.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0265.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0266.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0267.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0268.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0269.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0270.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0271.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0272.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0273.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0274.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0275.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0276.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0277.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0278.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0279.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0280.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0281.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0282.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0283.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0284.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0285.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0286.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0287.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0288.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0289.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0290.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0291.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0292.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0293.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0294.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0295.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0296.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0297.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0298.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0299.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0300.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0301.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0302.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0303.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0304.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0305.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0306.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0307.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0308.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0309.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0310.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0311.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0312.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0313.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0314.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0315.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0316.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0317.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0318.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0319.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0320.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0321.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0322.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0323.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0324.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0325.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0326.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0327.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0328.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0329.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0330.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0331.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0332.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0333.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0334.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0335.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0336.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0337.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0338.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0339.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0340.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0341.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0342.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0343.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0344.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0345.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0346.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0347.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0348.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0349.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0350.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0351.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0352.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0353.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0354.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0355.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0356.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0357.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0358.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0359.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0360.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0361.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0362.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0363.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0364.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0365.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0366.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0367.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0368.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0369.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0370.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0371.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0372.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0373.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0374.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0375.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0376.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0377.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0378.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0379.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0380.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0381.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0382.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0383.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0384.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0385.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0386.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0387.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0388.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0389.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0390.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0391.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0392.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0393.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0394.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0395.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0396.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0397.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0398.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0399.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0400.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0401.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0402.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0403.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0404.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0405.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0406.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0407.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0408.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0409.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0410.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0411.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0412.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0413.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0414.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0415.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0416.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0417.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0418.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0419.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0420.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0421.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0422.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0423.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0424.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0425.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0426.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0427.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0428.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0429.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0430.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0431.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0432.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0433.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0434.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0435.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0436.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0437.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0438.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0439.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0440.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0441.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0442.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0443.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0444.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0445.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0446.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0447.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0448.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0449.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0450.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0451.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0452.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0453.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0454.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0455.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0456.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0457.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0458.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0459.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0460.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0461.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0462.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0463.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0464.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0465.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0466.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0467.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0468.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0469.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0470.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0471.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0472.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0473.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0474.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0475.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0476.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0477.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0478.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0479.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0480.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0481.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0482.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0483.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0484.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0485.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0486.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0487.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0488.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0489.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0490.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0491.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0492.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0493.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0494.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0495.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0496.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0497.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0498.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0499.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0500.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0501.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0502.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0503.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0504.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0505.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0506.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0507.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0508.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0509.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0510.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0511.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0512.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0513.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0514.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0515.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0516.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0517.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0518.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0519.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0520.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0521.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0522.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0523.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0524.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0525.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0526.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0527.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0528.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0529.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0530.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0531.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0532.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0533.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0534.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0535.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0536.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0537.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0538.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0539.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0540.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0541.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0542.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0543.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0544.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0545.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0546.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0547.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0548.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0549.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0550.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0551.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0552.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0553.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0554.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0555.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0556.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0557.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0558.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0559.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0560.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0561.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0562.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0563.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0564.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0565.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0566.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0567.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0568.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0569.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0570.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0571.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0572.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0573.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0574.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0575.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0576.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0577.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0578.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0579.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0580.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0581.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0582.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0583.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0584.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0585.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0586.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0587.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0588.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0589.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0590.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0591.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0592.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0593.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0594.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0595.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0596.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0597.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0598.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0599.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0600.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0601.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0602.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0603.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0604.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0605.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0606.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0607.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0608.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0609.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0610.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0611.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0612.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0613.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0614.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0615.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0616.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0617.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0618.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0619.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0620.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0621.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0622.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0623.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0624.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0625.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0626.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0627.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0628.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0629.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0630.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0631.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0632.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0633.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0634.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0635.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0636.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0637.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0638.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0639.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0640.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0641.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0642.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0643.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0644.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0645.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0646.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0647.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0648.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0649.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0650.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0651.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0652.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0653.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0654.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0655.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0656.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0657.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0658.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0659.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0660.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0661.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0662.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0663.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0664.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0665.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0666.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0667.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0668.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0669.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0670.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0671.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0672.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0673.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0674.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0675.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0676.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0677.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0678.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0679.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0680.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0681.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0682.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0683.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0684.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0685.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0686.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0687.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0688.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0689.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0690.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0691.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0692.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0693.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0694.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0695.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0696.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0697.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0698.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0699.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0700.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0701.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0702.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0703.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0704.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0705.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0706.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0707.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0708.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0709.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0710.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0711.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0712.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0713.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0714.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0715.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0716.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0717.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0718.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0719.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0720.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0721.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0722.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0723.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0724.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0725.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0726.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0727.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0728.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0729.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0730.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0731.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0732.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0733.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0734.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0735.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0736.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0737.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0738.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0739.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0740.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0741.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0742.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0743.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0744.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0745.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0746.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0747.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0748.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0749.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0750.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0751.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0752.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0753.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0754.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0755.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0756.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0757.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0758.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0759.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0760.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0761.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0762.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0763.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0764.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0765.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0766.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0767.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0768.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0769.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0770.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0771.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0772.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0773.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0774.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0775.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0776.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0777.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0778.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0779.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0780.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0781.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0782.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0783.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0784.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0785.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0786.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0787.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0788.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0789.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0790.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0791.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0792.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0793.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0794.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0795.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0796.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0797.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0798.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0799.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0800.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0801.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0802.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0803.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0804.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0805.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0806.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0807.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0808.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0809.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0810.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0811.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0812.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0813.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0814.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0815.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0816.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0817.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0818.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0819.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0820.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0821.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0822.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0823.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0824.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0825.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0826.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0827.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0828.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0829.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0830.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0831.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0832.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0833.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0834.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0835.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0836.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0837.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0838.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0839.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0840.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0841.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0842.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0843.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0844.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0845.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0846.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0847.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0848.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0849.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0850.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0851.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0852.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0853.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0854.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0855.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0856.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0857.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0858.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0859.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0860.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0861.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0862.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0863.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0864.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0865.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0866.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0867.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0868.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0869.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0870.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0871.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0872.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0873.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0874.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0875.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0876.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0877.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0878.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0879.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0880.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0881.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0882.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0883.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0884.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0885.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0886.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0887.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0888.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0889.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0890.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0891.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0892.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0893.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0894.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0895.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0896.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0897.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0898.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0899.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0900.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0901.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0902.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0903.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0904.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0905.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0906.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0907.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0908.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0909.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0910.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0911.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0912.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0913.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0914.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0915.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0916.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0917.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0918.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0919.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0920.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0921.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0922.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0923.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0924.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0925.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0926.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0927.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0928.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0929.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0930.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0931.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0932.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0933.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0934.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0935.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0936.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0937.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0938.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0939.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0940.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0941.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0942.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0943.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0944.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0945.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0946.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0947.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0948.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0949.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0950.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0951.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0952.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0953.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0954.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0955.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0956.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0957.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0958.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0959.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0960.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0961.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0962.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0963.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0964.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0965.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0966.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0967.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0968.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0969.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0970.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0971.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0972.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0973.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0974.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0975.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0976.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0977.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0978.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0979.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0980.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0981.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0982.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0983.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0984.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0985.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0986.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0987.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0988.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0989.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0990.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0991.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0992.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0993.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0994.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0995.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0996.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0997.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0998.png', '../Data/train_source_image\\\\TRAIN_SOURCE_0999.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1000.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1001.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1002.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1003.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1004.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1005.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1006.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1007.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1008.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1009.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1010.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1011.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1012.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1013.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1014.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1015.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1016.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1017.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1018.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1019.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1020.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1021.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1022.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1023.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1024.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1025.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1026.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1027.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1028.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1029.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1030.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1031.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1032.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1033.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1034.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1035.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1036.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1037.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1038.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1039.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1040.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1041.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1042.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1043.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1044.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1045.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1046.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1047.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1048.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1049.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1050.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1051.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1052.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1053.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1054.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1055.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1056.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1057.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1058.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1059.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1060.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1061.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1062.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1063.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1064.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1065.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1066.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1067.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1068.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1069.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1070.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1071.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1072.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1073.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1074.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1075.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1076.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1077.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1078.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1079.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1080.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1081.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1082.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1083.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1084.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1085.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1086.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1087.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1088.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1089.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1090.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1091.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1092.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1093.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1094.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1095.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1096.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1097.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1098.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1099.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1100.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1101.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1102.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1103.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1104.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1105.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1106.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1107.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1108.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1109.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1110.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1111.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1112.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1113.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1114.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1115.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1116.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1117.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1118.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1119.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1120.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1121.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1122.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1123.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1124.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1125.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1126.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1127.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1128.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1129.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1130.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1131.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1132.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1133.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1134.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1135.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1136.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1137.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1138.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1139.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1140.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1141.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1142.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1143.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1144.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1145.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1146.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1147.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1148.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1149.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1150.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1151.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1152.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1153.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1154.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1155.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1156.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1157.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1158.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1159.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1160.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1161.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1162.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1163.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1164.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1165.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1166.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1167.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1168.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1169.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1170.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1171.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1172.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1173.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1174.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1175.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1176.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1177.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1178.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1179.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1180.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1181.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1182.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1183.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1184.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1185.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1186.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1187.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1188.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1189.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1190.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1191.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1192.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1193.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1194.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1195.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1196.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1197.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1198.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1199.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1200.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1201.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1202.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1203.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1204.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1205.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1206.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1207.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1208.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1209.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1210.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1211.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1212.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1213.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1214.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1215.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1216.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1217.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1218.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1219.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1220.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1221.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1222.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1223.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1224.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1225.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1226.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1227.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1228.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1229.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1230.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1231.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1232.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1233.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1234.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1235.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1236.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1237.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1238.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1239.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1240.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1241.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1242.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1243.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1244.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1245.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1246.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1247.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1248.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1249.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1250.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1251.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1252.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1253.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1254.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1255.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1256.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1257.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1258.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1259.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1260.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1261.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1262.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1263.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1264.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1265.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1266.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1267.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1268.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1269.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1270.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1271.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1272.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1273.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1274.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1275.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1276.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1277.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1278.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1279.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1280.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1281.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1282.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1283.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1284.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1285.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1286.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1287.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1288.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1289.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1290.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1291.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1292.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1293.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1294.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1295.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1296.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1297.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1298.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1299.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1300.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1301.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1302.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1303.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1304.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1305.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1306.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1307.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1308.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1309.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1310.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1311.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1312.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1313.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1314.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1315.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1316.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1317.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1318.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1319.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1320.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1321.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1322.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1323.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1324.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1325.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1326.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1327.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1328.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1329.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1330.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1331.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1332.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1333.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1334.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1335.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1336.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1337.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1338.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1339.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1340.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1341.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1342.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1343.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1344.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1345.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1346.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1347.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1348.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1349.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1350.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1351.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1352.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1353.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1354.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1355.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1356.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1357.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1358.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1359.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1360.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1361.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1362.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1363.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1364.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1365.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1366.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1367.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1368.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1369.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1370.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1371.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1372.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1373.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1374.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1375.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1376.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1377.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1378.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1379.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1380.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1381.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1382.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1383.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1384.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1385.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1386.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1387.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1388.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1389.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1390.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1391.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1392.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1393.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1394.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1395.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1396.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1397.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1398.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1399.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1400.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1401.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1402.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1403.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1404.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1405.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1406.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1407.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1408.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1409.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1410.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1411.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1412.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1413.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1414.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1415.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1416.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1417.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1418.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1419.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1420.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1421.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1422.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1423.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1424.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1425.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1426.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1427.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1428.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1429.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1430.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1431.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1432.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1433.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1434.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1435.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1436.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1437.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1438.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1439.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1440.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1441.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1442.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1443.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1444.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1445.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1446.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1447.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1448.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1449.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1450.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1451.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1452.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1453.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1454.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1455.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1456.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1457.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1458.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1459.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1460.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1461.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1462.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1463.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1464.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1465.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1466.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1467.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1468.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1469.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1470.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1471.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1472.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1473.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1474.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1475.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1476.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1477.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1478.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1479.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1480.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1481.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1482.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1483.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1484.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1485.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1486.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1487.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1488.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1489.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1490.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1491.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1492.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1493.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1494.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1495.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1496.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1497.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1498.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1499.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1500.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1501.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1502.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1503.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1504.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1505.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1506.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1507.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1508.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1509.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1510.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1511.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1512.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1513.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1514.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1515.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1516.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1517.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1518.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1519.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1520.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1521.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1522.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1523.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1524.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1525.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1526.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1527.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1528.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1529.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1530.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1531.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1532.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1533.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1534.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1535.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1536.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1537.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1538.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1539.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1540.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1541.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1542.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1543.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1544.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1545.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1546.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1547.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1548.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1549.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1550.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1551.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1552.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1553.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1554.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1555.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1556.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1557.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1558.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1559.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1560.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1561.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1562.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1563.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1564.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1565.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1566.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1567.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1568.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1569.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1570.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1571.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1572.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1573.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1574.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1575.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1576.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1577.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1578.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1579.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1580.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1581.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1582.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1583.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1584.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1585.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1586.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1587.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1588.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1589.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1590.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1591.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1592.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1593.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1594.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1595.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1596.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1597.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1598.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1599.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1600.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1601.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1602.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1603.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1604.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1605.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1606.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1607.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1608.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1609.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1610.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1611.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1612.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1613.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1614.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1615.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1616.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1617.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1618.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1619.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1620.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1621.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1622.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1623.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1624.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1625.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1626.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1627.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1628.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1629.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1630.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1631.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1632.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1633.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1634.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1635.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1636.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1637.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1638.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1639.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1640.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1641.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1642.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1643.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1644.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1645.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1646.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1647.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1648.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1649.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1650.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1651.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1652.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1653.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1654.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1655.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1656.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1657.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1658.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1659.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1660.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1661.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1662.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1663.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1664.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1665.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1666.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1667.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1668.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1669.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1670.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1671.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1672.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1673.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1674.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1675.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1676.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1677.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1678.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1679.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1680.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1681.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1682.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1683.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1684.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1685.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1686.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1687.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1688.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1689.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1690.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1691.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1692.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1693.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1694.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1695.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1696.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1697.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1698.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1699.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1700.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1701.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1702.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1703.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1704.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1705.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1706.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1707.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1708.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1709.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1710.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1711.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1712.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1713.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1714.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1715.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1716.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1717.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1718.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1719.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1720.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1721.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1722.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1723.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1724.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1725.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1726.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1727.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1728.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1729.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1730.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1731.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1732.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1733.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1734.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1735.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1736.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1737.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1738.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1739.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1740.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1741.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1742.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1743.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1744.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1745.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1746.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1747.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1748.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1749.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1750.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1751.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1752.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1753.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1754.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1755.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1756.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1757.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1758.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1759.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1760.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1761.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1762.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1763.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1764.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1765.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1766.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1767.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1768.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1769.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1770.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1771.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1772.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1773.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1774.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1775.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1776.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1777.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1778.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1779.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1780.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1781.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1782.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1783.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1784.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1785.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1786.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1787.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1788.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1789.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1790.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1791.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1792.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1793.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1794.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1795.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1796.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1797.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1798.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1799.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1800.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1801.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1802.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1803.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1804.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1805.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1806.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1807.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1808.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1809.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1810.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1811.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1812.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1813.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1814.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1815.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1816.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1817.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1818.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1819.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1820.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1821.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1822.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1823.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1824.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1825.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1826.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1827.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1828.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1829.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1830.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1831.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1832.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1833.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1834.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1835.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1836.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1837.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1838.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1839.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1840.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1841.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1842.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1843.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1844.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1845.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1846.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1847.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1848.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1849.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1850.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1851.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1852.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1853.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1854.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1855.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1856.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1857.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1858.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1859.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1860.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1861.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1862.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1863.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1864.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1865.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1866.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1867.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1868.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1869.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1870.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1871.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1872.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1873.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1874.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1875.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1876.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1877.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1878.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1879.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1880.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1881.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1882.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1883.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1884.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1885.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1886.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1887.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1888.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1889.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1890.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1891.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1892.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1893.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1894.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1895.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1896.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1897.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1898.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1899.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1900.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1901.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1902.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1903.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1904.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1905.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1906.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1907.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1908.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1909.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1910.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1911.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1912.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1913.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1914.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1915.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1916.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1917.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1918.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1919.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1920.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1921.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1922.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1923.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1924.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1925.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1926.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1927.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1928.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1929.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1930.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1931.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1932.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1933.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1934.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1935.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1936.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1937.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1938.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1939.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1940.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1941.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1942.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1943.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1944.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1945.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1946.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1947.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1948.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1949.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1950.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1951.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1952.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1953.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1954.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1955.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1956.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1957.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1958.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1959.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1960.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1961.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1962.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1963.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1964.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1965.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1966.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1967.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1968.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1969.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1970.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1971.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1972.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1973.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1974.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1975.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1976.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1977.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1978.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1979.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1980.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1981.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1982.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1983.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1984.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1985.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1986.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1987.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1988.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1989.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1990.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1991.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1992.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1993.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1994.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1995.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1996.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1997.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1998.png', '../Data/train_source_image\\\\TRAIN_SOURCE_1999.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2000.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2001.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2002.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2003.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2004.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2005.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2006.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2007.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2008.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2009.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2010.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2011.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2012.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2013.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2014.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2015.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2016.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2017.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2018.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2019.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2020.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2021.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2022.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2023.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2024.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2025.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2026.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2027.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2028.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2029.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2030.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2031.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2032.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2033.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2034.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2035.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2036.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2037.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2038.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2039.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2040.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2041.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2042.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2043.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2044.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2045.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2046.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2047.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2048.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2049.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2050.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2051.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2052.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2053.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2054.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2055.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2056.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2057.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2058.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2059.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2060.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2061.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2062.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2063.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2064.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2065.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2066.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2067.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2068.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2069.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2070.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2071.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2072.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2073.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2074.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2075.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2076.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2077.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2078.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2079.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2080.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2081.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2082.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2083.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2084.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2085.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2086.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2087.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2088.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2089.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2090.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2091.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2092.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2093.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2094.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2095.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2096.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2097.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2098.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2099.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2100.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2101.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2102.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2103.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2104.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2105.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2106.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2107.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2108.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2109.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2110.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2111.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2112.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2113.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2114.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2115.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2116.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2117.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2118.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2119.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2120.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2121.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2122.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2123.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2124.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2125.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2126.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2127.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2128.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2129.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2130.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2131.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2132.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2133.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2134.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2135.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2136.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2137.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2138.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2139.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2140.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2141.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2142.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2143.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2144.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2145.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2146.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2147.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2148.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2149.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2150.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2151.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2152.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2153.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2154.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2155.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2156.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2157.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2158.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2159.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2160.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2161.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2162.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2163.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2164.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2165.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2166.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2167.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2168.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2169.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2170.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2171.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2172.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2173.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2174.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2175.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2176.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2177.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2178.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2179.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2180.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2181.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2182.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2183.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2184.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2185.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2186.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2187.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2188.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2189.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2190.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2191.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2192.png', '../Data/train_source_image\\\\TRAIN_SOURCE_2193.png', '../Data/val_source_image\\\\VALID_SOURCE_000.png', '../Data/val_source_image\\\\VALID_SOURCE_001.png', '../Data/val_source_image\\\\VALID_SOURCE_002.png', '../Data/val_source_image\\\\VALID_SOURCE_003.png', '../Data/val_source_image\\\\VALID_SOURCE_004.png', '../Data/val_source_image\\\\VALID_SOURCE_005.png', '../Data/val_source_image\\\\VALID_SOURCE_006.png', '../Data/val_source_image\\\\VALID_SOURCE_007.png', '../Data/val_source_image\\\\VALID_SOURCE_008.png', '../Data/val_source_image\\\\VALID_SOURCE_009.png', '../Data/val_source_image\\\\VALID_SOURCE_010.png', '../Data/val_source_image\\\\VALID_SOURCE_011.png', '../Data/val_source_image\\\\VALID_SOURCE_012.png', '../Data/val_source_image\\\\VALID_SOURCE_013.png', '../Data/val_source_image\\\\VALID_SOURCE_014.png', '../Data/val_source_image\\\\VALID_SOURCE_015.png', '../Data/val_source_image\\\\VALID_SOURCE_016.png', '../Data/val_source_image\\\\VALID_SOURCE_017.png', '../Data/val_source_image\\\\VALID_SOURCE_018.png', '../Data/val_source_image\\\\VALID_SOURCE_019.png', '../Data/val_source_image\\\\VALID_SOURCE_020.png', '../Data/val_source_image\\\\VALID_SOURCE_021.png', '../Data/val_source_image\\\\VALID_SOURCE_022.png', '../Data/val_source_image\\\\VALID_SOURCE_023.png', '../Data/val_source_image\\\\VALID_SOURCE_024.png', '../Data/val_source_image\\\\VALID_SOURCE_025.png', '../Data/val_source_image\\\\VALID_SOURCE_026.png', '../Data/val_source_image\\\\VALID_SOURCE_027.png', '../Data/val_source_image\\\\VALID_SOURCE_028.png', '../Data/val_source_image\\\\VALID_SOURCE_029.png', '../Data/val_source_image\\\\VALID_SOURCE_030.png', '../Data/val_source_image\\\\VALID_SOURCE_031.png', '../Data/val_source_image\\\\VALID_SOURCE_032.png', '../Data/val_source_image\\\\VALID_SOURCE_033.png', '../Data/val_source_image\\\\VALID_SOURCE_034.png', '../Data/val_source_image\\\\VALID_SOURCE_035.png', '../Data/val_source_image\\\\VALID_SOURCE_036.png', '../Data/val_source_image\\\\VALID_SOURCE_037.png', '../Data/val_source_image\\\\VALID_SOURCE_038.png', '../Data/val_source_image\\\\VALID_SOURCE_039.png', '../Data/val_source_image\\\\VALID_SOURCE_040.png', '../Data/val_source_image\\\\VALID_SOURCE_041.png', '../Data/val_source_image\\\\VALID_SOURCE_042.png', '../Data/val_source_image\\\\VALID_SOURCE_043.png', '../Data/val_source_image\\\\VALID_SOURCE_044.png', '../Data/val_source_image\\\\VALID_SOURCE_045.png', '../Data/val_source_image\\\\VALID_SOURCE_046.png', '../Data/val_source_image\\\\VALID_SOURCE_047.png', '../Data/val_source_image\\\\VALID_SOURCE_048.png', '../Data/val_source_image\\\\VALID_SOURCE_049.png', '../Data/val_source_image\\\\VALID_SOURCE_050.png', '../Data/val_source_image\\\\VALID_SOURCE_051.png', '../Data/val_source_image\\\\VALID_SOURCE_052.png', '../Data/val_source_image\\\\VALID_SOURCE_053.png', '../Data/val_source_image\\\\VALID_SOURCE_054.png', '../Data/val_source_image\\\\VALID_SOURCE_055.png', '../Data/val_source_image\\\\VALID_SOURCE_056.png', '../Data/val_source_image\\\\VALID_SOURCE_057.png', '../Data/val_source_image\\\\VALID_SOURCE_058.png', '../Data/val_source_image\\\\VALID_SOURCE_059.png', '../Data/val_source_image\\\\VALID_SOURCE_060.png', '../Data/val_source_image\\\\VALID_SOURCE_061.png', '../Data/val_source_image\\\\VALID_SOURCE_062.png', '../Data/val_source_image\\\\VALID_SOURCE_063.png', '../Data/val_source_image\\\\VALID_SOURCE_064.png', '../Data/val_source_image\\\\VALID_SOURCE_065.png', '../Data/val_source_image\\\\VALID_SOURCE_066.png', '../Data/val_source_image\\\\VALID_SOURCE_067.png', '../Data/val_source_image\\\\VALID_SOURCE_068.png', '../Data/val_source_image\\\\VALID_SOURCE_069.png', '../Data/val_source_image\\\\VALID_SOURCE_070.png', '../Data/val_source_image\\\\VALID_SOURCE_071.png', '../Data/val_source_image\\\\VALID_SOURCE_072.png', '../Data/val_source_image\\\\VALID_SOURCE_073.png', '../Data/val_source_image\\\\VALID_SOURCE_074.png', '../Data/val_source_image\\\\VALID_SOURCE_075.png', '../Data/val_source_image\\\\VALID_SOURCE_076.png', '../Data/val_source_image\\\\VALID_SOURCE_077.png', '../Data/val_source_image\\\\VALID_SOURCE_078.png', '../Data/val_source_image\\\\VALID_SOURCE_079.png', '../Data/val_source_image\\\\VALID_SOURCE_080.png', '../Data/val_source_image\\\\VALID_SOURCE_081.png', '../Data/val_source_image\\\\VALID_SOURCE_082.png', '../Data/val_source_image\\\\VALID_SOURCE_083.png', '../Data/val_source_image\\\\VALID_SOURCE_084.png', '../Data/val_source_image\\\\VALID_SOURCE_085.png', '../Data/val_source_image\\\\VALID_SOURCE_086.png', '../Data/val_source_image\\\\VALID_SOURCE_087.png', '../Data/val_source_image\\\\VALID_SOURCE_088.png', '../Data/val_source_image\\\\VALID_SOURCE_089.png', '../Data/val_source_image\\\\VALID_SOURCE_090.png', '../Data/val_source_image\\\\VALID_SOURCE_091.png', '../Data/val_source_image\\\\VALID_SOURCE_092.png', '../Data/val_source_image\\\\VALID_SOURCE_093.png', '../Data/val_source_image\\\\VALID_SOURCE_094.png', '../Data/val_source_image\\\\VALID_SOURCE_095.png', '../Data/val_source_image\\\\VALID_SOURCE_096.png', '../Data/val_source_image\\\\VALID_SOURCE_097.png', '../Data/val_source_image\\\\VALID_SOURCE_098.png', '../Data/val_source_image\\\\VALID_SOURCE_099.png', '../Data/val_source_image\\\\VALID_SOURCE_100.png', '../Data/val_source_image\\\\VALID_SOURCE_101.png', '../Data/val_source_image\\\\VALID_SOURCE_102.png', '../Data/val_source_image\\\\VALID_SOURCE_103.png', '../Data/val_source_image\\\\VALID_SOURCE_104.png', '../Data/val_source_image\\\\VALID_SOURCE_105.png', '../Data/val_source_image\\\\VALID_SOURCE_106.png', '../Data/val_source_image\\\\VALID_SOURCE_107.png', '../Data/val_source_image\\\\VALID_SOURCE_108.png', '../Data/val_source_image\\\\VALID_SOURCE_109.png', '../Data/val_source_image\\\\VALID_SOURCE_110.png', '../Data/val_source_image\\\\VALID_SOURCE_111.png', '../Data/val_source_image\\\\VALID_SOURCE_112.png', '../Data/val_source_image\\\\VALID_SOURCE_113.png', '../Data/val_source_image\\\\VALID_SOURCE_114.png', '../Data/val_source_image\\\\VALID_SOURCE_115.png', '../Data/val_source_image\\\\VALID_SOURCE_116.png', '../Data/val_source_image\\\\VALID_SOURCE_117.png', '../Data/val_source_image\\\\VALID_SOURCE_118.png', '../Data/val_source_image\\\\VALID_SOURCE_119.png', '../Data/val_source_image\\\\VALID_SOURCE_120.png', '../Data/val_source_image\\\\VALID_SOURCE_121.png', '../Data/val_source_image\\\\VALID_SOURCE_122.png', '../Data/val_source_image\\\\VALID_SOURCE_123.png', '../Data/val_source_image\\\\VALID_SOURCE_124.png', '../Data/val_source_image\\\\VALID_SOURCE_125.png', '../Data/val_source_image\\\\VALID_SOURCE_126.png', '../Data/val_source_image\\\\VALID_SOURCE_127.png', '../Data/val_source_image\\\\VALID_SOURCE_128.png', '../Data/val_source_image\\\\VALID_SOURCE_129.png', '../Data/val_source_image\\\\VALID_SOURCE_130.png', '../Data/val_source_image\\\\VALID_SOURCE_131.png', '../Data/val_source_image\\\\VALID_SOURCE_132.png', '../Data/val_source_image\\\\VALID_SOURCE_133.png', '../Data/val_source_image\\\\VALID_SOURCE_134.png', '../Data/val_source_image\\\\VALID_SOURCE_135.png', '../Data/val_source_image\\\\VALID_SOURCE_136.png', '../Data/val_source_image\\\\VALID_SOURCE_137.png', '../Data/val_source_image\\\\VALID_SOURCE_138.png', '../Data/val_source_image\\\\VALID_SOURCE_139.png', '../Data/val_source_image\\\\VALID_SOURCE_140.png', '../Data/val_source_image\\\\VALID_SOURCE_141.png', '../Data/val_source_image\\\\VALID_SOURCE_142.png', '../Data/val_source_image\\\\VALID_SOURCE_143.png', '../Data/val_source_image\\\\VALID_SOURCE_144.png', '../Data/val_source_image\\\\VALID_SOURCE_145.png', '../Data/val_source_image\\\\VALID_SOURCE_146.png', '../Data/val_source_image\\\\VALID_SOURCE_147.png', '../Data/val_source_image\\\\VALID_SOURCE_148.png', '../Data/val_source_image\\\\VALID_SOURCE_149.png', '../Data/val_source_image\\\\VALID_SOURCE_150.png', '../Data/val_source_image\\\\VALID_SOURCE_151.png', '../Data/val_source_image\\\\VALID_SOURCE_152.png', '../Data/val_source_image\\\\VALID_SOURCE_153.png', '../Data/val_source_image\\\\VALID_SOURCE_154.png', '../Data/val_source_image\\\\VALID_SOURCE_155.png', '../Data/val_source_image\\\\VALID_SOURCE_156.png', '../Data/val_source_image\\\\VALID_SOURCE_157.png', '../Data/val_source_image\\\\VALID_SOURCE_158.png', '../Data/val_source_image\\\\VALID_SOURCE_159.png', '../Data/val_source_image\\\\VALID_SOURCE_160.png', '../Data/val_source_image\\\\VALID_SOURCE_161.png', '../Data/val_source_image\\\\VALID_SOURCE_162.png', '../Data/val_source_image\\\\VALID_SOURCE_163.png', '../Data/val_source_image\\\\VALID_SOURCE_164.png', '../Data/val_source_image\\\\VALID_SOURCE_165.png', '../Data/val_source_image\\\\VALID_SOURCE_166.png', '../Data/val_source_image\\\\VALID_SOURCE_167.png', '../Data/val_source_image\\\\VALID_SOURCE_168.png', '../Data/val_source_image\\\\VALID_SOURCE_169.png', '../Data/val_source_image\\\\VALID_SOURCE_170.png', '../Data/val_source_image\\\\VALID_SOURCE_171.png', '../Data/val_source_image\\\\VALID_SOURCE_172.png', '../Data/val_source_image\\\\VALID_SOURCE_173.png', '../Data/val_source_image\\\\VALID_SOURCE_174.png', '../Data/val_source_image\\\\VALID_SOURCE_175.png', '../Data/val_source_image\\\\VALID_SOURCE_176.png', '../Data/val_source_image\\\\VALID_SOURCE_177.png', '../Data/val_source_image\\\\VALID_SOURCE_178.png', '../Data/val_source_image\\\\VALID_SOURCE_179.png', '../Data/val_source_image\\\\VALID_SOURCE_180.png', '../Data/val_source_image\\\\VALID_SOURCE_181.png', '../Data/val_source_image\\\\VALID_SOURCE_182.png', '../Data/val_source_image\\\\VALID_SOURCE_183.png', '../Data/val_source_image\\\\VALID_SOURCE_184.png', '../Data/val_source_image\\\\VALID_SOURCE_185.png', '../Data/val_source_image\\\\VALID_SOURCE_186.png', '../Data/val_source_image\\\\VALID_SOURCE_187.png', '../Data/val_source_image\\\\VALID_SOURCE_188.png', '../Data/val_source_image\\\\VALID_SOURCE_189.png', '../Data/val_source_image\\\\VALID_SOURCE_190.png', '../Data/val_source_image\\\\VALID_SOURCE_191.png', '../Data/val_source_image\\\\VALID_SOURCE_192.png', '../Data/val_source_image\\\\VALID_SOURCE_193.png', '../Data/val_source_image\\\\VALID_SOURCE_194.png', '../Data/val_source_image\\\\VALID_SOURCE_195.png', '../Data/val_source_image\\\\VALID_SOURCE_196.png', '../Data/val_source_image\\\\VALID_SOURCE_197.png', '../Data/val_source_image\\\\VALID_SOURCE_198.png', '../Data/val_source_image\\\\VALID_SOURCE_199.png', '../Data/val_source_image\\\\VALID_SOURCE_200.png', '../Data/val_source_image\\\\VALID_SOURCE_201.png', '../Data/val_source_image\\\\VALID_SOURCE_202.png', '../Data/val_source_image\\\\VALID_SOURCE_203.png', '../Data/val_source_image\\\\VALID_SOURCE_204.png', '../Data/val_source_image\\\\VALID_SOURCE_205.png', '../Data/val_source_image\\\\VALID_SOURCE_206.png', '../Data/val_source_image\\\\VALID_SOURCE_207.png', '../Data/val_source_image\\\\VALID_SOURCE_208.png', '../Data/val_source_image\\\\VALID_SOURCE_209.png', '../Data/val_source_image\\\\VALID_SOURCE_210.png', '../Data/val_source_image\\\\VALID_SOURCE_211.png', '../Data/val_source_image\\\\VALID_SOURCE_212.png', '../Data/val_source_image\\\\VALID_SOURCE_213.png', '../Data/val_source_image\\\\VALID_SOURCE_214.png', '../Data/val_source_image\\\\VALID_SOURCE_215.png', '../Data/val_source_image\\\\VALID_SOURCE_216.png', '../Data/val_source_image\\\\VALID_SOURCE_217.png', '../Data/val_source_image\\\\VALID_SOURCE_218.png', '../Data/val_source_image\\\\VALID_SOURCE_219.png', '../Data/val_source_image\\\\VALID_SOURCE_220.png', '../Data/val_source_image\\\\VALID_SOURCE_221.png', '../Data/val_source_image\\\\VALID_SOURCE_222.png', '../Data/val_source_image\\\\VALID_SOURCE_223.png', '../Data/val_source_image\\\\VALID_SOURCE_224.png', '../Data/val_source_image\\\\VALID_SOURCE_225.png', '../Data/val_source_image\\\\VALID_SOURCE_226.png', '../Data/val_source_image\\\\VALID_SOURCE_227.png', '../Data/val_source_image\\\\VALID_SOURCE_228.png', '../Data/val_source_image\\\\VALID_SOURCE_229.png', '../Data/val_source_image\\\\VALID_SOURCE_230.png', '../Data/val_source_image\\\\VALID_SOURCE_231.png', '../Data/val_source_image\\\\VALID_SOURCE_232.png', '../Data/val_source_image\\\\VALID_SOURCE_233.png', '../Data/val_source_image\\\\VALID_SOURCE_234.png', '../Data/val_source_image\\\\VALID_SOURCE_235.png', '../Data/val_source_image\\\\VALID_SOURCE_236.png', '../Data/val_source_image\\\\VALID_SOURCE_237.png', '../Data/val_source_image\\\\VALID_SOURCE_238.png', '../Data/val_source_image\\\\VALID_SOURCE_239.png', '../Data/val_source_image\\\\VALID_SOURCE_240.png', '../Data/val_source_image\\\\VALID_SOURCE_241.png', '../Data/val_source_image\\\\VALID_SOURCE_242.png', '../Data/val_source_image\\\\VALID_SOURCE_243.png', '../Data/val_source_image\\\\VALID_SOURCE_244.png', '../Data/val_source_image\\\\VALID_SOURCE_245.png', '../Data/val_source_image\\\\VALID_SOURCE_246.png', '../Data/val_source_image\\\\VALID_SOURCE_247.png', '../Data/val_source_image\\\\VALID_SOURCE_248.png', '../Data/val_source_image\\\\VALID_SOURCE_249.png', '../Data/val_source_image\\\\VALID_SOURCE_250.png', '../Data/val_source_image\\\\VALID_SOURCE_251.png', '../Data/val_source_image\\\\VALID_SOURCE_252.png', '../Data/val_source_image\\\\VALID_SOURCE_253.png', '../Data/val_source_image\\\\VALID_SOURCE_254.png', '../Data/val_source_image\\\\VALID_SOURCE_255.png', '../Data/val_source_image\\\\VALID_SOURCE_256.png', '../Data/val_source_image\\\\VALID_SOURCE_257.png', '../Data/val_source_image\\\\VALID_SOURCE_258.png', '../Data/val_source_image\\\\VALID_SOURCE_259.png', '../Data/val_source_image\\\\VALID_SOURCE_260.png', '../Data/val_source_image\\\\VALID_SOURCE_261.png', '../Data/val_source_image\\\\VALID_SOURCE_262.png', '../Data/val_source_image\\\\VALID_SOURCE_263.png', '../Data/val_source_image\\\\VALID_SOURCE_264.png', '../Data/val_source_image\\\\VALID_SOURCE_265.png', '../Data/val_source_image\\\\VALID_SOURCE_266.png', '../Data/val_source_image\\\\VALID_SOURCE_267.png', '../Data/val_source_image\\\\VALID_SOURCE_268.png', '../Data/val_source_image\\\\VALID_SOURCE_269.png', '../Data/val_source_image\\\\VALID_SOURCE_270.png', '../Data/val_source_image\\\\VALID_SOURCE_271.png', '../Data/val_source_image\\\\VALID_SOURCE_272.png', '../Data/val_source_image\\\\VALID_SOURCE_273.png', '../Data/val_source_image\\\\VALID_SOURCE_274.png', '../Data/val_source_image\\\\VALID_SOURCE_275.png', '../Data/val_source_image\\\\VALID_SOURCE_276.png', '../Data/val_source_image\\\\VALID_SOURCE_277.png', '../Data/val_source_image\\\\VALID_SOURCE_278.png', '../Data/val_source_image\\\\VALID_SOURCE_279.png', '../Data/val_source_image\\\\VALID_SOURCE_280.png', '../Data/val_source_image\\\\VALID_SOURCE_281.png', '../Data/val_source_image\\\\VALID_SOURCE_282.png', '../Data/val_source_image\\\\VALID_SOURCE_283.png', '../Data/val_source_image\\\\VALID_SOURCE_284.png', '../Data/val_source_image\\\\VALID_SOURCE_285.png', '../Data/val_source_image\\\\VALID_SOURCE_286.png', '../Data/val_source_image\\\\VALID_SOURCE_287.png', '../Data/val_source_image\\\\VALID_SOURCE_288.png', '../Data/val_source_image\\\\VALID_SOURCE_289.png', '../Data/val_source_image\\\\VALID_SOURCE_290.png', '../Data/val_source_image\\\\VALID_SOURCE_291.png', '../Data/val_source_image\\\\VALID_SOURCE_292.png', '../Data/val_source_image\\\\VALID_SOURCE_293.png', '../Data/val_source_image\\\\VALID_SOURCE_294.png', '../Data/val_source_image\\\\VALID_SOURCE_295.png', '../Data/val_source_image\\\\VALID_SOURCE_296.png', '../Data/val_source_image\\\\VALID_SOURCE_297.png', '../Data/val_source_image\\\\VALID_SOURCE_298.png', '../Data/val_source_image\\\\VALID_SOURCE_299.png', '../Data/val_source_image\\\\VALID_SOURCE_300.png', '../Data/val_source_image\\\\VALID_SOURCE_301.png', '../Data/val_source_image\\\\VALID_SOURCE_302.png', '../Data/val_source_image\\\\VALID_SOURCE_303.png', '../Data/val_source_image\\\\VALID_SOURCE_304.png', '../Data/val_source_image\\\\VALID_SOURCE_305.png', '../Data/val_source_image\\\\VALID_SOURCE_306.png', '../Data/val_source_image\\\\VALID_SOURCE_307.png', '../Data/val_source_image\\\\VALID_SOURCE_308.png', '../Data/val_source_image\\\\VALID_SOURCE_309.png', '../Data/val_source_image\\\\VALID_SOURCE_310.png', '../Data/val_source_image\\\\VALID_SOURCE_311.png', '../Data/val_source_image\\\\VALID_SOURCE_312.png', '../Data/val_source_image\\\\VALID_SOURCE_313.png', '../Data/val_source_image\\\\VALID_SOURCE_314.png', '../Data/val_source_image\\\\VALID_SOURCE_315.png', '../Data/val_source_image\\\\VALID_SOURCE_316.png', '../Data/val_source_image\\\\VALID_SOURCE_317.png', '../Data/val_source_image\\\\VALID_SOURCE_318.png', '../Data/val_source_image\\\\VALID_SOURCE_319.png', '../Data/val_source_image\\\\VALID_SOURCE_320.png', '../Data/val_source_image\\\\VALID_SOURCE_321.png', '../Data/val_source_image\\\\VALID_SOURCE_322.png', '../Data/val_source_image\\\\VALID_SOURCE_323.png', '../Data/val_source_image\\\\VALID_SOURCE_324.png', '../Data/val_source_image\\\\VALID_SOURCE_325.png', '../Data/val_source_image\\\\VALID_SOURCE_326.png', '../Data/val_source_image\\\\VALID_SOURCE_327.png', '../Data/val_source_image\\\\VALID_SOURCE_328.png', '../Data/val_source_image\\\\VALID_SOURCE_329.png', '../Data/val_source_image\\\\VALID_SOURCE_330.png', '../Data/val_source_image\\\\VALID_SOURCE_331.png', '../Data/val_source_image\\\\VALID_SOURCE_332.png', '../Data/val_source_image\\\\VALID_SOURCE_333.png', '../Data/val_source_image\\\\VALID_SOURCE_334.png', '../Data/val_source_image\\\\VALID_SOURCE_335.png', '../Data/val_source_image\\\\VALID_SOURCE_336.png', '../Data/val_source_image\\\\VALID_SOURCE_337.png', '../Data/val_source_image\\\\VALID_SOURCE_338.png', '../Data/val_source_image\\\\VALID_SOURCE_339.png', '../Data/val_source_image\\\\VALID_SOURCE_340.png', '../Data/val_source_image\\\\VALID_SOURCE_341.png', '../Data/val_source_image\\\\VALID_SOURCE_342.png', '../Data/val_source_image\\\\VALID_SOURCE_343.png', '../Data/val_source_image\\\\VALID_SOURCE_344.png', '../Data/val_source_image\\\\VALID_SOURCE_345.png', '../Data/val_source_image\\\\VALID_SOURCE_346.png', '../Data/val_source_image\\\\VALID_SOURCE_347.png', '../Data/val_source_image\\\\VALID_SOURCE_348.png', '../Data/val_source_image\\\\VALID_SOURCE_349.png', '../Data/val_source_image\\\\VALID_SOURCE_350.png', '../Data/val_source_image\\\\VALID_SOURCE_351.png', '../Data/val_source_image\\\\VALID_SOURCE_352.png', '../Data/val_source_image\\\\VALID_SOURCE_353.png', '../Data/val_source_image\\\\VALID_SOURCE_354.png', '../Data/val_source_image\\\\VALID_SOURCE_355.png', '../Data/val_source_image\\\\VALID_SOURCE_356.png', '../Data/val_source_image\\\\VALID_SOURCE_357.png', '../Data/val_source_image\\\\VALID_SOURCE_358.png', '../Data/val_source_image\\\\VALID_SOURCE_359.png', '../Data/val_source_image\\\\VALID_SOURCE_360.png', '../Data/val_source_image\\\\VALID_SOURCE_361.png', '../Data/val_source_image\\\\VALID_SOURCE_362.png', '../Data/val_source_image\\\\VALID_SOURCE_363.png', '../Data/val_source_image\\\\VALID_SOURCE_364.png', '../Data/val_source_image\\\\VALID_SOURCE_365.png', '../Data/val_source_image\\\\VALID_SOURCE_366.png', '../Data/val_source_image\\\\VALID_SOURCE_367.png', '../Data/val_source_image\\\\VALID_SOURCE_368.png', '../Data/val_source_image\\\\VALID_SOURCE_369.png', '../Data/val_source_image\\\\VALID_SOURCE_370.png', '../Data/val_source_image\\\\VALID_SOURCE_371.png', '../Data/val_source_image\\\\VALID_SOURCE_372.png', '../Data/val_source_image\\\\VALID_SOURCE_373.png', '../Data/val_source_image\\\\VALID_SOURCE_374.png', '../Data/val_source_image\\\\VALID_SOURCE_375.png', '../Data/val_source_image\\\\VALID_SOURCE_376.png', '../Data/val_source_image\\\\VALID_SOURCE_377.png', '../Data/val_source_image\\\\VALID_SOURCE_378.png', '../Data/val_source_image\\\\VALID_SOURCE_379.png', '../Data/val_source_image\\\\VALID_SOURCE_380.png', '../Data/val_source_image\\\\VALID_SOURCE_381.png', '../Data/val_source_image\\\\VALID_SOURCE_382.png', '../Data/val_source_image\\\\VALID_SOURCE_383.png', '../Data/val_source_image\\\\VALID_SOURCE_384.png', '../Data/val_source_image\\\\VALID_SOURCE_385.png', '../Data/val_source_image\\\\VALID_SOURCE_386.png', '../Data/val_source_image\\\\VALID_SOURCE_387.png', '../Data/val_source_image\\\\VALID_SOURCE_388.png', '../Data/val_source_image\\\\VALID_SOURCE_389.png', '../Data/val_source_image\\\\VALID_SOURCE_390.png', '../Data/val_source_image\\\\VALID_SOURCE_391.png', '../Data/val_source_image\\\\VALID_SOURCE_392.png', '../Data/val_source_image\\\\VALID_SOURCE_393.png', '../Data/val_source_image\\\\VALID_SOURCE_394.png', '../Data/val_source_image\\\\VALID_SOURCE_395.png', '../Data/val_source_image\\\\VALID_SOURCE_396.png', '../Data/val_source_image\\\\VALID_SOURCE_397.png', '../Data/val_source_image\\\\VALID_SOURCE_398.png', '../Data/val_source_image\\\\VALID_SOURCE_399.png', '../Data/val_source_image\\\\VALID_SOURCE_400.png', '../Data/val_source_image\\\\VALID_SOURCE_401.png', '../Data/val_source_image\\\\VALID_SOURCE_402.png', '../Data/val_source_image\\\\VALID_SOURCE_403.png', '../Data/val_source_image\\\\VALID_SOURCE_404.png', '../Data/val_source_image\\\\VALID_SOURCE_405.png', '../Data/val_source_image\\\\VALID_SOURCE_406.png', '../Data/val_source_image\\\\VALID_SOURCE_407.png', '../Data/val_source_image\\\\VALID_SOURCE_408.png', '../Data/val_source_image\\\\VALID_SOURCE_409.png', '../Data/val_source_image\\\\VALID_SOURCE_410.png', '../Data/val_source_image\\\\VALID_SOURCE_411.png', '../Data/val_source_image\\\\VALID_SOURCE_412.png', '../Data/val_source_image\\\\VALID_SOURCE_413.png', '../Data/val_source_image\\\\VALID_SOURCE_414.png', '../Data/val_source_image\\\\VALID_SOURCE_415.png', '../Data/val_source_image\\\\VALID_SOURCE_416.png', '../Data/val_source_image\\\\VALID_SOURCE_417.png', '../Data/val_source_image\\\\VALID_SOURCE_418.png', '../Data/val_source_image\\\\VALID_SOURCE_419.png', '../Data/val_source_image\\\\VALID_SOURCE_420.png', '../Data/val_source_image\\\\VALID_SOURCE_421.png', '../Data/val_source_image\\\\VALID_SOURCE_422.png', '../Data/val_source_image\\\\VALID_SOURCE_423.png', '../Data/val_source_image\\\\VALID_SOURCE_424.png', '../Data/val_source_image\\\\VALID_SOURCE_425.png', '../Data/val_source_image\\\\VALID_SOURCE_426.png', '../Data/val_source_image\\\\VALID_SOURCE_427.png', '../Data/val_source_image\\\\VALID_SOURCE_428.png', '../Data/val_source_image\\\\VALID_SOURCE_429.png', '../Data/val_source_image\\\\VALID_SOURCE_430.png', '../Data/val_source_image\\\\VALID_SOURCE_431.png', '../Data/val_source_image\\\\VALID_SOURCE_432.png', '../Data/val_source_image\\\\VALID_SOURCE_433.png', '../Data/val_source_image\\\\VALID_SOURCE_434.png', '../Data/val_source_image\\\\VALID_SOURCE_435.png', '../Data/val_source_image\\\\VALID_SOURCE_436.png', '../Data/val_source_image\\\\VALID_SOURCE_437.png', '../Data/val_source_image\\\\VALID_SOURCE_438.png', '../Data/val_source_image\\\\VALID_SOURCE_439.png', '../Data/val_source_image\\\\VALID_SOURCE_440.png', '../Data/val_source_image\\\\VALID_SOURCE_441.png', '../Data/val_source_image\\\\VALID_SOURCE_442.png', '../Data/val_source_image\\\\VALID_SOURCE_443.png', '../Data/val_source_image\\\\VALID_SOURCE_444.png', '../Data/val_source_image\\\\VALID_SOURCE_445.png', '../Data/val_source_image\\\\VALID_SOURCE_446.png', '../Data/val_source_image\\\\VALID_SOURCE_447.png', '../Data/val_source_image\\\\VALID_SOURCE_448.png', '../Data/val_source_image\\\\VALID_SOURCE_449.png', '../Data/val_source_image\\\\VALID_SOURCE_450.png', '../Data/val_source_image\\\\VALID_SOURCE_451.png', '../Data/val_source_image\\\\VALID_SOURCE_452.png', '../Data/val_source_image\\\\VALID_SOURCE_453.png', '../Data/val_source_image\\\\VALID_SOURCE_454.png', '../Data/val_source_image\\\\VALID_SOURCE_455.png', '../Data/val_source_image\\\\VALID_SOURCE_456.png', '../Data/val_source_image\\\\VALID_SOURCE_457.png', '../Data/val_source_image\\\\VALID_SOURCE_458.png', '../Data/val_source_image\\\\VALID_SOURCE_459.png', '../Data/val_source_image\\\\VALID_SOURCE_460.png', '../Data/val_source_image\\\\VALID_SOURCE_461.png', '../Data/val_source_image\\\\VALID_SOURCE_462.png', '../Data/val_source_image\\\\VALID_SOURCE_463.png', '../Data/val_source_image\\\\VALID_SOURCE_464.png', '../Data/val_source_image\\\\VALID_SOURCE_465.png']\n"
     ]
    }
   ],
   "source": [
    "#폴더 이동시 경로 수정이 필요할 수 있음 \n",
    "train_source = glob.glob(\"../Data/train_source_image/*\")\n",
    "val_source = glob.glob(\"../Data/val_source_image/*\")\n",
    "train_gt = glob.glob(\"../Data/train_source_gt/*\")\n",
    "val_gt = glob.glob(\"../Data/val_source_gt/*\")\n",
    "\n",
    "train_source += val_source\n",
    "train_gt += val_gt\n",
    "\n",
    "# glob 이후에 정렬이 안되어 있기 때문에, source - gt matching을 위해 정렬\n",
    "train_source.sort()\n",
    "train_gt.sort()\n",
    "\n",
    "print(train_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../Data/train_source_image\\TRAIN_SOURCE_0000.png</td>\n",
       "      <td>../Data/train_source_gt\\TRAIN_SOURCE_0000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../Data/train_source_image\\TRAIN_SOURCE_0001.png</td>\n",
       "      <td>../Data/train_source_gt\\TRAIN_SOURCE_0001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../Data/train_source_image\\TRAIN_SOURCE_0002.png</td>\n",
       "      <td>../Data/train_source_gt\\TRAIN_SOURCE_0002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../Data/train_source_image\\TRAIN_SOURCE_0003.png</td>\n",
       "      <td>../Data/train_source_gt\\TRAIN_SOURCE_0003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../Data/train_source_image\\TRAIN_SOURCE_0004.png</td>\n",
       "      <td>../Data/train_source_gt\\TRAIN_SOURCE_0004.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>../Data/val_source_image\\VALID_SOURCE_461.png</td>\n",
       "      <td>../Data/val_source_gt\\VALID_SOURCE_461.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2656</th>\n",
       "      <td>../Data/val_source_image\\VALID_SOURCE_462.png</td>\n",
       "      <td>../Data/val_source_gt\\VALID_SOURCE_462.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2657</th>\n",
       "      <td>../Data/val_source_image\\VALID_SOURCE_463.png</td>\n",
       "      <td>../Data/val_source_gt\\VALID_SOURCE_463.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>../Data/val_source_image\\VALID_SOURCE_464.png</td>\n",
       "      <td>../Data/val_source_gt\\VALID_SOURCE_464.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>../Data/val_source_image\\VALID_SOURCE_465.png</td>\n",
       "      <td>../Data/val_source_gt\\VALID_SOURCE_465.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2660 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                source  \\\n",
       "0     ../Data/train_source_image\\TRAIN_SOURCE_0000.png   \n",
       "1     ../Data/train_source_image\\TRAIN_SOURCE_0001.png   \n",
       "2     ../Data/train_source_image\\TRAIN_SOURCE_0002.png   \n",
       "3     ../Data/train_source_image\\TRAIN_SOURCE_0003.png   \n",
       "4     ../Data/train_source_image\\TRAIN_SOURCE_0004.png   \n",
       "...                                                ...   \n",
       "2655     ../Data/val_source_image\\VALID_SOURCE_461.png   \n",
       "2656     ../Data/val_source_image\\VALID_SOURCE_462.png   \n",
       "2657     ../Data/val_source_image\\VALID_SOURCE_463.png   \n",
       "2658     ../Data/val_source_image\\VALID_SOURCE_464.png   \n",
       "2659     ../Data/val_source_image\\VALID_SOURCE_465.png   \n",
       "\n",
       "                                                 gt  \n",
       "0     ../Data/train_source_gt\\TRAIN_SOURCE_0000.png  \n",
       "1     ../Data/train_source_gt\\TRAIN_SOURCE_0001.png  \n",
       "2     ../Data/train_source_gt\\TRAIN_SOURCE_0002.png  \n",
       "3     ../Data/train_source_gt\\TRAIN_SOURCE_0003.png  \n",
       "4     ../Data/train_source_gt\\TRAIN_SOURCE_0004.png  \n",
       "...                                             ...  \n",
       "2655     ../Data/val_source_gt\\VALID_SOURCE_461.png  \n",
       "2656     ../Data/val_source_gt\\VALID_SOURCE_462.png  \n",
       "2657     ../Data/val_source_gt\\VALID_SOURCE_463.png  \n",
       "2658     ../Data/val_source_gt\\VALID_SOURCE_464.png  \n",
       "2659     ../Data/val_source_gt\\VALID_SOURCE_465.png  \n",
       "\n",
       "[2660 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DF 생성 \n",
    "df = pd.DataFrame(columns=['source','gt'])\n",
    "df['source'] = train_source\n",
    "df['gt'] = train_gt\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, source, gt, transform=None, infer=False):\n",
    "        self.source = source\n",
    "        self.gt = gt\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.source[idx]\n",
    "        image = cv.imread(img_path)\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "        \n",
    "        mask_path = self.gt[idx]\n",
    "        mask = cv.imread(mask_path, cv.IMREAD_GRAYSCALE)\n",
    "        mask[mask == 255] = 12 #/ 배경을 픽셀값 12로 간주 이거 원래 없던 값!\n",
    "\n",
    "        if self.transform: # 알부네이션 먹이이는 형식으로 진행 \n",
    "            augmented = self.transform(image=image, mask=mask) \n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "            \n",
    "        return image, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.source)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfrom - Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose(\n",
    "    [   \n",
    "        A.Resize(224, 224),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, _, _ = train_test_split(df, _, test_size=0.2, random_state=CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(source = train['source'].values, gt = train['gt'].values, transform=transform, infer=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = CustomDataset(source = val['source'].values, gt = val['gt'].values, transform=transform, infer=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "### SMP API\n",
    "\n",
    "- model.encoder - pretrained backbone to extract features of different spatial resolution\n",
    "- model.decoder - depends on models architecture (Unet/Linknet/PSPNet/FPN)\n",
    "- model.segmentation_head - last block to produce required number of mask channels (include also optional upsampling and activation)\n",
    "- model.classification_head - optional block which create classification head on top of encoder\n",
    "- model.forward(x) - sequentially pass x through model`s encoder, decoder and segmentation head (and classification head if specified)\n",
    "\n",
    "### Model Param\n",
    " - Docs - https://www.kaggle.com/code/ligtfeather/semantic-segmentation-is-easy-with-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): MixVisionTransformerEncoder(\n",
       "    (patch_embed1): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (patch_embed2): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (patch_embed3): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (patch_embed4): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (block1): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (kv): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (kv): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.002)\n",
       "        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (kv): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.004)\n",
       "        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "    (block2): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.006)\n",
       "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.008)\n",
       "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.010)\n",
       "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.012)\n",
       "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.014)\n",
       "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.016)\n",
       "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "    (block3): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.018)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.020)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.022)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.024)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.025)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.027)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.029)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.031)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.033)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.035)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.037)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.039)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.041)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.043)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.045)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.047)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.049)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.051)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.053)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.055)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.057)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.059)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.061)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.063)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (24): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.065)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (25): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.067)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (26): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.069)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (27): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.071)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (28): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.073)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (29): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.075)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (30): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.076)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (31): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.078)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (32): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.080)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (33): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.082)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (34): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.084)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (35): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.086)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (36): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.088)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (37): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.090)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (38): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.092)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (39): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.094)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "    (block4): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.096)\n",
       "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.098)\n",
       "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.100)\n",
       "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(832, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       "  (classification_head): ClassificationHead(\n",
       "    (0): AdaptiveMaxPool2d(output_size=1)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Dropout(p=0.5, inplace=True)\n",
       "    (3): Linear(in_features=512, out_features=13, bias=True)\n",
       "    (4): Activation(\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux_params=dict(\n",
    "    pooling='max',             # one of 'avg', 'max'\n",
    "    dropout=0.5,               # dropout ratio, default is None\n",
    "    activation='sigmoid',      # activation function, default is None\n",
    "    classes=13,                 # define number of output labels\n",
    ")\n",
    "\n",
    "model = smp.Unet('mit_b5', encoder_weights='imagenet', classes=13, activation=None, encoder_depth=5, decoder_channels=[256, 128, 64, 32, 16] , aux_params=aux_params)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mIoU for Score >> 가져온 함수여서... batch 사이즈에 대한 고려가 안되어 있을 수 있음\n",
    "def mIoU(pred_mask, mask, smooth=1e-10, n_classes=13):\n",
    "    with torch.no_grad():\n",
    "        pred_mask = F.softmax(pred_mask, dim=1)\n",
    "        pred_mask = torch.argmax(pred_mask, dim=1)\n",
    "        pred_mask = pred_mask.contiguous().view(-1)\n",
    "        mask = mask.contiguous().view(-1)\n",
    "\n",
    "        iou_per_class = []\n",
    "        for clas in range(0, n_classes): #loop per pixel class\n",
    "            true_class = pred_mask == clas\n",
    "            true_label = mask == clas\n",
    "\n",
    "            if true_label.long().sum().item() == 0: #no exist label in this loop\n",
    "                iou_per_class.append(np.nan)\n",
    "            else:\n",
    "                intersect = torch.logical_and(true_class, true_label).sum().float().item()\n",
    "                union = torch.logical_or(true_class, true_label).sum().float().item()\n",
    "\n",
    "                iou = (intersect + smooth) / (union +smooth)\n",
    "                iou_per_class.append(iou)\n",
    "                \n",
    "    return np.nanmean(iou_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_score = 0\n",
    "    with torch.no_grad():\n",
    "        for source , gt in tqdm(iter(val_loader)):\n",
    "            source = source.float().to(device)\n",
    "            gt = gt.long().to(device)\n",
    "            outputs = model(source)\n",
    "            loss = criterion(outputs[0], gt.squeeze(1))\n",
    "            val_loss += loss.item()\n",
    "            val_score += mIoU(outputs[0], gt)\n",
    "    \n",
    "    return val_loss/len(val_loader) , val_score/len(val_loader)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    # Model load \n",
    "    model = model.to(device) # 그냥 model.to(device)만 하면 저장 안됨\n",
    "\n",
    "    # loss function과 optimizer 정의\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "    # 이거 밖에서 선언할거임 \n",
    "    \n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(0, CFG['EPOCHS']):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for source , gt in tqdm(train_loader):\n",
    "            source = source.float().to(device)\n",
    "            gt = gt.long().to(device)\n",
    "            \n",
    "            optimizer.zero_grad() #! 이건 뭐해주는거지?? 추후에 확인 필\n",
    "            outputs = model(source)\n",
    "            \n",
    "            loss = criterion(outputs[0], gt.squeeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        _train_loss = train_loss/len(train_loader)\n",
    "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val accuracy score : [{_val_score:.5f}]')\n",
    "         \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(_val_score)\n",
    "        \n",
    "        if best_score < _val_score:\n",
    "            best_score = _val_score\n",
    "            best_model = model\n",
    "            torch.save(best_model.state_dict(), \"./models/Unet_mit_b5.pt\")\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model()\n",
    "# model.load_state_dict(torch.load('path'))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [17:27<00:00,  7.87s/it]\n",
      "100%|██████████| 34/34 [00:39<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Train Loss : [0.87165] Val Loss : [0.41271] Val accuracy score : [0.39832]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:26<00:00,  5.16s/it]\n",
      "100%|██████████| 34/34 [00:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.33916] Val Loss : [0.29076] Val accuracy score : [0.51331]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:27<00:00,  5.17s/it]\n",
      "100%|██████████| 34/34 [00:53<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.24768] Val Loss : [0.22374] Val accuracy score : [0.54685]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:28<00:00,  5.18s/it]\n",
      "100%|██████████| 34/34 [00:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.19709] Val Loss : [0.19549] Val accuracy score : [0.57013]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:29<00:00,  5.19s/it]\n",
      "100%|██████████| 34/34 [00:53<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.16882] Val Loss : [0.19152] Val accuracy score : [0.57991]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:28<00:00,  5.17s/it]\n",
      "100%|██████████| 34/34 [00:34<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.15300] Val Loss : [0.17057] Val accuracy score : [0.59024]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:28<00:00,  5.18s/it]\n",
      "100%|██████████| 34/34 [00:54<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [0.16241] Val Loss : [0.17435] Val accuracy score : [0.60275]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:17<00:00,  5.10s/it]\n",
      "100%|██████████| 34/34 [00:34<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [0.13207] Val Loss : [0.16090] Val accuracy score : [0.63369]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:22<00:00,  5.13s/it]\n",
      "100%|██████████| 34/34 [00:53<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [0.11742] Val Loss : [0.15631] Val accuracy score : [0.63957]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:25<00:00,  5.16s/it]\n",
      "100%|██████████| 34/34 [00:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [0.10649] Val Loss : [0.15162] Val accuracy score : [0.64858]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:25<00:00,  5.16s/it]\n",
      "100%|██████████| 34/34 [00:53<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [0.09641] Val Loss : [0.15434] Val accuracy score : [0.65789]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:23<00:00,  5.14s/it]\n",
      "100%|██████████| 34/34 [00:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11], Train Loss : [0.08989] Val Loss : [0.15264] Val accuracy score : [0.66511]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:24<00:00,  5.15s/it]\n",
      "100%|██████████| 34/34 [00:53<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12], Train Loss : [0.08644] Val Loss : [0.15263] Val accuracy score : [0.68635]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:24<00:00,  5.14s/it]\n",
      "100%|██████████| 34/34 [00:33<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13], Train Loss : [0.08068] Val Loss : [0.15303] Val accuracy score : [0.68681]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:25<00:00,  5.16s/it]\n",
      "100%|██████████| 34/34 [00:53<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14], Train Loss : [0.07812] Val Loss : [0.15201] Val accuracy score : [0.70741]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:26<00:00,  5.16s/it]\n",
      "100%|██████████| 34/34 [00:33<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15], Train Loss : [0.07125] Val Loss : [0.14959] Val accuracy score : [0.71471]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:25<00:00,  5.15s/it]\n",
      "100%|██████████| 34/34 [00:53<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16], Train Loss : [0.06784] Val Loss : [0.15183] Val accuracy score : [0.71321]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:23<00:00,  5.14s/it]\n",
      "100%|██████████| 34/34 [00:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17], Train Loss : [0.06479] Val Loss : [0.15321] Val accuracy score : [0.71731]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:25<00:00,  5.16s/it]\n",
      "100%|██████████| 34/34 [00:53<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18], Train Loss : [0.06213] Val Loss : [0.15274] Val accuracy score : [0.72177]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:24<00:00,  5.15s/it]\n",
      "100%|██████████| 34/34 [00:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19], Train Loss : [0.06037] Val Loss : [0.15839] Val accuracy score : [0.71832]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:24<00:00,  5.15s/it]\n",
      "100%|██████████| 34/34 [00:54<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], Train Loss : [0.05773] Val Loss : [0.15402] Val accuracy score : [0.73102]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:23<00:00,  5.14s/it]\n",
      "100%|██████████| 34/34 [00:35<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21], Train Loss : [0.05608] Val Loss : [0.15519] Val accuracy score : [0.73241]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:23<00:00,  5.14s/it]\n",
      "100%|██████████| 34/34 [00:53<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22], Train Loss : [0.05359] Val Loss : [0.16069] Val accuracy score : [0.72714]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:22<00:00,  5.13s/it]\n",
      "100%|██████████| 34/34 [00:33<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23], Train Loss : [0.05145] Val Loss : [0.15572] Val accuracy score : [0.74084]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:22<00:00,  5.13s/it]\n",
      "100%|██████████| 34/34 [00:52<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24], Train Loss : [0.04980] Val Loss : [0.16492] Val accuracy score : [0.73586]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:24<00:00,  5.14s/it]\n",
      "100%|██████████| 34/34 [00:32<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25], Train Loss : [0.04821] Val Loss : [0.15986] Val accuracy score : [0.73875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:21<00:00,  5.12s/it]\n",
      "100%|██████████| 34/34 [00:51<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26], Train Loss : [0.04772] Val Loss : [0.15782] Val accuracy score : [0.74862]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:23<00:00,  5.14s/it]\n",
      "100%|██████████| 34/34 [00:32<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27], Train Loss : [0.04573] Val Loss : [0.16265] Val accuracy score : [0.74491]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:24<00:00,  5.14s/it]\n",
      "100%|██████████| 34/34 [00:52<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28], Train Loss : [0.04510] Val Loss : [0.16401] Val accuracy score : [0.74051]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [11:24<00:00,  5.14s/it]\n",
      "100%|██████████| 34/34 [00:34<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29], Train Loss : [0.04490] Val Loss : [0.16393] Val accuracy score : [0.74125]\n",
      "Epoch 00030: reducing learning rate of group 0 to 1.5000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../Data/test_image\\\\TEST_0000.png', '../Data/test_image\\\\TEST_0001.png', '../Data/test_image\\\\TEST_0002.png', '../Data/test_image\\\\TEST_0003.png', '../Data/test_image\\\\TEST_0004.png', '../Data/test_image\\\\TEST_0005.png', '../Data/test_image\\\\TEST_0006.png', '../Data/test_image\\\\TEST_0007.png', '../Data/test_image\\\\TEST_0008.png', '../Data/test_image\\\\TEST_0009.png', '../Data/test_image\\\\TEST_0010.png', '../Data/test_image\\\\TEST_0011.png', '../Data/test_image\\\\TEST_0012.png', '../Data/test_image\\\\TEST_0013.png', '../Data/test_image\\\\TEST_0014.png', '../Data/test_image\\\\TEST_0015.png', '../Data/test_image\\\\TEST_0016.png', '../Data/test_image\\\\TEST_0017.png', '../Data/test_image\\\\TEST_0018.png', '../Data/test_image\\\\TEST_0019.png', '../Data/test_image\\\\TEST_0020.png', '../Data/test_image\\\\TEST_0021.png', '../Data/test_image\\\\TEST_0022.png', '../Data/test_image\\\\TEST_0023.png', '../Data/test_image\\\\TEST_0024.png', '../Data/test_image\\\\TEST_0025.png', '../Data/test_image\\\\TEST_0026.png', '../Data/test_image\\\\TEST_0027.png', '../Data/test_image\\\\TEST_0028.png', '../Data/test_image\\\\TEST_0029.png', '../Data/test_image\\\\TEST_0030.png', '../Data/test_image\\\\TEST_0031.png', '../Data/test_image\\\\TEST_0032.png', '../Data/test_image\\\\TEST_0033.png', '../Data/test_image\\\\TEST_0034.png', '../Data/test_image\\\\TEST_0035.png', '../Data/test_image\\\\TEST_0036.png', '../Data/test_image\\\\TEST_0037.png', '../Data/test_image\\\\TEST_0038.png', '../Data/test_image\\\\TEST_0039.png', '../Data/test_image\\\\TEST_0040.png', '../Data/test_image\\\\TEST_0041.png', '../Data/test_image\\\\TEST_0042.png', '../Data/test_image\\\\TEST_0043.png', '../Data/test_image\\\\TEST_0044.png', '../Data/test_image\\\\TEST_0045.png', '../Data/test_image\\\\TEST_0046.png', '../Data/test_image\\\\TEST_0047.png', '../Data/test_image\\\\TEST_0048.png', '../Data/test_image\\\\TEST_0049.png', '../Data/test_image\\\\TEST_0050.png', '../Data/test_image\\\\TEST_0051.png', '../Data/test_image\\\\TEST_0052.png', '../Data/test_image\\\\TEST_0053.png', '../Data/test_image\\\\TEST_0054.png', '../Data/test_image\\\\TEST_0055.png', '../Data/test_image\\\\TEST_0056.png', '../Data/test_image\\\\TEST_0057.png', '../Data/test_image\\\\TEST_0058.png', '../Data/test_image\\\\TEST_0059.png', '../Data/test_image\\\\TEST_0060.png', '../Data/test_image\\\\TEST_0061.png', '../Data/test_image\\\\TEST_0062.png', '../Data/test_image\\\\TEST_0063.png', '../Data/test_image\\\\TEST_0064.png', '../Data/test_image\\\\TEST_0065.png', '../Data/test_image\\\\TEST_0066.png', '../Data/test_image\\\\TEST_0067.png', '../Data/test_image\\\\TEST_0068.png', '../Data/test_image\\\\TEST_0069.png', '../Data/test_image\\\\TEST_0070.png', '../Data/test_image\\\\TEST_0071.png', '../Data/test_image\\\\TEST_0072.png', '../Data/test_image\\\\TEST_0073.png', '../Data/test_image\\\\TEST_0074.png', '../Data/test_image\\\\TEST_0075.png', '../Data/test_image\\\\TEST_0076.png', '../Data/test_image\\\\TEST_0077.png', '../Data/test_image\\\\TEST_0078.png', '../Data/test_image\\\\TEST_0079.png', '../Data/test_image\\\\TEST_0080.png', '../Data/test_image\\\\TEST_0081.png', '../Data/test_image\\\\TEST_0082.png', '../Data/test_image\\\\TEST_0083.png', '../Data/test_image\\\\TEST_0084.png', '../Data/test_image\\\\TEST_0085.png', '../Data/test_image\\\\TEST_0086.png', '../Data/test_image\\\\TEST_0087.png', '../Data/test_image\\\\TEST_0088.png', '../Data/test_image\\\\TEST_0089.png', '../Data/test_image\\\\TEST_0090.png', '../Data/test_image\\\\TEST_0091.png', '../Data/test_image\\\\TEST_0092.png', '../Data/test_image\\\\TEST_0093.png', '../Data/test_image\\\\TEST_0094.png', '../Data/test_image\\\\TEST_0095.png', '../Data/test_image\\\\TEST_0096.png', '../Data/test_image\\\\TEST_0097.png', '../Data/test_image\\\\TEST_0098.png', '../Data/test_image\\\\TEST_0099.png', '../Data/test_image\\\\TEST_0100.png', '../Data/test_image\\\\TEST_0101.png', '../Data/test_image\\\\TEST_0102.png', '../Data/test_image\\\\TEST_0103.png', '../Data/test_image\\\\TEST_0104.png', '../Data/test_image\\\\TEST_0105.png', '../Data/test_image\\\\TEST_0106.png', '../Data/test_image\\\\TEST_0107.png', '../Data/test_image\\\\TEST_0108.png', '../Data/test_image\\\\TEST_0109.png', '../Data/test_image\\\\TEST_0110.png', '../Data/test_image\\\\TEST_0111.png', '../Data/test_image\\\\TEST_0112.png', '../Data/test_image\\\\TEST_0113.png', '../Data/test_image\\\\TEST_0114.png', '../Data/test_image\\\\TEST_0115.png', '../Data/test_image\\\\TEST_0116.png', '../Data/test_image\\\\TEST_0117.png', '../Data/test_image\\\\TEST_0118.png', '../Data/test_image\\\\TEST_0119.png', '../Data/test_image\\\\TEST_0120.png', '../Data/test_image\\\\TEST_0121.png', '../Data/test_image\\\\TEST_0122.png', '../Data/test_image\\\\TEST_0123.png', '../Data/test_image\\\\TEST_0124.png', '../Data/test_image\\\\TEST_0125.png', '../Data/test_image\\\\TEST_0126.png', '../Data/test_image\\\\TEST_0127.png', '../Data/test_image\\\\TEST_0128.png', '../Data/test_image\\\\TEST_0129.png', '../Data/test_image\\\\TEST_0130.png', '../Data/test_image\\\\TEST_0131.png', '../Data/test_image\\\\TEST_0132.png', '../Data/test_image\\\\TEST_0133.png', '../Data/test_image\\\\TEST_0134.png', '../Data/test_image\\\\TEST_0135.png', '../Data/test_image\\\\TEST_0136.png', '../Data/test_image\\\\TEST_0137.png', '../Data/test_image\\\\TEST_0138.png', '../Data/test_image\\\\TEST_0139.png', '../Data/test_image\\\\TEST_0140.png', '../Data/test_image\\\\TEST_0141.png', '../Data/test_image\\\\TEST_0142.png', '../Data/test_image\\\\TEST_0143.png', '../Data/test_image\\\\TEST_0144.png', '../Data/test_image\\\\TEST_0145.png', '../Data/test_image\\\\TEST_0146.png', '../Data/test_image\\\\TEST_0147.png', '../Data/test_image\\\\TEST_0148.png', '../Data/test_image\\\\TEST_0149.png', '../Data/test_image\\\\TEST_0150.png', '../Data/test_image\\\\TEST_0151.png', '../Data/test_image\\\\TEST_0152.png', '../Data/test_image\\\\TEST_0153.png', '../Data/test_image\\\\TEST_0154.png', '../Data/test_image\\\\TEST_0155.png', '../Data/test_image\\\\TEST_0156.png', '../Data/test_image\\\\TEST_0157.png', '../Data/test_image\\\\TEST_0158.png', '../Data/test_image\\\\TEST_0159.png', '../Data/test_image\\\\TEST_0160.png', '../Data/test_image\\\\TEST_0161.png', '../Data/test_image\\\\TEST_0162.png', '../Data/test_image\\\\TEST_0163.png', '../Data/test_image\\\\TEST_0164.png', '../Data/test_image\\\\TEST_0165.png', '../Data/test_image\\\\TEST_0166.png', '../Data/test_image\\\\TEST_0167.png', '../Data/test_image\\\\TEST_0168.png', '../Data/test_image\\\\TEST_0169.png', '../Data/test_image\\\\TEST_0170.png', '../Data/test_image\\\\TEST_0171.png', '../Data/test_image\\\\TEST_0172.png', '../Data/test_image\\\\TEST_0173.png', '../Data/test_image\\\\TEST_0174.png', '../Data/test_image\\\\TEST_0175.png', '../Data/test_image\\\\TEST_0176.png', '../Data/test_image\\\\TEST_0177.png', '../Data/test_image\\\\TEST_0178.png', '../Data/test_image\\\\TEST_0179.png', '../Data/test_image\\\\TEST_0180.png', '../Data/test_image\\\\TEST_0181.png', '../Data/test_image\\\\TEST_0182.png', '../Data/test_image\\\\TEST_0183.png', '../Data/test_image\\\\TEST_0184.png', '../Data/test_image\\\\TEST_0185.png', '../Data/test_image\\\\TEST_0186.png', '../Data/test_image\\\\TEST_0187.png', '../Data/test_image\\\\TEST_0188.png', '../Data/test_image\\\\TEST_0189.png', '../Data/test_image\\\\TEST_0190.png', '../Data/test_image\\\\TEST_0191.png', '../Data/test_image\\\\TEST_0192.png', '../Data/test_image\\\\TEST_0193.png', '../Data/test_image\\\\TEST_0194.png', '../Data/test_image\\\\TEST_0195.png', '../Data/test_image\\\\TEST_0196.png', '../Data/test_image\\\\TEST_0197.png', '../Data/test_image\\\\TEST_0198.png', '../Data/test_image\\\\TEST_0199.png', '../Data/test_image\\\\TEST_0200.png', '../Data/test_image\\\\TEST_0201.png', '../Data/test_image\\\\TEST_0202.png', '../Data/test_image\\\\TEST_0203.png', '../Data/test_image\\\\TEST_0204.png', '../Data/test_image\\\\TEST_0205.png', '../Data/test_image\\\\TEST_0206.png', '../Data/test_image\\\\TEST_0207.png', '../Data/test_image\\\\TEST_0208.png', '../Data/test_image\\\\TEST_0209.png', '../Data/test_image\\\\TEST_0210.png', '../Data/test_image\\\\TEST_0211.png', '../Data/test_image\\\\TEST_0212.png', '../Data/test_image\\\\TEST_0213.png', '../Data/test_image\\\\TEST_0214.png', '../Data/test_image\\\\TEST_0215.png', '../Data/test_image\\\\TEST_0216.png', '../Data/test_image\\\\TEST_0217.png', '../Data/test_image\\\\TEST_0218.png', '../Data/test_image\\\\TEST_0219.png', '../Data/test_image\\\\TEST_0220.png', '../Data/test_image\\\\TEST_0221.png', '../Data/test_image\\\\TEST_0222.png', '../Data/test_image\\\\TEST_0223.png', '../Data/test_image\\\\TEST_0224.png', '../Data/test_image\\\\TEST_0225.png', '../Data/test_image\\\\TEST_0226.png', '../Data/test_image\\\\TEST_0227.png', '../Data/test_image\\\\TEST_0228.png', '../Data/test_image\\\\TEST_0229.png', '../Data/test_image\\\\TEST_0230.png', '../Data/test_image\\\\TEST_0231.png', '../Data/test_image\\\\TEST_0232.png', '../Data/test_image\\\\TEST_0233.png', '../Data/test_image\\\\TEST_0234.png', '../Data/test_image\\\\TEST_0235.png', '../Data/test_image\\\\TEST_0236.png', '../Data/test_image\\\\TEST_0237.png', '../Data/test_image\\\\TEST_0238.png', '../Data/test_image\\\\TEST_0239.png', '../Data/test_image\\\\TEST_0240.png', '../Data/test_image\\\\TEST_0241.png', '../Data/test_image\\\\TEST_0242.png', '../Data/test_image\\\\TEST_0243.png', '../Data/test_image\\\\TEST_0244.png', '../Data/test_image\\\\TEST_0245.png', '../Data/test_image\\\\TEST_0246.png', '../Data/test_image\\\\TEST_0247.png', '../Data/test_image\\\\TEST_0248.png', '../Data/test_image\\\\TEST_0249.png', '../Data/test_image\\\\TEST_0250.png', '../Data/test_image\\\\TEST_0251.png', '../Data/test_image\\\\TEST_0252.png', '../Data/test_image\\\\TEST_0253.png', '../Data/test_image\\\\TEST_0254.png', '../Data/test_image\\\\TEST_0255.png', '../Data/test_image\\\\TEST_0256.png', '../Data/test_image\\\\TEST_0257.png', '../Data/test_image\\\\TEST_0258.png', '../Data/test_image\\\\TEST_0259.png', '../Data/test_image\\\\TEST_0260.png', '../Data/test_image\\\\TEST_0261.png', '../Data/test_image\\\\TEST_0262.png', '../Data/test_image\\\\TEST_0263.png', '../Data/test_image\\\\TEST_0264.png', '../Data/test_image\\\\TEST_0265.png', '../Data/test_image\\\\TEST_0266.png', '../Data/test_image\\\\TEST_0267.png', '../Data/test_image\\\\TEST_0268.png', '../Data/test_image\\\\TEST_0269.png', '../Data/test_image\\\\TEST_0270.png', '../Data/test_image\\\\TEST_0271.png', '../Data/test_image\\\\TEST_0272.png', '../Data/test_image\\\\TEST_0273.png', '../Data/test_image\\\\TEST_0274.png', '../Data/test_image\\\\TEST_0275.png', '../Data/test_image\\\\TEST_0276.png', '../Data/test_image\\\\TEST_0277.png', '../Data/test_image\\\\TEST_0278.png', '../Data/test_image\\\\TEST_0279.png', '../Data/test_image\\\\TEST_0280.png', '../Data/test_image\\\\TEST_0281.png', '../Data/test_image\\\\TEST_0282.png', '../Data/test_image\\\\TEST_0283.png', '../Data/test_image\\\\TEST_0284.png', '../Data/test_image\\\\TEST_0285.png', '../Data/test_image\\\\TEST_0286.png', '../Data/test_image\\\\TEST_0287.png', '../Data/test_image\\\\TEST_0288.png', '../Data/test_image\\\\TEST_0289.png', '../Data/test_image\\\\TEST_0290.png', '../Data/test_image\\\\TEST_0291.png', '../Data/test_image\\\\TEST_0292.png', '../Data/test_image\\\\TEST_0293.png', '../Data/test_image\\\\TEST_0294.png', '../Data/test_image\\\\TEST_0295.png', '../Data/test_image\\\\TEST_0296.png', '../Data/test_image\\\\TEST_0297.png', '../Data/test_image\\\\TEST_0298.png', '../Data/test_image\\\\TEST_0299.png', '../Data/test_image\\\\TEST_0300.png', '../Data/test_image\\\\TEST_0301.png', '../Data/test_image\\\\TEST_0302.png', '../Data/test_image\\\\TEST_0303.png', '../Data/test_image\\\\TEST_0304.png', '../Data/test_image\\\\TEST_0305.png', '../Data/test_image\\\\TEST_0306.png', '../Data/test_image\\\\TEST_0307.png', '../Data/test_image\\\\TEST_0308.png', '../Data/test_image\\\\TEST_0309.png', '../Data/test_image\\\\TEST_0310.png', '../Data/test_image\\\\TEST_0311.png', '../Data/test_image\\\\TEST_0312.png', '../Data/test_image\\\\TEST_0313.png', '../Data/test_image\\\\TEST_0314.png', '../Data/test_image\\\\TEST_0315.png', '../Data/test_image\\\\TEST_0316.png', '../Data/test_image\\\\TEST_0317.png', '../Data/test_image\\\\TEST_0318.png', '../Data/test_image\\\\TEST_0319.png', '../Data/test_image\\\\TEST_0320.png', '../Data/test_image\\\\TEST_0321.png', '../Data/test_image\\\\TEST_0322.png', '../Data/test_image\\\\TEST_0323.png', '../Data/test_image\\\\TEST_0324.png', '../Data/test_image\\\\TEST_0325.png', '../Data/test_image\\\\TEST_0326.png', '../Data/test_image\\\\TEST_0327.png', '../Data/test_image\\\\TEST_0328.png', '../Data/test_image\\\\TEST_0329.png', '../Data/test_image\\\\TEST_0330.png', '../Data/test_image\\\\TEST_0331.png', '../Data/test_image\\\\TEST_0332.png', '../Data/test_image\\\\TEST_0333.png', '../Data/test_image\\\\TEST_0334.png', '../Data/test_image\\\\TEST_0335.png', '../Data/test_image\\\\TEST_0336.png', '../Data/test_image\\\\TEST_0337.png', '../Data/test_image\\\\TEST_0338.png', '../Data/test_image\\\\TEST_0339.png', '../Data/test_image\\\\TEST_0340.png', '../Data/test_image\\\\TEST_0341.png', '../Data/test_image\\\\TEST_0342.png', '../Data/test_image\\\\TEST_0343.png', '../Data/test_image\\\\TEST_0344.png', '../Data/test_image\\\\TEST_0345.png', '../Data/test_image\\\\TEST_0346.png', '../Data/test_image\\\\TEST_0347.png', '../Data/test_image\\\\TEST_0348.png', '../Data/test_image\\\\TEST_0349.png', '../Data/test_image\\\\TEST_0350.png', '../Data/test_image\\\\TEST_0351.png', '../Data/test_image\\\\TEST_0352.png', '../Data/test_image\\\\TEST_0353.png', '../Data/test_image\\\\TEST_0354.png', '../Data/test_image\\\\TEST_0355.png', '../Data/test_image\\\\TEST_0356.png', '../Data/test_image\\\\TEST_0357.png', '../Data/test_image\\\\TEST_0358.png', '../Data/test_image\\\\TEST_0359.png', '../Data/test_image\\\\TEST_0360.png', '../Data/test_image\\\\TEST_0361.png', '../Data/test_image\\\\TEST_0362.png', '../Data/test_image\\\\TEST_0363.png', '../Data/test_image\\\\TEST_0364.png', '../Data/test_image\\\\TEST_0365.png', '../Data/test_image\\\\TEST_0366.png', '../Data/test_image\\\\TEST_0367.png', '../Data/test_image\\\\TEST_0368.png', '../Data/test_image\\\\TEST_0369.png', '../Data/test_image\\\\TEST_0370.png', '../Data/test_image\\\\TEST_0371.png', '../Data/test_image\\\\TEST_0372.png', '../Data/test_image\\\\TEST_0373.png', '../Data/test_image\\\\TEST_0374.png', '../Data/test_image\\\\TEST_0375.png', '../Data/test_image\\\\TEST_0376.png', '../Data/test_image\\\\TEST_0377.png', '../Data/test_image\\\\TEST_0378.png', '../Data/test_image\\\\TEST_0379.png', '../Data/test_image\\\\TEST_0380.png', '../Data/test_image\\\\TEST_0381.png', '../Data/test_image\\\\TEST_0382.png', '../Data/test_image\\\\TEST_0383.png', '../Data/test_image\\\\TEST_0384.png', '../Data/test_image\\\\TEST_0385.png', '../Data/test_image\\\\TEST_0386.png', '../Data/test_image\\\\TEST_0387.png', '../Data/test_image\\\\TEST_0388.png', '../Data/test_image\\\\TEST_0389.png', '../Data/test_image\\\\TEST_0390.png', '../Data/test_image\\\\TEST_0391.png', '../Data/test_image\\\\TEST_0392.png', '../Data/test_image\\\\TEST_0393.png', '../Data/test_image\\\\TEST_0394.png', '../Data/test_image\\\\TEST_0395.png', '../Data/test_image\\\\TEST_0396.png', '../Data/test_image\\\\TEST_0397.png', '../Data/test_image\\\\TEST_0398.png', '../Data/test_image\\\\TEST_0399.png', '../Data/test_image\\\\TEST_0400.png', '../Data/test_image\\\\TEST_0401.png', '../Data/test_image\\\\TEST_0402.png', '../Data/test_image\\\\TEST_0403.png', '../Data/test_image\\\\TEST_0404.png', '../Data/test_image\\\\TEST_0405.png', '../Data/test_image\\\\TEST_0406.png', '../Data/test_image\\\\TEST_0407.png', '../Data/test_image\\\\TEST_0408.png', '../Data/test_image\\\\TEST_0409.png', '../Data/test_image\\\\TEST_0410.png', '../Data/test_image\\\\TEST_0411.png', '../Data/test_image\\\\TEST_0412.png', '../Data/test_image\\\\TEST_0413.png', '../Data/test_image\\\\TEST_0414.png', '../Data/test_image\\\\TEST_0415.png', '../Data/test_image\\\\TEST_0416.png', '../Data/test_image\\\\TEST_0417.png', '../Data/test_image\\\\TEST_0418.png', '../Data/test_image\\\\TEST_0419.png', '../Data/test_image\\\\TEST_0420.png', '../Data/test_image\\\\TEST_0421.png', '../Data/test_image\\\\TEST_0422.png', '../Data/test_image\\\\TEST_0423.png', '../Data/test_image\\\\TEST_0424.png', '../Data/test_image\\\\TEST_0425.png', '../Data/test_image\\\\TEST_0426.png', '../Data/test_image\\\\TEST_0427.png', '../Data/test_image\\\\TEST_0428.png', '../Data/test_image\\\\TEST_0429.png', '../Data/test_image\\\\TEST_0430.png', '../Data/test_image\\\\TEST_0431.png', '../Data/test_image\\\\TEST_0432.png', '../Data/test_image\\\\TEST_0433.png', '../Data/test_image\\\\TEST_0434.png', '../Data/test_image\\\\TEST_0435.png', '../Data/test_image\\\\TEST_0436.png', '../Data/test_image\\\\TEST_0437.png', '../Data/test_image\\\\TEST_0438.png', '../Data/test_image\\\\TEST_0439.png', '../Data/test_image\\\\TEST_0440.png', '../Data/test_image\\\\TEST_0441.png', '../Data/test_image\\\\TEST_0442.png', '../Data/test_image\\\\TEST_0443.png', '../Data/test_image\\\\TEST_0444.png', '../Data/test_image\\\\TEST_0445.png', '../Data/test_image\\\\TEST_0446.png', '../Data/test_image\\\\TEST_0447.png', '../Data/test_image\\\\TEST_0448.png', '../Data/test_image\\\\TEST_0449.png', '../Data/test_image\\\\TEST_0450.png', '../Data/test_image\\\\TEST_0451.png', '../Data/test_image\\\\TEST_0452.png', '../Data/test_image\\\\TEST_0453.png', '../Data/test_image\\\\TEST_0454.png', '../Data/test_image\\\\TEST_0455.png', '../Data/test_image\\\\TEST_0456.png', '../Data/test_image\\\\TEST_0457.png', '../Data/test_image\\\\TEST_0458.png', '../Data/test_image\\\\TEST_0459.png', '../Data/test_image\\\\TEST_0460.png', '../Data/test_image\\\\TEST_0461.png', '../Data/test_image\\\\TEST_0462.png', '../Data/test_image\\\\TEST_0463.png', '../Data/test_image\\\\TEST_0464.png', '../Data/test_image\\\\TEST_0465.png', '../Data/test_image\\\\TEST_0466.png', '../Data/test_image\\\\TEST_0467.png', '../Data/test_image\\\\TEST_0468.png', '../Data/test_image\\\\TEST_0469.png', '../Data/test_image\\\\TEST_0470.png', '../Data/test_image\\\\TEST_0471.png', '../Data/test_image\\\\TEST_0472.png', '../Data/test_image\\\\TEST_0473.png', '../Data/test_image\\\\TEST_0474.png', '../Data/test_image\\\\TEST_0475.png', '../Data/test_image\\\\TEST_0476.png', '../Data/test_image\\\\TEST_0477.png', '../Data/test_image\\\\TEST_0478.png', '../Data/test_image\\\\TEST_0479.png', '../Data/test_image\\\\TEST_0480.png', '../Data/test_image\\\\TEST_0481.png', '../Data/test_image\\\\TEST_0482.png', '../Data/test_image\\\\TEST_0483.png', '../Data/test_image\\\\TEST_0484.png', '../Data/test_image\\\\TEST_0485.png', '../Data/test_image\\\\TEST_0486.png', '../Data/test_image\\\\TEST_0487.png', '../Data/test_image\\\\TEST_0488.png', '../Data/test_image\\\\TEST_0489.png', '../Data/test_image\\\\TEST_0490.png', '../Data/test_image\\\\TEST_0491.png', '../Data/test_image\\\\TEST_0492.png', '../Data/test_image\\\\TEST_0493.png', '../Data/test_image\\\\TEST_0494.png', '../Data/test_image\\\\TEST_0495.png', '../Data/test_image\\\\TEST_0496.png', '../Data/test_image\\\\TEST_0497.png', '../Data/test_image\\\\TEST_0498.png', '../Data/test_image\\\\TEST_0499.png', '../Data/test_image\\\\TEST_0500.png', '../Data/test_image\\\\TEST_0501.png', '../Data/test_image\\\\TEST_0502.png', '../Data/test_image\\\\TEST_0503.png', '../Data/test_image\\\\TEST_0504.png', '../Data/test_image\\\\TEST_0505.png', '../Data/test_image\\\\TEST_0506.png', '../Data/test_image\\\\TEST_0507.png', '../Data/test_image\\\\TEST_0508.png', '../Data/test_image\\\\TEST_0509.png', '../Data/test_image\\\\TEST_0510.png', '../Data/test_image\\\\TEST_0511.png', '../Data/test_image\\\\TEST_0512.png', '../Data/test_image\\\\TEST_0513.png', '../Data/test_image\\\\TEST_0514.png', '../Data/test_image\\\\TEST_0515.png', '../Data/test_image\\\\TEST_0516.png', '../Data/test_image\\\\TEST_0517.png', '../Data/test_image\\\\TEST_0518.png', '../Data/test_image\\\\TEST_0519.png', '../Data/test_image\\\\TEST_0520.png', '../Data/test_image\\\\TEST_0521.png', '../Data/test_image\\\\TEST_0522.png', '../Data/test_image\\\\TEST_0523.png', '../Data/test_image\\\\TEST_0524.png', '../Data/test_image\\\\TEST_0525.png', '../Data/test_image\\\\TEST_0526.png', '../Data/test_image\\\\TEST_0527.png', '../Data/test_image\\\\TEST_0528.png', '../Data/test_image\\\\TEST_0529.png', '../Data/test_image\\\\TEST_0530.png', '../Data/test_image\\\\TEST_0531.png', '../Data/test_image\\\\TEST_0532.png', '../Data/test_image\\\\TEST_0533.png', '../Data/test_image\\\\TEST_0534.png', '../Data/test_image\\\\TEST_0535.png', '../Data/test_image\\\\TEST_0536.png', '../Data/test_image\\\\TEST_0537.png', '../Data/test_image\\\\TEST_0538.png', '../Data/test_image\\\\TEST_0539.png', '../Data/test_image\\\\TEST_0540.png', '../Data/test_image\\\\TEST_0541.png', '../Data/test_image\\\\TEST_0542.png', '../Data/test_image\\\\TEST_0543.png', '../Data/test_image\\\\TEST_0544.png', '../Data/test_image\\\\TEST_0545.png', '../Data/test_image\\\\TEST_0546.png', '../Data/test_image\\\\TEST_0547.png', '../Data/test_image\\\\TEST_0548.png', '../Data/test_image\\\\TEST_0549.png', '../Data/test_image\\\\TEST_0550.png', '../Data/test_image\\\\TEST_0551.png', '../Data/test_image\\\\TEST_0552.png', '../Data/test_image\\\\TEST_0553.png', '../Data/test_image\\\\TEST_0554.png', '../Data/test_image\\\\TEST_0555.png', '../Data/test_image\\\\TEST_0556.png', '../Data/test_image\\\\TEST_0557.png', '../Data/test_image\\\\TEST_0558.png', '../Data/test_image\\\\TEST_0559.png', '../Data/test_image\\\\TEST_0560.png', '../Data/test_image\\\\TEST_0561.png', '../Data/test_image\\\\TEST_0562.png', '../Data/test_image\\\\TEST_0563.png', '../Data/test_image\\\\TEST_0564.png', '../Data/test_image\\\\TEST_0565.png', '../Data/test_image\\\\TEST_0566.png', '../Data/test_image\\\\TEST_0567.png', '../Data/test_image\\\\TEST_0568.png', '../Data/test_image\\\\TEST_0569.png', '../Data/test_image\\\\TEST_0570.png', '../Data/test_image\\\\TEST_0571.png', '../Data/test_image\\\\TEST_0572.png', '../Data/test_image\\\\TEST_0573.png', '../Data/test_image\\\\TEST_0574.png', '../Data/test_image\\\\TEST_0575.png', '../Data/test_image\\\\TEST_0576.png', '../Data/test_image\\\\TEST_0577.png', '../Data/test_image\\\\TEST_0578.png', '../Data/test_image\\\\TEST_0579.png', '../Data/test_image\\\\TEST_0580.png', '../Data/test_image\\\\TEST_0581.png', '../Data/test_image\\\\TEST_0582.png', '../Data/test_image\\\\TEST_0583.png', '../Data/test_image\\\\TEST_0584.png', '../Data/test_image\\\\TEST_0585.png', '../Data/test_image\\\\TEST_0586.png', '../Data/test_image\\\\TEST_0587.png', '../Data/test_image\\\\TEST_0588.png', '../Data/test_image\\\\TEST_0589.png', '../Data/test_image\\\\TEST_0590.png', '../Data/test_image\\\\TEST_0591.png', '../Data/test_image\\\\TEST_0592.png', '../Data/test_image\\\\TEST_0593.png', '../Data/test_image\\\\TEST_0594.png', '../Data/test_image\\\\TEST_0595.png', '../Data/test_image\\\\TEST_0596.png', '../Data/test_image\\\\TEST_0597.png', '../Data/test_image\\\\TEST_0598.png', '../Data/test_image\\\\TEST_0599.png', '../Data/test_image\\\\TEST_0600.png', '../Data/test_image\\\\TEST_0601.png', '../Data/test_image\\\\TEST_0602.png', '../Data/test_image\\\\TEST_0603.png', '../Data/test_image\\\\TEST_0604.png', '../Data/test_image\\\\TEST_0605.png', '../Data/test_image\\\\TEST_0606.png', '../Data/test_image\\\\TEST_0607.png', '../Data/test_image\\\\TEST_0608.png', '../Data/test_image\\\\TEST_0609.png', '../Data/test_image\\\\TEST_0610.png', '../Data/test_image\\\\TEST_0611.png', '../Data/test_image\\\\TEST_0612.png', '../Data/test_image\\\\TEST_0613.png', '../Data/test_image\\\\TEST_0614.png', '../Data/test_image\\\\TEST_0615.png', '../Data/test_image\\\\TEST_0616.png', '../Data/test_image\\\\TEST_0617.png', '../Data/test_image\\\\TEST_0618.png', '../Data/test_image\\\\TEST_0619.png', '../Data/test_image\\\\TEST_0620.png', '../Data/test_image\\\\TEST_0621.png', '../Data/test_image\\\\TEST_0622.png', '../Data/test_image\\\\TEST_0623.png', '../Data/test_image\\\\TEST_0624.png', '../Data/test_image\\\\TEST_0625.png', '../Data/test_image\\\\TEST_0626.png', '../Data/test_image\\\\TEST_0627.png', '../Data/test_image\\\\TEST_0628.png', '../Data/test_image\\\\TEST_0629.png', '../Data/test_image\\\\TEST_0630.png', '../Data/test_image\\\\TEST_0631.png', '../Data/test_image\\\\TEST_0632.png', '../Data/test_image\\\\TEST_0633.png', '../Data/test_image\\\\TEST_0634.png', '../Data/test_image\\\\TEST_0635.png', '../Data/test_image\\\\TEST_0636.png', '../Data/test_image\\\\TEST_0637.png', '../Data/test_image\\\\TEST_0638.png', '../Data/test_image\\\\TEST_0639.png', '../Data/test_image\\\\TEST_0640.png', '../Data/test_image\\\\TEST_0641.png', '../Data/test_image\\\\TEST_0642.png', '../Data/test_image\\\\TEST_0643.png', '../Data/test_image\\\\TEST_0644.png', '../Data/test_image\\\\TEST_0645.png', '../Data/test_image\\\\TEST_0646.png', '../Data/test_image\\\\TEST_0647.png', '../Data/test_image\\\\TEST_0648.png', '../Data/test_image\\\\TEST_0649.png', '../Data/test_image\\\\TEST_0650.png', '../Data/test_image\\\\TEST_0651.png', '../Data/test_image\\\\TEST_0652.png', '../Data/test_image\\\\TEST_0653.png', '../Data/test_image\\\\TEST_0654.png', '../Data/test_image\\\\TEST_0655.png', '../Data/test_image\\\\TEST_0656.png', '../Data/test_image\\\\TEST_0657.png', '../Data/test_image\\\\TEST_0658.png', '../Data/test_image\\\\TEST_0659.png', '../Data/test_image\\\\TEST_0660.png', '../Data/test_image\\\\TEST_0661.png', '../Data/test_image\\\\TEST_0662.png', '../Data/test_image\\\\TEST_0663.png', '../Data/test_image\\\\TEST_0664.png', '../Data/test_image\\\\TEST_0665.png', '../Data/test_image\\\\TEST_0666.png', '../Data/test_image\\\\TEST_0667.png', '../Data/test_image\\\\TEST_0668.png', '../Data/test_image\\\\TEST_0669.png', '../Data/test_image\\\\TEST_0670.png', '../Data/test_image\\\\TEST_0671.png', '../Data/test_image\\\\TEST_0672.png', '../Data/test_image\\\\TEST_0673.png', '../Data/test_image\\\\TEST_0674.png', '../Data/test_image\\\\TEST_0675.png', '../Data/test_image\\\\TEST_0676.png', '../Data/test_image\\\\TEST_0677.png', '../Data/test_image\\\\TEST_0678.png', '../Data/test_image\\\\TEST_0679.png', '../Data/test_image\\\\TEST_0680.png', '../Data/test_image\\\\TEST_0681.png', '../Data/test_image\\\\TEST_0682.png', '../Data/test_image\\\\TEST_0683.png', '../Data/test_image\\\\TEST_0684.png', '../Data/test_image\\\\TEST_0685.png', '../Data/test_image\\\\TEST_0686.png', '../Data/test_image\\\\TEST_0687.png', '../Data/test_image\\\\TEST_0688.png', '../Data/test_image\\\\TEST_0689.png', '../Data/test_image\\\\TEST_0690.png', '../Data/test_image\\\\TEST_0691.png', '../Data/test_image\\\\TEST_0692.png', '../Data/test_image\\\\TEST_0693.png', '../Data/test_image\\\\TEST_0694.png', '../Data/test_image\\\\TEST_0695.png', '../Data/test_image\\\\TEST_0696.png', '../Data/test_image\\\\TEST_0697.png', '../Data/test_image\\\\TEST_0698.png', '../Data/test_image\\\\TEST_0699.png', '../Data/test_image\\\\TEST_0700.png', '../Data/test_image\\\\TEST_0701.png', '../Data/test_image\\\\TEST_0702.png', '../Data/test_image\\\\TEST_0703.png', '../Data/test_image\\\\TEST_0704.png', '../Data/test_image\\\\TEST_0705.png', '../Data/test_image\\\\TEST_0706.png', '../Data/test_image\\\\TEST_0707.png', '../Data/test_image\\\\TEST_0708.png', '../Data/test_image\\\\TEST_0709.png', '../Data/test_image\\\\TEST_0710.png', '../Data/test_image\\\\TEST_0711.png', '../Data/test_image\\\\TEST_0712.png', '../Data/test_image\\\\TEST_0713.png', '../Data/test_image\\\\TEST_0714.png', '../Data/test_image\\\\TEST_0715.png', '../Data/test_image\\\\TEST_0716.png', '../Data/test_image\\\\TEST_0717.png', '../Data/test_image\\\\TEST_0718.png', '../Data/test_image\\\\TEST_0719.png', '../Data/test_image\\\\TEST_0720.png', '../Data/test_image\\\\TEST_0721.png', '../Data/test_image\\\\TEST_0722.png', '../Data/test_image\\\\TEST_0723.png', '../Data/test_image\\\\TEST_0724.png', '../Data/test_image\\\\TEST_0725.png', '../Data/test_image\\\\TEST_0726.png', '../Data/test_image\\\\TEST_0727.png', '../Data/test_image\\\\TEST_0728.png', '../Data/test_image\\\\TEST_0729.png', '../Data/test_image\\\\TEST_0730.png', '../Data/test_image\\\\TEST_0731.png', '../Data/test_image\\\\TEST_0732.png', '../Data/test_image\\\\TEST_0733.png', '../Data/test_image\\\\TEST_0734.png', '../Data/test_image\\\\TEST_0735.png', '../Data/test_image\\\\TEST_0736.png', '../Data/test_image\\\\TEST_0737.png', '../Data/test_image\\\\TEST_0738.png', '../Data/test_image\\\\TEST_0739.png', '../Data/test_image\\\\TEST_0740.png', '../Data/test_image\\\\TEST_0741.png', '../Data/test_image\\\\TEST_0742.png', '../Data/test_image\\\\TEST_0743.png', '../Data/test_image\\\\TEST_0744.png', '../Data/test_image\\\\TEST_0745.png', '../Data/test_image\\\\TEST_0746.png', '../Data/test_image\\\\TEST_0747.png', '../Data/test_image\\\\TEST_0748.png', '../Data/test_image\\\\TEST_0749.png', '../Data/test_image\\\\TEST_0750.png', '../Data/test_image\\\\TEST_0751.png', '../Data/test_image\\\\TEST_0752.png', '../Data/test_image\\\\TEST_0753.png', '../Data/test_image\\\\TEST_0754.png', '../Data/test_image\\\\TEST_0755.png', '../Data/test_image\\\\TEST_0756.png', '../Data/test_image\\\\TEST_0757.png', '../Data/test_image\\\\TEST_0758.png', '../Data/test_image\\\\TEST_0759.png', '../Data/test_image\\\\TEST_0760.png', '../Data/test_image\\\\TEST_0761.png', '../Data/test_image\\\\TEST_0762.png', '../Data/test_image\\\\TEST_0763.png', '../Data/test_image\\\\TEST_0764.png', '../Data/test_image\\\\TEST_0765.png', '../Data/test_image\\\\TEST_0766.png', '../Data/test_image\\\\TEST_0767.png', '../Data/test_image\\\\TEST_0768.png', '../Data/test_image\\\\TEST_0769.png', '../Data/test_image\\\\TEST_0770.png', '../Data/test_image\\\\TEST_0771.png', '../Data/test_image\\\\TEST_0772.png', '../Data/test_image\\\\TEST_0773.png', '../Data/test_image\\\\TEST_0774.png', '../Data/test_image\\\\TEST_0775.png', '../Data/test_image\\\\TEST_0776.png', '../Data/test_image\\\\TEST_0777.png', '../Data/test_image\\\\TEST_0778.png', '../Data/test_image\\\\TEST_0779.png', '../Data/test_image\\\\TEST_0780.png', '../Data/test_image\\\\TEST_0781.png', '../Data/test_image\\\\TEST_0782.png', '../Data/test_image\\\\TEST_0783.png', '../Data/test_image\\\\TEST_0784.png', '../Data/test_image\\\\TEST_0785.png', '../Data/test_image\\\\TEST_0786.png', '../Data/test_image\\\\TEST_0787.png', '../Data/test_image\\\\TEST_0788.png', '../Data/test_image\\\\TEST_0789.png', '../Data/test_image\\\\TEST_0790.png', '../Data/test_image\\\\TEST_0791.png', '../Data/test_image\\\\TEST_0792.png', '../Data/test_image\\\\TEST_0793.png', '../Data/test_image\\\\TEST_0794.png', '../Data/test_image\\\\TEST_0795.png', '../Data/test_image\\\\TEST_0796.png', '../Data/test_image\\\\TEST_0797.png', '../Data/test_image\\\\TEST_0798.png', '../Data/test_image\\\\TEST_0799.png', '../Data/test_image\\\\TEST_0800.png', '../Data/test_image\\\\TEST_0801.png', '../Data/test_image\\\\TEST_0802.png', '../Data/test_image\\\\TEST_0803.png', '../Data/test_image\\\\TEST_0804.png', '../Data/test_image\\\\TEST_0805.png', '../Data/test_image\\\\TEST_0806.png', '../Data/test_image\\\\TEST_0807.png', '../Data/test_image\\\\TEST_0808.png', '../Data/test_image\\\\TEST_0809.png', '../Data/test_image\\\\TEST_0810.png', '../Data/test_image\\\\TEST_0811.png', '../Data/test_image\\\\TEST_0812.png', '../Data/test_image\\\\TEST_0813.png', '../Data/test_image\\\\TEST_0814.png', '../Data/test_image\\\\TEST_0815.png', '../Data/test_image\\\\TEST_0816.png', '../Data/test_image\\\\TEST_0817.png', '../Data/test_image\\\\TEST_0818.png', '../Data/test_image\\\\TEST_0819.png', '../Data/test_image\\\\TEST_0820.png', '../Data/test_image\\\\TEST_0821.png', '../Data/test_image\\\\TEST_0822.png', '../Data/test_image\\\\TEST_0823.png', '../Data/test_image\\\\TEST_0824.png', '../Data/test_image\\\\TEST_0825.png', '../Data/test_image\\\\TEST_0826.png', '../Data/test_image\\\\TEST_0827.png', '../Data/test_image\\\\TEST_0828.png', '../Data/test_image\\\\TEST_0829.png', '../Data/test_image\\\\TEST_0830.png', '../Data/test_image\\\\TEST_0831.png', '../Data/test_image\\\\TEST_0832.png', '../Data/test_image\\\\TEST_0833.png', '../Data/test_image\\\\TEST_0834.png', '../Data/test_image\\\\TEST_0835.png', '../Data/test_image\\\\TEST_0836.png', '../Data/test_image\\\\TEST_0837.png', '../Data/test_image\\\\TEST_0838.png', '../Data/test_image\\\\TEST_0839.png', '../Data/test_image\\\\TEST_0840.png', '../Data/test_image\\\\TEST_0841.png', '../Data/test_image\\\\TEST_0842.png', '../Data/test_image\\\\TEST_0843.png', '../Data/test_image\\\\TEST_0844.png', '../Data/test_image\\\\TEST_0845.png', '../Data/test_image\\\\TEST_0846.png', '../Data/test_image\\\\TEST_0847.png', '../Data/test_image\\\\TEST_0848.png', '../Data/test_image\\\\TEST_0849.png', '../Data/test_image\\\\TEST_0850.png', '../Data/test_image\\\\TEST_0851.png', '../Data/test_image\\\\TEST_0852.png', '../Data/test_image\\\\TEST_0853.png', '../Data/test_image\\\\TEST_0854.png', '../Data/test_image\\\\TEST_0855.png', '../Data/test_image\\\\TEST_0856.png', '../Data/test_image\\\\TEST_0857.png', '../Data/test_image\\\\TEST_0858.png', '../Data/test_image\\\\TEST_0859.png', '../Data/test_image\\\\TEST_0860.png', '../Data/test_image\\\\TEST_0861.png', '../Data/test_image\\\\TEST_0862.png', '../Data/test_image\\\\TEST_0863.png', '../Data/test_image\\\\TEST_0864.png', '../Data/test_image\\\\TEST_0865.png', '../Data/test_image\\\\TEST_0866.png', '../Data/test_image\\\\TEST_0867.png', '../Data/test_image\\\\TEST_0868.png', '../Data/test_image\\\\TEST_0869.png', '../Data/test_image\\\\TEST_0870.png', '../Data/test_image\\\\TEST_0871.png', '../Data/test_image\\\\TEST_0872.png', '../Data/test_image\\\\TEST_0873.png', '../Data/test_image\\\\TEST_0874.png', '../Data/test_image\\\\TEST_0875.png', '../Data/test_image\\\\TEST_0876.png', '../Data/test_image\\\\TEST_0877.png', '../Data/test_image\\\\TEST_0878.png', '../Data/test_image\\\\TEST_0879.png', '../Data/test_image\\\\TEST_0880.png', '../Data/test_image\\\\TEST_0881.png', '../Data/test_image\\\\TEST_0882.png', '../Data/test_image\\\\TEST_0883.png', '../Data/test_image\\\\TEST_0884.png', '../Data/test_image\\\\TEST_0885.png', '../Data/test_image\\\\TEST_0886.png', '../Data/test_image\\\\TEST_0887.png', '../Data/test_image\\\\TEST_0888.png', '../Data/test_image\\\\TEST_0889.png', '../Data/test_image\\\\TEST_0890.png', '../Data/test_image\\\\TEST_0891.png', '../Data/test_image\\\\TEST_0892.png', '../Data/test_image\\\\TEST_0893.png', '../Data/test_image\\\\TEST_0894.png', '../Data/test_image\\\\TEST_0895.png', '../Data/test_image\\\\TEST_0896.png', '../Data/test_image\\\\TEST_0897.png', '../Data/test_image\\\\TEST_0898.png', '../Data/test_image\\\\TEST_0899.png', '../Data/test_image\\\\TEST_0900.png', '../Data/test_image\\\\TEST_0901.png', '../Data/test_image\\\\TEST_0902.png', '../Data/test_image\\\\TEST_0903.png', '../Data/test_image\\\\TEST_0904.png', '../Data/test_image\\\\TEST_0905.png', '../Data/test_image\\\\TEST_0906.png', '../Data/test_image\\\\TEST_0907.png', '../Data/test_image\\\\TEST_0908.png', '../Data/test_image\\\\TEST_0909.png', '../Data/test_image\\\\TEST_0910.png', '../Data/test_image\\\\TEST_0911.png', '../Data/test_image\\\\TEST_0912.png', '../Data/test_image\\\\TEST_0913.png', '../Data/test_image\\\\TEST_0914.png', '../Data/test_image\\\\TEST_0915.png', '../Data/test_image\\\\TEST_0916.png', '../Data/test_image\\\\TEST_0917.png', '../Data/test_image\\\\TEST_0918.png', '../Data/test_image\\\\TEST_0919.png', '../Data/test_image\\\\TEST_0920.png', '../Data/test_image\\\\TEST_0921.png', '../Data/test_image\\\\TEST_0922.png', '../Data/test_image\\\\TEST_0923.png', '../Data/test_image\\\\TEST_0924.png', '../Data/test_image\\\\TEST_0925.png', '../Data/test_image\\\\TEST_0926.png', '../Data/test_image\\\\TEST_0927.png', '../Data/test_image\\\\TEST_0928.png', '../Data/test_image\\\\TEST_0929.png', '../Data/test_image\\\\TEST_0930.png', '../Data/test_image\\\\TEST_0931.png', '../Data/test_image\\\\TEST_0932.png', '../Data/test_image\\\\TEST_0933.png', '../Data/test_image\\\\TEST_0934.png', '../Data/test_image\\\\TEST_0935.png', '../Data/test_image\\\\TEST_0936.png', '../Data/test_image\\\\TEST_0937.png', '../Data/test_image\\\\TEST_0938.png', '../Data/test_image\\\\TEST_0939.png', '../Data/test_image\\\\TEST_0940.png', '../Data/test_image\\\\TEST_0941.png', '../Data/test_image\\\\TEST_0942.png', '../Data/test_image\\\\TEST_0943.png', '../Data/test_image\\\\TEST_0944.png', '../Data/test_image\\\\TEST_0945.png', '../Data/test_image\\\\TEST_0946.png', '../Data/test_image\\\\TEST_0947.png', '../Data/test_image\\\\TEST_0948.png', '../Data/test_image\\\\TEST_0949.png', '../Data/test_image\\\\TEST_0950.png', '../Data/test_image\\\\TEST_0951.png', '../Data/test_image\\\\TEST_0952.png', '../Data/test_image\\\\TEST_0953.png', '../Data/test_image\\\\TEST_0954.png', '../Data/test_image\\\\TEST_0955.png', '../Data/test_image\\\\TEST_0956.png', '../Data/test_image\\\\TEST_0957.png', '../Data/test_image\\\\TEST_0958.png', '../Data/test_image\\\\TEST_0959.png', '../Data/test_image\\\\TEST_0960.png', '../Data/test_image\\\\TEST_0961.png', '../Data/test_image\\\\TEST_0962.png', '../Data/test_image\\\\TEST_0963.png', '../Data/test_image\\\\TEST_0964.png', '../Data/test_image\\\\TEST_0965.png', '../Data/test_image\\\\TEST_0966.png', '../Data/test_image\\\\TEST_0967.png', '../Data/test_image\\\\TEST_0968.png', '../Data/test_image\\\\TEST_0969.png', '../Data/test_image\\\\TEST_0970.png', '../Data/test_image\\\\TEST_0971.png', '../Data/test_image\\\\TEST_0972.png', '../Data/test_image\\\\TEST_0973.png', '../Data/test_image\\\\TEST_0974.png', '../Data/test_image\\\\TEST_0975.png', '../Data/test_image\\\\TEST_0976.png', '../Data/test_image\\\\TEST_0977.png', '../Data/test_image\\\\TEST_0978.png', '../Data/test_image\\\\TEST_0979.png', '../Data/test_image\\\\TEST_0980.png', '../Data/test_image\\\\TEST_0981.png', '../Data/test_image\\\\TEST_0982.png', '../Data/test_image\\\\TEST_0983.png', '../Data/test_image\\\\TEST_0984.png', '../Data/test_image\\\\TEST_0985.png', '../Data/test_image\\\\TEST_0986.png', '../Data/test_image\\\\TEST_0987.png', '../Data/test_image\\\\TEST_0988.png', '../Data/test_image\\\\TEST_0989.png', '../Data/test_image\\\\TEST_0990.png', '../Data/test_image\\\\TEST_0991.png', '../Data/test_image\\\\TEST_0992.png', '../Data/test_image\\\\TEST_0993.png', '../Data/test_image\\\\TEST_0994.png', '../Data/test_image\\\\TEST_0995.png', '../Data/test_image\\\\TEST_0996.png', '../Data/test_image\\\\TEST_0997.png', '../Data/test_image\\\\TEST_0998.png', '../Data/test_image\\\\TEST_0999.png', '../Data/test_image\\\\TEST_1000.png', '../Data/test_image\\\\TEST_1001.png', '../Data/test_image\\\\TEST_1002.png', '../Data/test_image\\\\TEST_1003.png', '../Data/test_image\\\\TEST_1004.png', '../Data/test_image\\\\TEST_1005.png', '../Data/test_image\\\\TEST_1006.png', '../Data/test_image\\\\TEST_1007.png', '../Data/test_image\\\\TEST_1008.png', '../Data/test_image\\\\TEST_1009.png', '../Data/test_image\\\\TEST_1010.png', '../Data/test_image\\\\TEST_1011.png', '../Data/test_image\\\\TEST_1012.png', '../Data/test_image\\\\TEST_1013.png', '../Data/test_image\\\\TEST_1014.png', '../Data/test_image\\\\TEST_1015.png', '../Data/test_image\\\\TEST_1016.png', '../Data/test_image\\\\TEST_1017.png', '../Data/test_image\\\\TEST_1018.png', '../Data/test_image\\\\TEST_1019.png', '../Data/test_image\\\\TEST_1020.png', '../Data/test_image\\\\TEST_1021.png', '../Data/test_image\\\\TEST_1022.png', '../Data/test_image\\\\TEST_1023.png', '../Data/test_image\\\\TEST_1024.png', '../Data/test_image\\\\TEST_1025.png', '../Data/test_image\\\\TEST_1026.png', '../Data/test_image\\\\TEST_1027.png', '../Data/test_image\\\\TEST_1028.png', '../Data/test_image\\\\TEST_1029.png', '../Data/test_image\\\\TEST_1030.png', '../Data/test_image\\\\TEST_1031.png', '../Data/test_image\\\\TEST_1032.png', '../Data/test_image\\\\TEST_1033.png', '../Data/test_image\\\\TEST_1034.png', '../Data/test_image\\\\TEST_1035.png', '../Data/test_image\\\\TEST_1036.png', '../Data/test_image\\\\TEST_1037.png', '../Data/test_image\\\\TEST_1038.png', '../Data/test_image\\\\TEST_1039.png', '../Data/test_image\\\\TEST_1040.png', '../Data/test_image\\\\TEST_1041.png', '../Data/test_image\\\\TEST_1042.png', '../Data/test_image\\\\TEST_1043.png', '../Data/test_image\\\\TEST_1044.png', '../Data/test_image\\\\TEST_1045.png', '../Data/test_image\\\\TEST_1046.png', '../Data/test_image\\\\TEST_1047.png', '../Data/test_image\\\\TEST_1048.png', '../Data/test_image\\\\TEST_1049.png', '../Data/test_image\\\\TEST_1050.png', '../Data/test_image\\\\TEST_1051.png', '../Data/test_image\\\\TEST_1052.png', '../Data/test_image\\\\TEST_1053.png', '../Data/test_image\\\\TEST_1054.png', '../Data/test_image\\\\TEST_1055.png', '../Data/test_image\\\\TEST_1056.png', '../Data/test_image\\\\TEST_1057.png', '../Data/test_image\\\\TEST_1058.png', '../Data/test_image\\\\TEST_1059.png', '../Data/test_image\\\\TEST_1060.png', '../Data/test_image\\\\TEST_1061.png', '../Data/test_image\\\\TEST_1062.png', '../Data/test_image\\\\TEST_1063.png', '../Data/test_image\\\\TEST_1064.png', '../Data/test_image\\\\TEST_1065.png', '../Data/test_image\\\\TEST_1066.png', '../Data/test_image\\\\TEST_1067.png', '../Data/test_image\\\\TEST_1068.png', '../Data/test_image\\\\TEST_1069.png', '../Data/test_image\\\\TEST_1070.png', '../Data/test_image\\\\TEST_1071.png', '../Data/test_image\\\\TEST_1072.png', '../Data/test_image\\\\TEST_1073.png', '../Data/test_image\\\\TEST_1074.png', '../Data/test_image\\\\TEST_1075.png', '../Data/test_image\\\\TEST_1076.png', '../Data/test_image\\\\TEST_1077.png', '../Data/test_image\\\\TEST_1078.png', '../Data/test_image\\\\TEST_1079.png', '../Data/test_image\\\\TEST_1080.png', '../Data/test_image\\\\TEST_1081.png', '../Data/test_image\\\\TEST_1082.png', '../Data/test_image\\\\TEST_1083.png', '../Data/test_image\\\\TEST_1084.png', '../Data/test_image\\\\TEST_1085.png', '../Data/test_image\\\\TEST_1086.png', '../Data/test_image\\\\TEST_1087.png', '../Data/test_image\\\\TEST_1088.png', '../Data/test_image\\\\TEST_1089.png', '../Data/test_image\\\\TEST_1090.png', '../Data/test_image\\\\TEST_1091.png', '../Data/test_image\\\\TEST_1092.png', '../Data/test_image\\\\TEST_1093.png', '../Data/test_image\\\\TEST_1094.png', '../Data/test_image\\\\TEST_1095.png', '../Data/test_image\\\\TEST_1096.png', '../Data/test_image\\\\TEST_1097.png', '../Data/test_image\\\\TEST_1098.png', '../Data/test_image\\\\TEST_1099.png', '../Data/test_image\\\\TEST_1100.png', '../Data/test_image\\\\TEST_1101.png', '../Data/test_image\\\\TEST_1102.png', '../Data/test_image\\\\TEST_1103.png', '../Data/test_image\\\\TEST_1104.png', '../Data/test_image\\\\TEST_1105.png', '../Data/test_image\\\\TEST_1106.png', '../Data/test_image\\\\TEST_1107.png', '../Data/test_image\\\\TEST_1108.png', '../Data/test_image\\\\TEST_1109.png', '../Data/test_image\\\\TEST_1110.png', '../Data/test_image\\\\TEST_1111.png', '../Data/test_image\\\\TEST_1112.png', '../Data/test_image\\\\TEST_1113.png', '../Data/test_image\\\\TEST_1114.png', '../Data/test_image\\\\TEST_1115.png', '../Data/test_image\\\\TEST_1116.png', '../Data/test_image\\\\TEST_1117.png', '../Data/test_image\\\\TEST_1118.png', '../Data/test_image\\\\TEST_1119.png', '../Data/test_image\\\\TEST_1120.png', '../Data/test_image\\\\TEST_1121.png', '../Data/test_image\\\\TEST_1122.png', '../Data/test_image\\\\TEST_1123.png', '../Data/test_image\\\\TEST_1124.png', '../Data/test_image\\\\TEST_1125.png', '../Data/test_image\\\\TEST_1126.png', '../Data/test_image\\\\TEST_1127.png', '../Data/test_image\\\\TEST_1128.png', '../Data/test_image\\\\TEST_1129.png', '../Data/test_image\\\\TEST_1130.png', '../Data/test_image\\\\TEST_1131.png', '../Data/test_image\\\\TEST_1132.png', '../Data/test_image\\\\TEST_1133.png', '../Data/test_image\\\\TEST_1134.png', '../Data/test_image\\\\TEST_1135.png', '../Data/test_image\\\\TEST_1136.png', '../Data/test_image\\\\TEST_1137.png', '../Data/test_image\\\\TEST_1138.png', '../Data/test_image\\\\TEST_1139.png', '../Data/test_image\\\\TEST_1140.png', '../Data/test_image\\\\TEST_1141.png', '../Data/test_image\\\\TEST_1142.png', '../Data/test_image\\\\TEST_1143.png', '../Data/test_image\\\\TEST_1144.png', '../Data/test_image\\\\TEST_1145.png', '../Data/test_image\\\\TEST_1146.png', '../Data/test_image\\\\TEST_1147.png', '../Data/test_image\\\\TEST_1148.png', '../Data/test_image\\\\TEST_1149.png', '../Data/test_image\\\\TEST_1150.png', '../Data/test_image\\\\TEST_1151.png', '../Data/test_image\\\\TEST_1152.png', '../Data/test_image\\\\TEST_1153.png', '../Data/test_image\\\\TEST_1154.png', '../Data/test_image\\\\TEST_1155.png', '../Data/test_image\\\\TEST_1156.png', '../Data/test_image\\\\TEST_1157.png', '../Data/test_image\\\\TEST_1158.png', '../Data/test_image\\\\TEST_1159.png', '../Data/test_image\\\\TEST_1160.png', '../Data/test_image\\\\TEST_1161.png', '../Data/test_image\\\\TEST_1162.png', '../Data/test_image\\\\TEST_1163.png', '../Data/test_image\\\\TEST_1164.png', '../Data/test_image\\\\TEST_1165.png', '../Data/test_image\\\\TEST_1166.png', '../Data/test_image\\\\TEST_1167.png', '../Data/test_image\\\\TEST_1168.png', '../Data/test_image\\\\TEST_1169.png', '../Data/test_image\\\\TEST_1170.png', '../Data/test_image\\\\TEST_1171.png', '../Data/test_image\\\\TEST_1172.png', '../Data/test_image\\\\TEST_1173.png', '../Data/test_image\\\\TEST_1174.png', '../Data/test_image\\\\TEST_1175.png', '../Data/test_image\\\\TEST_1176.png', '../Data/test_image\\\\TEST_1177.png', '../Data/test_image\\\\TEST_1178.png', '../Data/test_image\\\\TEST_1179.png', '../Data/test_image\\\\TEST_1180.png', '../Data/test_image\\\\TEST_1181.png', '../Data/test_image\\\\TEST_1182.png', '../Data/test_image\\\\TEST_1183.png', '../Data/test_image\\\\TEST_1184.png', '../Data/test_image\\\\TEST_1185.png', '../Data/test_image\\\\TEST_1186.png', '../Data/test_image\\\\TEST_1187.png', '../Data/test_image\\\\TEST_1188.png', '../Data/test_image\\\\TEST_1189.png', '../Data/test_image\\\\TEST_1190.png', '../Data/test_image\\\\TEST_1191.png', '../Data/test_image\\\\TEST_1192.png', '../Data/test_image\\\\TEST_1193.png', '../Data/test_image\\\\TEST_1194.png', '../Data/test_image\\\\TEST_1195.png', '../Data/test_image\\\\TEST_1196.png', '../Data/test_image\\\\TEST_1197.png', '../Data/test_image\\\\TEST_1198.png', '../Data/test_image\\\\TEST_1199.png', '../Data/test_image\\\\TEST_1200.png', '../Data/test_image\\\\TEST_1201.png', '../Data/test_image\\\\TEST_1202.png', '../Data/test_image\\\\TEST_1203.png', '../Data/test_image\\\\TEST_1204.png', '../Data/test_image\\\\TEST_1205.png', '../Data/test_image\\\\TEST_1206.png', '../Data/test_image\\\\TEST_1207.png', '../Data/test_image\\\\TEST_1208.png', '../Data/test_image\\\\TEST_1209.png', '../Data/test_image\\\\TEST_1210.png', '../Data/test_image\\\\TEST_1211.png', '../Data/test_image\\\\TEST_1212.png', '../Data/test_image\\\\TEST_1213.png', '../Data/test_image\\\\TEST_1214.png', '../Data/test_image\\\\TEST_1215.png', '../Data/test_image\\\\TEST_1216.png', '../Data/test_image\\\\TEST_1217.png', '../Data/test_image\\\\TEST_1218.png', '../Data/test_image\\\\TEST_1219.png', '../Data/test_image\\\\TEST_1220.png', '../Data/test_image\\\\TEST_1221.png', '../Data/test_image\\\\TEST_1222.png', '../Data/test_image\\\\TEST_1223.png', '../Data/test_image\\\\TEST_1224.png', '../Data/test_image\\\\TEST_1225.png', '../Data/test_image\\\\TEST_1226.png', '../Data/test_image\\\\TEST_1227.png', '../Data/test_image\\\\TEST_1228.png', '../Data/test_image\\\\TEST_1229.png', '../Data/test_image\\\\TEST_1230.png', '../Data/test_image\\\\TEST_1231.png', '../Data/test_image\\\\TEST_1232.png', '../Data/test_image\\\\TEST_1233.png', '../Data/test_image\\\\TEST_1234.png', '../Data/test_image\\\\TEST_1235.png', '../Data/test_image\\\\TEST_1236.png', '../Data/test_image\\\\TEST_1237.png', '../Data/test_image\\\\TEST_1238.png', '../Data/test_image\\\\TEST_1239.png', '../Data/test_image\\\\TEST_1240.png', '../Data/test_image\\\\TEST_1241.png', '../Data/test_image\\\\TEST_1242.png', '../Data/test_image\\\\TEST_1243.png', '../Data/test_image\\\\TEST_1244.png', '../Data/test_image\\\\TEST_1245.png', '../Data/test_image\\\\TEST_1246.png', '../Data/test_image\\\\TEST_1247.png', '../Data/test_image\\\\TEST_1248.png', '../Data/test_image\\\\TEST_1249.png', '../Data/test_image\\\\TEST_1250.png', '../Data/test_image\\\\TEST_1251.png', '../Data/test_image\\\\TEST_1252.png', '../Data/test_image\\\\TEST_1253.png', '../Data/test_image\\\\TEST_1254.png', '../Data/test_image\\\\TEST_1255.png', '../Data/test_image\\\\TEST_1256.png', '../Data/test_image\\\\TEST_1257.png', '../Data/test_image\\\\TEST_1258.png', '../Data/test_image\\\\TEST_1259.png', '../Data/test_image\\\\TEST_1260.png', '../Data/test_image\\\\TEST_1261.png', '../Data/test_image\\\\TEST_1262.png', '../Data/test_image\\\\TEST_1263.png', '../Data/test_image\\\\TEST_1264.png', '../Data/test_image\\\\TEST_1265.png', '../Data/test_image\\\\TEST_1266.png', '../Data/test_image\\\\TEST_1267.png', '../Data/test_image\\\\TEST_1268.png', '../Data/test_image\\\\TEST_1269.png', '../Data/test_image\\\\TEST_1270.png', '../Data/test_image\\\\TEST_1271.png', '../Data/test_image\\\\TEST_1272.png', '../Data/test_image\\\\TEST_1273.png', '../Data/test_image\\\\TEST_1274.png', '../Data/test_image\\\\TEST_1275.png', '../Data/test_image\\\\TEST_1276.png', '../Data/test_image\\\\TEST_1277.png', '../Data/test_image\\\\TEST_1278.png', '../Data/test_image\\\\TEST_1279.png', '../Data/test_image\\\\TEST_1280.png', '../Data/test_image\\\\TEST_1281.png', '../Data/test_image\\\\TEST_1282.png', '../Data/test_image\\\\TEST_1283.png', '../Data/test_image\\\\TEST_1284.png', '../Data/test_image\\\\TEST_1285.png', '../Data/test_image\\\\TEST_1286.png', '../Data/test_image\\\\TEST_1287.png', '../Data/test_image\\\\TEST_1288.png', '../Data/test_image\\\\TEST_1289.png', '../Data/test_image\\\\TEST_1290.png', '../Data/test_image\\\\TEST_1291.png', '../Data/test_image\\\\TEST_1292.png', '../Data/test_image\\\\TEST_1293.png', '../Data/test_image\\\\TEST_1294.png', '../Data/test_image\\\\TEST_1295.png', '../Data/test_image\\\\TEST_1296.png', '../Data/test_image\\\\TEST_1297.png', '../Data/test_image\\\\TEST_1298.png', '../Data/test_image\\\\TEST_1299.png', '../Data/test_image\\\\TEST_1300.png', '../Data/test_image\\\\TEST_1301.png', '../Data/test_image\\\\TEST_1302.png', '../Data/test_image\\\\TEST_1303.png', '../Data/test_image\\\\TEST_1304.png', '../Data/test_image\\\\TEST_1305.png', '../Data/test_image\\\\TEST_1306.png', '../Data/test_image\\\\TEST_1307.png', '../Data/test_image\\\\TEST_1308.png', '../Data/test_image\\\\TEST_1309.png', '../Data/test_image\\\\TEST_1310.png', '../Data/test_image\\\\TEST_1311.png', '../Data/test_image\\\\TEST_1312.png', '../Data/test_image\\\\TEST_1313.png', '../Data/test_image\\\\TEST_1314.png', '../Data/test_image\\\\TEST_1315.png', '../Data/test_image\\\\TEST_1316.png', '../Data/test_image\\\\TEST_1317.png', '../Data/test_image\\\\TEST_1318.png', '../Data/test_image\\\\TEST_1319.png', '../Data/test_image\\\\TEST_1320.png', '../Data/test_image\\\\TEST_1321.png', '../Data/test_image\\\\TEST_1322.png', '../Data/test_image\\\\TEST_1323.png', '../Data/test_image\\\\TEST_1324.png', '../Data/test_image\\\\TEST_1325.png', '../Data/test_image\\\\TEST_1326.png', '../Data/test_image\\\\TEST_1327.png', '../Data/test_image\\\\TEST_1328.png', '../Data/test_image\\\\TEST_1329.png', '../Data/test_image\\\\TEST_1330.png', '../Data/test_image\\\\TEST_1331.png', '../Data/test_image\\\\TEST_1332.png', '../Data/test_image\\\\TEST_1333.png', '../Data/test_image\\\\TEST_1334.png', '../Data/test_image\\\\TEST_1335.png', '../Data/test_image\\\\TEST_1336.png', '../Data/test_image\\\\TEST_1337.png', '../Data/test_image\\\\TEST_1338.png', '../Data/test_image\\\\TEST_1339.png', '../Data/test_image\\\\TEST_1340.png', '../Data/test_image\\\\TEST_1341.png', '../Data/test_image\\\\TEST_1342.png', '../Data/test_image\\\\TEST_1343.png', '../Data/test_image\\\\TEST_1344.png', '../Data/test_image\\\\TEST_1345.png', '../Data/test_image\\\\TEST_1346.png', '../Data/test_image\\\\TEST_1347.png', '../Data/test_image\\\\TEST_1348.png', '../Data/test_image\\\\TEST_1349.png', '../Data/test_image\\\\TEST_1350.png', '../Data/test_image\\\\TEST_1351.png', '../Data/test_image\\\\TEST_1352.png', '../Data/test_image\\\\TEST_1353.png', '../Data/test_image\\\\TEST_1354.png', '../Data/test_image\\\\TEST_1355.png', '../Data/test_image\\\\TEST_1356.png', '../Data/test_image\\\\TEST_1357.png', '../Data/test_image\\\\TEST_1358.png', '../Data/test_image\\\\TEST_1359.png', '../Data/test_image\\\\TEST_1360.png', '../Data/test_image\\\\TEST_1361.png', '../Data/test_image\\\\TEST_1362.png', '../Data/test_image\\\\TEST_1363.png', '../Data/test_image\\\\TEST_1364.png', '../Data/test_image\\\\TEST_1365.png', '../Data/test_image\\\\TEST_1366.png', '../Data/test_image\\\\TEST_1367.png', '../Data/test_image\\\\TEST_1368.png', '../Data/test_image\\\\TEST_1369.png', '../Data/test_image\\\\TEST_1370.png', '../Data/test_image\\\\TEST_1371.png', '../Data/test_image\\\\TEST_1372.png', '../Data/test_image\\\\TEST_1373.png', '../Data/test_image\\\\TEST_1374.png', '../Data/test_image\\\\TEST_1375.png', '../Data/test_image\\\\TEST_1376.png', '../Data/test_image\\\\TEST_1377.png', '../Data/test_image\\\\TEST_1378.png', '../Data/test_image\\\\TEST_1379.png', '../Data/test_image\\\\TEST_1380.png', '../Data/test_image\\\\TEST_1381.png', '../Data/test_image\\\\TEST_1382.png', '../Data/test_image\\\\TEST_1383.png', '../Data/test_image\\\\TEST_1384.png', '../Data/test_image\\\\TEST_1385.png', '../Data/test_image\\\\TEST_1386.png', '../Data/test_image\\\\TEST_1387.png', '../Data/test_image\\\\TEST_1388.png', '../Data/test_image\\\\TEST_1389.png', '../Data/test_image\\\\TEST_1390.png', '../Data/test_image\\\\TEST_1391.png', '../Data/test_image\\\\TEST_1392.png', '../Data/test_image\\\\TEST_1393.png', '../Data/test_image\\\\TEST_1394.png', '../Data/test_image\\\\TEST_1395.png', '../Data/test_image\\\\TEST_1396.png', '../Data/test_image\\\\TEST_1397.png', '../Data/test_image\\\\TEST_1398.png', '../Data/test_image\\\\TEST_1399.png', '../Data/test_image\\\\TEST_1400.png', '../Data/test_image\\\\TEST_1401.png', '../Data/test_image\\\\TEST_1402.png', '../Data/test_image\\\\TEST_1403.png', '../Data/test_image\\\\TEST_1404.png', '../Data/test_image\\\\TEST_1405.png', '../Data/test_image\\\\TEST_1406.png', '../Data/test_image\\\\TEST_1407.png', '../Data/test_image\\\\TEST_1408.png', '../Data/test_image\\\\TEST_1409.png', '../Data/test_image\\\\TEST_1410.png', '../Data/test_image\\\\TEST_1411.png', '../Data/test_image\\\\TEST_1412.png', '../Data/test_image\\\\TEST_1413.png', '../Data/test_image\\\\TEST_1414.png', '../Data/test_image\\\\TEST_1415.png', '../Data/test_image\\\\TEST_1416.png', '../Data/test_image\\\\TEST_1417.png', '../Data/test_image\\\\TEST_1418.png', '../Data/test_image\\\\TEST_1419.png', '../Data/test_image\\\\TEST_1420.png', '../Data/test_image\\\\TEST_1421.png', '../Data/test_image\\\\TEST_1422.png', '../Data/test_image\\\\TEST_1423.png', '../Data/test_image\\\\TEST_1424.png', '../Data/test_image\\\\TEST_1425.png', '../Data/test_image\\\\TEST_1426.png', '../Data/test_image\\\\TEST_1427.png', '../Data/test_image\\\\TEST_1428.png', '../Data/test_image\\\\TEST_1429.png', '../Data/test_image\\\\TEST_1430.png', '../Data/test_image\\\\TEST_1431.png', '../Data/test_image\\\\TEST_1432.png', '../Data/test_image\\\\TEST_1433.png', '../Data/test_image\\\\TEST_1434.png', '../Data/test_image\\\\TEST_1435.png', '../Data/test_image\\\\TEST_1436.png', '../Data/test_image\\\\TEST_1437.png', '../Data/test_image\\\\TEST_1438.png', '../Data/test_image\\\\TEST_1439.png', '../Data/test_image\\\\TEST_1440.png', '../Data/test_image\\\\TEST_1441.png', '../Data/test_image\\\\TEST_1442.png', '../Data/test_image\\\\TEST_1443.png', '../Data/test_image\\\\TEST_1444.png', '../Data/test_image\\\\TEST_1445.png', '../Data/test_image\\\\TEST_1446.png', '../Data/test_image\\\\TEST_1447.png', '../Data/test_image\\\\TEST_1448.png', '../Data/test_image\\\\TEST_1449.png', '../Data/test_image\\\\TEST_1450.png', '../Data/test_image\\\\TEST_1451.png', '../Data/test_image\\\\TEST_1452.png', '../Data/test_image\\\\TEST_1453.png', '../Data/test_image\\\\TEST_1454.png', '../Data/test_image\\\\TEST_1455.png', '../Data/test_image\\\\TEST_1456.png', '../Data/test_image\\\\TEST_1457.png', '../Data/test_image\\\\TEST_1458.png', '../Data/test_image\\\\TEST_1459.png', '../Data/test_image\\\\TEST_1460.png', '../Data/test_image\\\\TEST_1461.png', '../Data/test_image\\\\TEST_1462.png', '../Data/test_image\\\\TEST_1463.png', '../Data/test_image\\\\TEST_1464.png', '../Data/test_image\\\\TEST_1465.png', '../Data/test_image\\\\TEST_1466.png', '../Data/test_image\\\\TEST_1467.png', '../Data/test_image\\\\TEST_1468.png', '../Data/test_image\\\\TEST_1469.png', '../Data/test_image\\\\TEST_1470.png', '../Data/test_image\\\\TEST_1471.png', '../Data/test_image\\\\TEST_1472.png', '../Data/test_image\\\\TEST_1473.png', '../Data/test_image\\\\TEST_1474.png', '../Data/test_image\\\\TEST_1475.png', '../Data/test_image\\\\TEST_1476.png', '../Data/test_image\\\\TEST_1477.png', '../Data/test_image\\\\TEST_1478.png', '../Data/test_image\\\\TEST_1479.png', '../Data/test_image\\\\TEST_1480.png', '../Data/test_image\\\\TEST_1481.png', '../Data/test_image\\\\TEST_1482.png', '../Data/test_image\\\\TEST_1483.png', '../Data/test_image\\\\TEST_1484.png', '../Data/test_image\\\\TEST_1485.png', '../Data/test_image\\\\TEST_1486.png', '../Data/test_image\\\\TEST_1487.png', '../Data/test_image\\\\TEST_1488.png', '../Data/test_image\\\\TEST_1489.png', '../Data/test_image\\\\TEST_1490.png', '../Data/test_image\\\\TEST_1491.png', '../Data/test_image\\\\TEST_1492.png', '../Data/test_image\\\\TEST_1493.png', '../Data/test_image\\\\TEST_1494.png', '../Data/test_image\\\\TEST_1495.png', '../Data/test_image\\\\TEST_1496.png', '../Data/test_image\\\\TEST_1497.png', '../Data/test_image\\\\TEST_1498.png', '../Data/test_image\\\\TEST_1499.png', '../Data/test_image\\\\TEST_1500.png', '../Data/test_image\\\\TEST_1501.png', '../Data/test_image\\\\TEST_1502.png', '../Data/test_image\\\\TEST_1503.png', '../Data/test_image\\\\TEST_1504.png', '../Data/test_image\\\\TEST_1505.png', '../Data/test_image\\\\TEST_1506.png', '../Data/test_image\\\\TEST_1507.png', '../Data/test_image\\\\TEST_1508.png', '../Data/test_image\\\\TEST_1509.png', '../Data/test_image\\\\TEST_1510.png', '../Data/test_image\\\\TEST_1511.png', '../Data/test_image\\\\TEST_1512.png', '../Data/test_image\\\\TEST_1513.png', '../Data/test_image\\\\TEST_1514.png', '../Data/test_image\\\\TEST_1515.png', '../Data/test_image\\\\TEST_1516.png', '../Data/test_image\\\\TEST_1517.png', '../Data/test_image\\\\TEST_1518.png', '../Data/test_image\\\\TEST_1519.png', '../Data/test_image\\\\TEST_1520.png', '../Data/test_image\\\\TEST_1521.png', '../Data/test_image\\\\TEST_1522.png', '../Data/test_image\\\\TEST_1523.png', '../Data/test_image\\\\TEST_1524.png', '../Data/test_image\\\\TEST_1525.png', '../Data/test_image\\\\TEST_1526.png', '../Data/test_image\\\\TEST_1527.png', '../Data/test_image\\\\TEST_1528.png', '../Data/test_image\\\\TEST_1529.png', '../Data/test_image\\\\TEST_1530.png', '../Data/test_image\\\\TEST_1531.png', '../Data/test_image\\\\TEST_1532.png', '../Data/test_image\\\\TEST_1533.png', '../Data/test_image\\\\TEST_1534.png', '../Data/test_image\\\\TEST_1535.png', '../Data/test_image\\\\TEST_1536.png', '../Data/test_image\\\\TEST_1537.png', '../Data/test_image\\\\TEST_1538.png', '../Data/test_image\\\\TEST_1539.png', '../Data/test_image\\\\TEST_1540.png', '../Data/test_image\\\\TEST_1541.png', '../Data/test_image\\\\TEST_1542.png', '../Data/test_image\\\\TEST_1543.png', '../Data/test_image\\\\TEST_1544.png', '../Data/test_image\\\\TEST_1545.png', '../Data/test_image\\\\TEST_1546.png', '../Data/test_image\\\\TEST_1547.png', '../Data/test_image\\\\TEST_1548.png', '../Data/test_image\\\\TEST_1549.png', '../Data/test_image\\\\TEST_1550.png', '../Data/test_image\\\\TEST_1551.png', '../Data/test_image\\\\TEST_1552.png', '../Data/test_image\\\\TEST_1553.png', '../Data/test_image\\\\TEST_1554.png', '../Data/test_image\\\\TEST_1555.png', '../Data/test_image\\\\TEST_1556.png', '../Data/test_image\\\\TEST_1557.png', '../Data/test_image\\\\TEST_1558.png', '../Data/test_image\\\\TEST_1559.png', '../Data/test_image\\\\TEST_1560.png', '../Data/test_image\\\\TEST_1561.png', '../Data/test_image\\\\TEST_1562.png', '../Data/test_image\\\\TEST_1563.png', '../Data/test_image\\\\TEST_1564.png', '../Data/test_image\\\\TEST_1565.png', '../Data/test_image\\\\TEST_1566.png', '../Data/test_image\\\\TEST_1567.png', '../Data/test_image\\\\TEST_1568.png', '../Data/test_image\\\\TEST_1569.png', '../Data/test_image\\\\TEST_1570.png', '../Data/test_image\\\\TEST_1571.png', '../Data/test_image\\\\TEST_1572.png', '../Data/test_image\\\\TEST_1573.png', '../Data/test_image\\\\TEST_1574.png', '../Data/test_image\\\\TEST_1575.png', '../Data/test_image\\\\TEST_1576.png', '../Data/test_image\\\\TEST_1577.png', '../Data/test_image\\\\TEST_1578.png', '../Data/test_image\\\\TEST_1579.png', '../Data/test_image\\\\TEST_1580.png', '../Data/test_image\\\\TEST_1581.png', '../Data/test_image\\\\TEST_1582.png', '../Data/test_image\\\\TEST_1583.png', '../Data/test_image\\\\TEST_1584.png', '../Data/test_image\\\\TEST_1585.png', '../Data/test_image\\\\TEST_1586.png', '../Data/test_image\\\\TEST_1587.png', '../Data/test_image\\\\TEST_1588.png', '../Data/test_image\\\\TEST_1589.png', '../Data/test_image\\\\TEST_1590.png', '../Data/test_image\\\\TEST_1591.png', '../Data/test_image\\\\TEST_1592.png', '../Data/test_image\\\\TEST_1593.png', '../Data/test_image\\\\TEST_1594.png', '../Data/test_image\\\\TEST_1595.png', '../Data/test_image\\\\TEST_1596.png', '../Data/test_image\\\\TEST_1597.png', '../Data/test_image\\\\TEST_1598.png', '../Data/test_image\\\\TEST_1599.png', '../Data/test_image\\\\TEST_1600.png', '../Data/test_image\\\\TEST_1601.png', '../Data/test_image\\\\TEST_1602.png', '../Data/test_image\\\\TEST_1603.png', '../Data/test_image\\\\TEST_1604.png', '../Data/test_image\\\\TEST_1605.png', '../Data/test_image\\\\TEST_1606.png', '../Data/test_image\\\\TEST_1607.png', '../Data/test_image\\\\TEST_1608.png', '../Data/test_image\\\\TEST_1609.png', '../Data/test_image\\\\TEST_1610.png', '../Data/test_image\\\\TEST_1611.png', '../Data/test_image\\\\TEST_1612.png', '../Data/test_image\\\\TEST_1613.png', '../Data/test_image\\\\TEST_1614.png', '../Data/test_image\\\\TEST_1615.png', '../Data/test_image\\\\TEST_1616.png', '../Data/test_image\\\\TEST_1617.png', '../Data/test_image\\\\TEST_1618.png', '../Data/test_image\\\\TEST_1619.png', '../Data/test_image\\\\TEST_1620.png', '../Data/test_image\\\\TEST_1621.png', '../Data/test_image\\\\TEST_1622.png', '../Data/test_image\\\\TEST_1623.png', '../Data/test_image\\\\TEST_1624.png', '../Data/test_image\\\\TEST_1625.png', '../Data/test_image\\\\TEST_1626.png', '../Data/test_image\\\\TEST_1627.png', '../Data/test_image\\\\TEST_1628.png', '../Data/test_image\\\\TEST_1629.png', '../Data/test_image\\\\TEST_1630.png', '../Data/test_image\\\\TEST_1631.png', '../Data/test_image\\\\TEST_1632.png', '../Data/test_image\\\\TEST_1633.png', '../Data/test_image\\\\TEST_1634.png', '../Data/test_image\\\\TEST_1635.png', '../Data/test_image\\\\TEST_1636.png', '../Data/test_image\\\\TEST_1637.png', '../Data/test_image\\\\TEST_1638.png', '../Data/test_image\\\\TEST_1639.png', '../Data/test_image\\\\TEST_1640.png', '../Data/test_image\\\\TEST_1641.png', '../Data/test_image\\\\TEST_1642.png', '../Data/test_image\\\\TEST_1643.png', '../Data/test_image\\\\TEST_1644.png', '../Data/test_image\\\\TEST_1645.png', '../Data/test_image\\\\TEST_1646.png', '../Data/test_image\\\\TEST_1647.png', '../Data/test_image\\\\TEST_1648.png', '../Data/test_image\\\\TEST_1649.png', '../Data/test_image\\\\TEST_1650.png', '../Data/test_image\\\\TEST_1651.png', '../Data/test_image\\\\TEST_1652.png', '../Data/test_image\\\\TEST_1653.png', '../Data/test_image\\\\TEST_1654.png', '../Data/test_image\\\\TEST_1655.png', '../Data/test_image\\\\TEST_1656.png', '../Data/test_image\\\\TEST_1657.png', '../Data/test_image\\\\TEST_1658.png', '../Data/test_image\\\\TEST_1659.png', '../Data/test_image\\\\TEST_1660.png', '../Data/test_image\\\\TEST_1661.png', '../Data/test_image\\\\TEST_1662.png', '../Data/test_image\\\\TEST_1663.png', '../Data/test_image\\\\TEST_1664.png', '../Data/test_image\\\\TEST_1665.png', '../Data/test_image\\\\TEST_1666.png', '../Data/test_image\\\\TEST_1667.png', '../Data/test_image\\\\TEST_1668.png', '../Data/test_image\\\\TEST_1669.png', '../Data/test_image\\\\TEST_1670.png', '../Data/test_image\\\\TEST_1671.png', '../Data/test_image\\\\TEST_1672.png', '../Data/test_image\\\\TEST_1673.png', '../Data/test_image\\\\TEST_1674.png', '../Data/test_image\\\\TEST_1675.png', '../Data/test_image\\\\TEST_1676.png', '../Data/test_image\\\\TEST_1677.png', '../Data/test_image\\\\TEST_1678.png', '../Data/test_image\\\\TEST_1679.png', '../Data/test_image\\\\TEST_1680.png', '../Data/test_image\\\\TEST_1681.png', '../Data/test_image\\\\TEST_1682.png', '../Data/test_image\\\\TEST_1683.png', '../Data/test_image\\\\TEST_1684.png', '../Data/test_image\\\\TEST_1685.png', '../Data/test_image\\\\TEST_1686.png', '../Data/test_image\\\\TEST_1687.png', '../Data/test_image\\\\TEST_1688.png', '../Data/test_image\\\\TEST_1689.png', '../Data/test_image\\\\TEST_1690.png', '../Data/test_image\\\\TEST_1691.png', '../Data/test_image\\\\TEST_1692.png', '../Data/test_image\\\\TEST_1693.png', '../Data/test_image\\\\TEST_1694.png', '../Data/test_image\\\\TEST_1695.png', '../Data/test_image\\\\TEST_1696.png', '../Data/test_image\\\\TEST_1697.png', '../Data/test_image\\\\TEST_1698.png', '../Data/test_image\\\\TEST_1699.png', '../Data/test_image\\\\TEST_1700.png', '../Data/test_image\\\\TEST_1701.png', '../Data/test_image\\\\TEST_1702.png', '../Data/test_image\\\\TEST_1703.png', '../Data/test_image\\\\TEST_1704.png', '../Data/test_image\\\\TEST_1705.png', '../Data/test_image\\\\TEST_1706.png', '../Data/test_image\\\\TEST_1707.png', '../Data/test_image\\\\TEST_1708.png', '../Data/test_image\\\\TEST_1709.png', '../Data/test_image\\\\TEST_1710.png', '../Data/test_image\\\\TEST_1711.png', '../Data/test_image\\\\TEST_1712.png', '../Data/test_image\\\\TEST_1713.png', '../Data/test_image\\\\TEST_1714.png', '../Data/test_image\\\\TEST_1715.png', '../Data/test_image\\\\TEST_1716.png', '../Data/test_image\\\\TEST_1717.png', '../Data/test_image\\\\TEST_1718.png', '../Data/test_image\\\\TEST_1719.png', '../Data/test_image\\\\TEST_1720.png', '../Data/test_image\\\\TEST_1721.png', '../Data/test_image\\\\TEST_1722.png', '../Data/test_image\\\\TEST_1723.png', '../Data/test_image\\\\TEST_1724.png', '../Data/test_image\\\\TEST_1725.png', '../Data/test_image\\\\TEST_1726.png', '../Data/test_image\\\\TEST_1727.png', '../Data/test_image\\\\TEST_1728.png', '../Data/test_image\\\\TEST_1729.png', '../Data/test_image\\\\TEST_1730.png', '../Data/test_image\\\\TEST_1731.png', '../Data/test_image\\\\TEST_1732.png', '../Data/test_image\\\\TEST_1733.png', '../Data/test_image\\\\TEST_1734.png', '../Data/test_image\\\\TEST_1735.png', '../Data/test_image\\\\TEST_1736.png', '../Data/test_image\\\\TEST_1737.png', '../Data/test_image\\\\TEST_1738.png', '../Data/test_image\\\\TEST_1739.png', '../Data/test_image\\\\TEST_1740.png', '../Data/test_image\\\\TEST_1741.png', '../Data/test_image\\\\TEST_1742.png', '../Data/test_image\\\\TEST_1743.png', '../Data/test_image\\\\TEST_1744.png', '../Data/test_image\\\\TEST_1745.png', '../Data/test_image\\\\TEST_1746.png', '../Data/test_image\\\\TEST_1747.png', '../Data/test_image\\\\TEST_1748.png', '../Data/test_image\\\\TEST_1749.png', '../Data/test_image\\\\TEST_1750.png', '../Data/test_image\\\\TEST_1751.png', '../Data/test_image\\\\TEST_1752.png', '../Data/test_image\\\\TEST_1753.png', '../Data/test_image\\\\TEST_1754.png', '../Data/test_image\\\\TEST_1755.png', '../Data/test_image\\\\TEST_1756.png', '../Data/test_image\\\\TEST_1757.png', '../Data/test_image\\\\TEST_1758.png', '../Data/test_image\\\\TEST_1759.png', '../Data/test_image\\\\TEST_1760.png', '../Data/test_image\\\\TEST_1761.png', '../Data/test_image\\\\TEST_1762.png', '../Data/test_image\\\\TEST_1763.png', '../Data/test_image\\\\TEST_1764.png', '../Data/test_image\\\\TEST_1765.png', '../Data/test_image\\\\TEST_1766.png', '../Data/test_image\\\\TEST_1767.png', '../Data/test_image\\\\TEST_1768.png', '../Data/test_image\\\\TEST_1769.png', '../Data/test_image\\\\TEST_1770.png', '../Data/test_image\\\\TEST_1771.png', '../Data/test_image\\\\TEST_1772.png', '../Data/test_image\\\\TEST_1773.png', '../Data/test_image\\\\TEST_1774.png', '../Data/test_image\\\\TEST_1775.png', '../Data/test_image\\\\TEST_1776.png', '../Data/test_image\\\\TEST_1777.png', '../Data/test_image\\\\TEST_1778.png', '../Data/test_image\\\\TEST_1779.png', '../Data/test_image\\\\TEST_1780.png', '../Data/test_image\\\\TEST_1781.png', '../Data/test_image\\\\TEST_1782.png', '../Data/test_image\\\\TEST_1783.png', '../Data/test_image\\\\TEST_1784.png', '../Data/test_image\\\\TEST_1785.png', '../Data/test_image\\\\TEST_1786.png', '../Data/test_image\\\\TEST_1787.png', '../Data/test_image\\\\TEST_1788.png', '../Data/test_image\\\\TEST_1789.png', '../Data/test_image\\\\TEST_1790.png', '../Data/test_image\\\\TEST_1791.png', '../Data/test_image\\\\TEST_1792.png', '../Data/test_image\\\\TEST_1793.png', '../Data/test_image\\\\TEST_1794.png', '../Data/test_image\\\\TEST_1795.png', '../Data/test_image\\\\TEST_1796.png', '../Data/test_image\\\\TEST_1797.png', '../Data/test_image\\\\TEST_1798.png', '../Data/test_image\\\\TEST_1799.png', '../Data/test_image\\\\TEST_1800.png', '../Data/test_image\\\\TEST_1801.png', '../Data/test_image\\\\TEST_1802.png', '../Data/test_image\\\\TEST_1803.png', '../Data/test_image\\\\TEST_1804.png', '../Data/test_image\\\\TEST_1805.png', '../Data/test_image\\\\TEST_1806.png', '../Data/test_image\\\\TEST_1807.png', '../Data/test_image\\\\TEST_1808.png', '../Data/test_image\\\\TEST_1809.png', '../Data/test_image\\\\TEST_1810.png', '../Data/test_image\\\\TEST_1811.png', '../Data/test_image\\\\TEST_1812.png', '../Data/test_image\\\\TEST_1813.png', '../Data/test_image\\\\TEST_1814.png', '../Data/test_image\\\\TEST_1815.png', '../Data/test_image\\\\TEST_1816.png', '../Data/test_image\\\\TEST_1817.png', '../Data/test_image\\\\TEST_1818.png', '../Data/test_image\\\\TEST_1819.png', '../Data/test_image\\\\TEST_1820.png', '../Data/test_image\\\\TEST_1821.png', '../Data/test_image\\\\TEST_1822.png', '../Data/test_image\\\\TEST_1823.png', '../Data/test_image\\\\TEST_1824.png', '../Data/test_image\\\\TEST_1825.png', '../Data/test_image\\\\TEST_1826.png', '../Data/test_image\\\\TEST_1827.png', '../Data/test_image\\\\TEST_1828.png', '../Data/test_image\\\\TEST_1829.png', '../Data/test_image\\\\TEST_1830.png', '../Data/test_image\\\\TEST_1831.png', '../Data/test_image\\\\TEST_1832.png', '../Data/test_image\\\\TEST_1833.png', '../Data/test_image\\\\TEST_1834.png', '../Data/test_image\\\\TEST_1835.png', '../Data/test_image\\\\TEST_1836.png', '../Data/test_image\\\\TEST_1837.png', '../Data/test_image\\\\TEST_1838.png', '../Data/test_image\\\\TEST_1839.png', '../Data/test_image\\\\TEST_1840.png', '../Data/test_image\\\\TEST_1841.png', '../Data/test_image\\\\TEST_1842.png', '../Data/test_image\\\\TEST_1843.png', '../Data/test_image\\\\TEST_1844.png', '../Data/test_image\\\\TEST_1845.png', '../Data/test_image\\\\TEST_1846.png', '../Data/test_image\\\\TEST_1847.png', '../Data/test_image\\\\TEST_1848.png', '../Data/test_image\\\\TEST_1849.png', '../Data/test_image\\\\TEST_1850.png', '../Data/test_image\\\\TEST_1851.png', '../Data/test_image\\\\TEST_1852.png', '../Data/test_image\\\\TEST_1853.png', '../Data/test_image\\\\TEST_1854.png', '../Data/test_image\\\\TEST_1855.png', '../Data/test_image\\\\TEST_1856.png', '../Data/test_image\\\\TEST_1857.png', '../Data/test_image\\\\TEST_1858.png', '../Data/test_image\\\\TEST_1859.png', '../Data/test_image\\\\TEST_1860.png', '../Data/test_image\\\\TEST_1861.png', '../Data/test_image\\\\TEST_1862.png', '../Data/test_image\\\\TEST_1863.png', '../Data/test_image\\\\TEST_1864.png', '../Data/test_image\\\\TEST_1865.png', '../Data/test_image\\\\TEST_1866.png', '../Data/test_image\\\\TEST_1867.png', '../Data/test_image\\\\TEST_1868.png', '../Data/test_image\\\\TEST_1869.png', '../Data/test_image\\\\TEST_1870.png', '../Data/test_image\\\\TEST_1871.png', '../Data/test_image\\\\TEST_1872.png', '../Data/test_image\\\\TEST_1873.png', '../Data/test_image\\\\TEST_1874.png', '../Data/test_image\\\\TEST_1875.png', '../Data/test_image\\\\TEST_1876.png', '../Data/test_image\\\\TEST_1877.png', '../Data/test_image\\\\TEST_1878.png', '../Data/test_image\\\\TEST_1879.png', '../Data/test_image\\\\TEST_1880.png', '../Data/test_image\\\\TEST_1881.png', '../Data/test_image\\\\TEST_1882.png', '../Data/test_image\\\\TEST_1883.png', '../Data/test_image\\\\TEST_1884.png', '../Data/test_image\\\\TEST_1885.png', '../Data/test_image\\\\TEST_1886.png', '../Data/test_image\\\\TEST_1887.png', '../Data/test_image\\\\TEST_1888.png', '../Data/test_image\\\\TEST_1889.png', '../Data/test_image\\\\TEST_1890.png', '../Data/test_image\\\\TEST_1891.png', '../Data/test_image\\\\TEST_1892.png', '../Data/test_image\\\\TEST_1893.png', '../Data/test_image\\\\TEST_1894.png', '../Data/test_image\\\\TEST_1895.png', '../Data/test_image\\\\TEST_1896.png', '../Data/test_image\\\\TEST_1897.png']\n"
     ]
    }
   ],
   "source": [
    "#폴더 이동시 경로 수정이 필요할 수 있음 \n",
    "test_dataset = glob.glob(\"../Data/test_image/*\")\n",
    "\n",
    "# glob 이후에 정렬이 안되어 있기 때문에, source - gt matching을 위해 정렬\n",
    "test_dataset.sort()\n",
    "\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../Data/test_image\\TEST_0000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../Data/test_image\\TEST_0001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../Data/test_image\\TEST_0002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../Data/test_image\\TEST_0003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../Data/test_image\\TEST_0004.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>../Data/test_image\\TEST_1893.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>../Data/test_image\\TEST_1894.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>../Data/test_image\\TEST_1895.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>../Data/test_image\\TEST_1896.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>../Data/test_image\\TEST_1897.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1898 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  test\n",
       "0     ../Data/test_image\\TEST_0000.png\n",
       "1     ../Data/test_image\\TEST_0001.png\n",
       "2     ../Data/test_image\\TEST_0002.png\n",
       "3     ../Data/test_image\\TEST_0003.png\n",
       "4     ../Data/test_image\\TEST_0004.png\n",
       "...                                ...\n",
       "1893  ../Data/test_image\\TEST_1893.png\n",
       "1894  ../Data/test_image\\TEST_1894.png\n",
       "1895  ../Data/test_image\\TEST_1895.png\n",
       "1896  ../Data/test_image\\TEST_1896.png\n",
       "1897  ../Data/test_image\\TEST_1897.png\n",
       "\n",
       "[1898 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame(columns=['test'])\n",
    "df_test['test'] = test_dataset\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(source = df_test['test'].values ,gt = _ , transform=transform, infer=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): MixVisionTransformerEncoder(\n",
       "    (patch_embed1): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (patch_embed2): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (patch_embed3): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (patch_embed4): OverlapPatchEmbed(\n",
       "      (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (block1): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (kv): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (kv): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.002)\n",
       "        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (kv): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.004)\n",
       "        (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "    (block2): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.006)\n",
       "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.008)\n",
       "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.010)\n",
       "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.012)\n",
       "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.014)\n",
       "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (kv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.016)\n",
       "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "    (block3): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.018)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.020)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.022)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.024)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.025)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.027)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.029)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.031)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.033)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.035)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.037)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.039)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.041)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.043)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.045)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.047)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.049)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.051)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.053)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.055)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.057)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.059)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.061)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.063)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (24): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.065)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (25): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.067)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (26): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.069)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (27): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.071)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (28): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.073)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (29): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.075)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (30): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.076)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (31): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.078)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (32): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.080)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (33): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.082)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (34): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.084)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (35): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.086)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (36): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.088)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (37): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.090)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (38): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.092)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (39): Block(\n",
       "        (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (kv): Linear(in_features=320, out_features=640, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.094)\n",
       "        (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "    (block4): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.096)\n",
       "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.098)\n",
       "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (kv): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.100)\n",
       "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dwconv): DWConv(\n",
       "            (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "          )\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(832, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       "  (classification_head): ClassificationHead(\n",
       "    (0): AdaptiveMaxPool2d(output_size=1)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Dropout(p=0.5, inplace=True)\n",
       "    (3): Linear(in_features=512, out_features=13, bias=True)\n",
       "    (4): Activation(\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smp.Unet('mit_b5', encoder_weights='imagenet', classes=13, activation=None, encoder_depth=5, decoder_channels=[256, 128, 64, 32, 16] , aux_params=aux_params)\n",
    "model.load_state_dict(torch.load('./models/Unet_mit_b5.pt'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [02:43<00:00,  1.37s/it]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    result = []\n",
    "    for images in tqdm(test_loader):\n",
    "        images = images.float().to(device)\n",
    "        outputs = model(images)\n",
    "        outputs = torch.softmax(outputs[0], dim=1).cpu()\n",
    "        outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "        # batch에 존재하는 각 이미지에 대해서 반복\n",
    "        for pred in outputs:\n",
    "            pred = pred.astype(np.uint8)\n",
    "            pred = Image.fromarray(pred) # 이미지로 변환\n",
    "            pred = pred.resize((960, 540), Image.NEAREST) # 960 x 540 사이즈로 변환\n",
    "            pred = np.array(pred) # 다시 수치로 변환\n",
    "            # class 0 ~ 11에 해당하는 경우에 마스크 형성 / 12(배경)는 제외하고 진행\n",
    "            for class_id in range(12):\n",
    "                class_mask = (pred == class_id).astype(np.uint8)\n",
    "                if np.sum(class_mask) > 0: # 마스크가 존재하는 경우 encode\n",
    "                    mask_rle = rle_encode(class_mask)\n",
    "                    result.append(mask_rle)\n",
    "                else: # 마스크가 존재하지 않는 경우 -1\n",
    "                    result.append(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submisssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>mask_rle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000_class_0</td>\n",
       "      <td>210712 5 211672 5 212632 5 213584 30 214544 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0000_class_1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0000_class_2</td>\n",
       "      <td>1 206 601 566 1561 583 2517 587 3477 587 4437 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0000_class_3</td>\n",
       "      <td>215345 9 216305 9 217265 9 218212 26 219172 26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0000_class_4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22771</th>\n",
       "      <td>TEST_1897_class_7</td>\n",
       "      <td>888 56 957 4 1848 56 1917 4 2808 47 3768 47 47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22772</th>\n",
       "      <td>TEST_1897_class_8</td>\n",
       "      <td>91 549 670 137 867 21 1051 549 1630 137 1827 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22773</th>\n",
       "      <td>TEST_1897_class_9</td>\n",
       "      <td>237001 4 237961 4 238921 9 239881 9 240841 9 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22774</th>\n",
       "      <td>TEST_1897_class_10</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22775</th>\n",
       "      <td>TEST_1897_class_11</td>\n",
       "      <td>203748 13 203988 13 204708 13 204948 13 205668...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22776 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                           mask_rle\n",
       "0       TEST_0000_class_0  210712 5 211672 5 212632 5 213584 30 214544 30...\n",
       "1       TEST_0000_class_1                                                 -1\n",
       "2       TEST_0000_class_2  1 206 601 566 1561 583 2517 587 3477 587 4437 ...\n",
       "3       TEST_0000_class_3  215345 9 216305 9 217265 9 218212 26 219172 26...\n",
       "4       TEST_0000_class_4                                                 -1\n",
       "...                   ...                                                ...\n",
       "22771   TEST_1897_class_7  888 56 957 4 1848 56 1917 4 2808 47 3768 47 47...\n",
       "22772   TEST_1897_class_8  91 549 670 137 867 21 1051 549 1630 137 1827 2...\n",
       "22773   TEST_1897_class_9  237001 4 237961 4 238921 9 239881 9 240841 9 2...\n",
       "22774  TEST_1897_class_10                                                 -1\n",
       "22775  TEST_1897_class_11  203748 13 203988 13 204708 13 204948 13 205668...\n",
       "\n",
       "[22776 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('../Data/sample_submission.csv')\n",
    "submit['mask_rle'] = result\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./baseline_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EHmin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
